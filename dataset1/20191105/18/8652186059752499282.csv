,src,lang,text
0,"











Consiguen hackear a Google Assistant, Alexa y Siri disparando con láseres a móviles y altavoces inteligentes
05 Nov 2019, 18:01 by Christian Collado
Un grupo de investigadores ha descubierto una vulnerabilidad en la gran mayoría de altavoces inteligentes, que permitiría a los atacantes hackear algunos de los principales asistentes virtuales tales como el Asistente de Google, Siri o Alexa de la manera más insólita posible: disparando láseres.
Utilizando este tipo de haces de luz, los investigadores fueron capaces de inyectar comandos en los dispositivos de manera inaudible, que una vez interpretados por los asistentes, desencadenaban acciones tales como abrir puertas de garaje, encender o apagar luces, e incluso desbloquear coches, todo ello a una distancia máxima de hasta 110 metros gracias al alcance de los láseres.
Light Commands: así pueden hackear tu altavoz inteligente con un láser



Al parecer, el ataque se aprovecha de una vulnerabilidad descubierta en los micrófonos integrados en los altavoces inteligentes. Éstos micrófonos utilizan sistemas micro-electromecánicos –conocidos como MEMS, por sus siglas en inglés–, que responden a la luz de una manera similar que si fuese sonido. Una vez descubierta la vulnerabilidad, el trabajo de los investigadores consistía en apuntar con el láser al micrófono del altavoz en cuestión, que interpretaría la luz como señales eléctricas, y actuaría en consecuencia detectando los “comandos de luz”.
Más llamativo aún es el hecho de que, para llevar a cabo el ataque, ni siquiera se requiere de un equipamiento costoso. Los investigadores fueron capaces de aprovecharse de la vulnerabilidad usando un puntero láser de poco menos de 6 euros, un amplificador de audio y un controlador de diodo láser de 300 euros. También es opcional el uso de un teleobjetivo, que permitiría apuntar el láser de una manera más precisa desde distancias lejanas.



Es conveniente destacar, además, que dado que los micrófonos de tipo MEMS son utilizados tanto en altavoces como en otros dispositivos electrónicos, los investigadores han descubierto que la mayoría de smartphones dotados de un asistente virtual también están expuestos a este tipo de ataques. No obstante, dado que algunos smartphones incluyen métodos de verificación de voz que determinan si el comando en cuestión proviene del usuario del dispositivo, aprovechar la vulnerabilidad en estos terminales no es tan sencillo como sí sucede en altavoces inteligentes del estilo deñ Google Nest Mini, que carece de cualquier tipo de sistema de verificación.
Desde Google aseguran estar analizando a fondo la investigación con el objetivo de encontrar una solución a este problema de seguridad. No obstante, los investigadores detrás de Light Command se muestran algo menos optimistas, y aseguran que dada la naturaleza de esta vulnerabilidad, no será fácil ponerle solución, y sugieren parches como obligar al usuario a pronunciar en voz alta un PIN numérico, además de recomendar a los fabricantes dotar a los futuros modelos de mecanismos de protección como micrófonos situados en partes opuestas del dispositivo, o algún tipo de “escudo” que evite la incidencia de luz en el micrófono.
Síguenos en Instagram Únete a nuestro canal de Telegram


",es,"











They manage to hack Google Assistant, Alexa and Siri by firing with lasers at mobiles and smart speakers
05 Nov 2019, 18:01 by Christian Collado
A group of researchers has discovered a vulnerability in the vast majority of smart speakers, which would allow attackers to hack some of the main virtual assistants such as Google Assistant, Siri or Alexa in the most unusual way possible: firing lasers.
Using this type of light beams, the researchers were able to inject commands into the devices in an inaudible way, which once interpreted by the attendees, triggered actions such as opening garage doors, turning on or off lights, and even unlocking cars, everything this at a maximum distance of up to 110 meters thanks to the range of lasers.
Light Commands: so you can hack your smart speaker with a laser



Apparently, the attack takes advantage of a vulnerability discovered in the microphones built into the smart speakers. These microphones use micro-electromechanical systems - known as MEMS, which respond to light in a similar way as if it were sound. Once the vulnerability was discovered, the researchers' job was to point the laser at the microphone of the speaker in question, which would interpret the light as electrical signals, and would act accordingly by detecting the “light commands”.
Even more striking is the fact that, in order to carry out the attack, expensive equipment is not even required. The researchers were able to exploit the vulnerability using a laser pointer of just under 6 euros, an audio amplifier and a laser diode controller of 300 euros. The use of a telephoto lens is also optional, which would allow the laser to be aimed more accurately from far distances.



It should also be noted that since MEMS microphones are used in both speakers and other electronic devices, researchers have discovered that most smartphones equipped with a virtual assistant are also exposed to such attacks. However, since some smartphones include voice verification methods that determine if the command in question comes from the user of the device, exploiting the vulnerability in these terminals is not as simple as it does in smart speakers like Google Nest Mini, which It lacks any type of verification system.
From Google they claim to be thoroughly analyzing the research with the aim of finding a solution to this security problem. However, the researchers behind Light Command are somewhat less optimistic, and say that given the nature of this vulnerability, it will not be easy to solve it, and they suggest patches such as forcing the user to pronounce a numerical PIN aloud, in addition to recommending manufacturers provide future models of protection mechanisms such as microphones located on opposite parts of the device, or some kind of ""shield"" that prevents the occurrence of light in the microphone.
Follow us on Instagram Join our Telegram channel


"
