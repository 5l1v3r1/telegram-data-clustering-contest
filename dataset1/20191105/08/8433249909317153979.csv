,src,lang,text
0,"











Forscher warnen
Hacker können smarte Geräte mit Laser kapern!

05 Nov 2019, 08:40


Es klingt wie Science-Fiction: Forscher aus Japan und den USA haben in einem Versuch herausgefunden, dass Laserstrahlen Sprachbefehle imitieren können. Hacker könnten das nutzen, um mit simplen Laserpointern smarte Geräte wie Google Home und Amazon Echo oder sogar Handys aus großer Entfernung zu steuern.

Erst vor wenigen Tagen war es Berliner Forschern gelungen, Smarthome-Geräte wie Amazon Echo und Google Home mit manipulierten Apps zu hacken (BILD berichtete).

Doch jetzt wird es noch wilder: Forscher der US-Universität von Michigan und der University of Electro-Communications in Japan haben herausgefunden, dass sich Geräte mit aktiviertem Sprachassistenten allein durch Laserlicht steuern lassen. Und das aus mehr als hundert Meter Entfernung – sogar durch geschlossene Fenster hindurch!




Gefährliche Lichtsgnale
▶︎ In der Studie mit dem Titel „Light Commands“ (deutsch: Lichtsignale) seien Geräte wie Google Home, Amazon Echo, Facebook Portal Mini, Fire Cube TV, iPhone XR, iPad (6. Generation), Samsung Galaxy S9 und Google Pixel 2 anfällig für den „Licht-Hack“ gewesen.

Die Forscher aus den USA und Japan richteten dazu verschieden starke Laser, darunter auch schwache Laserpointer und sogar Taschenlampen, auf die Mikrofone der Geräte und simulierten auf dieser Weise Sprachbefehle.


Irre: Die Forscher können auch nach sieben Monaten nicht genau erklären, warum das funktioniert! Sie wissen lediglich, dass die in den Geräten verbaute Technik ausgetrickst werden kann: Lichtsignale werden von den Mikrofonen als akustische Impulse fehlinterpretiert.


Den Forschern zufolge gelang es bei diesen Versuchen, Garagentore aus großer Distanz zu öffnen oder Google Home vom Dach eines gegenüberliegenden Gebäudes zu steuern. Es wäre ein Leichtes gewesen, so die Wissenschaftler, Lichter an – und auszuschalten, Online-Einkäufe zu tätigen oder sogar Türen zu öffnen, die digital versperrt seien.




Ungeahnte Schwachstellen

Dies sei laut Professor Kevin Fu von der Universität von Michigan nur„die Spitze des Eisbergs“ und öffne die Türen für „völlig neue Schwachstellen“. Es sei schwierig zu sagen, welche Produkte noch davon betroffen sein könnten, weil die [Schwachstelle] so grundlegend sei. Ihrer Meinung nach müssten die Mikrofone in betroffenen Geräten vollkommen umgestaltet werden – eine simple Abdeckung würde nicht ausreichen.

Unternehmen wie Amazon, Apple und Google seien auf die Sicherheitslücke aufmerksam gemacht worden – diese würden sich jetzt mit den Forschungsergebnissen beschäftigen.

Nutzer können sich vor solchem Missbrauch schützen, indem sie ihre Geräte nicht in Sichtweite von Fenstern aufstellen und wichtige Funktionen (z. B. Einkäufe) mit einer PIN absichern.



",de,"











Researchers warn
Hackers can hijack smart devices with lasers!

05 Nov 2019, 08:40


It sounds like science fiction: researchers from Japan and the US have found in an attempt that laser beams can mimic voice commands. Hackers could use this to control smart devices like Google Home and Amazon Echo or even cell phones from a distance with simple laser pointers.

Only a few days ago, Berlin researchers had succeeded in hacking smart home devices such as Amazon Echo and Google Home with manipulated apps (BILD reported).

But now it gets even wilder: researchers from the University of Michigan and the University of Electro-Communications in Japan have found that devices with activated speech assistants can be controlled by laser light alone. And more than a hundred meters away - even through closed windows!




Dangerous light signals
▶ ︎ In the study entitled ""Light Commands"" are devices such as Google Home, Amazon Echo, Facebook Portal Mini, Fire Cube TV, iPhone XR, iPad (6th Generation), Samsung Galaxy S9 and Google Pixel 2 have been prone to the ""light hack"".

The researchers from the USA and Japan turned variously powerful lasers, including weak laser pointers and even flashlights, on the microphones of the devices and thus simulated voice commands.


Funky: The researchers can not explain exactly why this works even after seven months! They only know that the technology used in the devices can be tricked out: light signals are misinterpreted by the microphones as acoustic impulses.


The researchers said they were able to open garage doors from a distance or steer Google Home from the roof of an opposite building. It would have been easy, scientists said, to turn lights on and off, make purchases online, or even open doors that are digitally locked.




Unexpected weaknesses

According to Professor Kevin Fu of the University of Michigan, this is just ""the tip of the iceberg"" and opens the door to ""completely new vulnerabilities"". It was difficult to say which products could still be affected because the [weak point] was so fundamental. In their opinion, the microphones in affected devices would have to be completely redesigned - a simple cover would not be enough.

Companies such as Amazon, Apple and Google have been made aware of the vulnerability - these would now deal with the research results.

Users can protect themselves against such abuse by not placing their devices within sight of windows and by securing important functions (eg purchases) with a PIN.



"
