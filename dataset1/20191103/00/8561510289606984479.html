<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <meta property="og:url" content="https://futurism.com/the-byte/ai-draws-decodes-brainwaves"/>
    <meta property="og:site_name" content="Futurism"/>
    <meta property="article:published_time" content="2019-11-03T00:00:00+00:00"/>
    <meta property="og:title" content="This AI Decodes Your Brainwaves and Draws What You’re Looking at"/>
    <meta property="og:description" content="Russian researchers have created an AI that analyzes electroencephalography data and draws what a person is looking at in real time."/>
  </head>
  <body>
    <article>
      <h1>This AI Decodes Your Brainwaves and Draws What You’re Looking at</h1>
      <address><time datetime="2019-11-03T00:00:00+00:00">03 Nov 2019</time> by <a rel="author">Kristin Houser</a></address>
      <p>Researchers have created an AI that draws what a person in looking at in real time just by reading and decoding their brain waves. Perhaps most impressive of all, the technique is noninvasive, with all the brainwave information gathered through a cyberpunk-looking, electrode-covered electroencephalography (EEG) headset.</p>
      <p>“Researchers used to think that studying brain processes via EEG is like figuring out the internal structure of a steam engine by analyzing the smoke left behind by a steam train,” researcher Grigory Rashkov said in a <a href="https://mipt.ru/english/news/neural_network_reconstructs_human_thoughts_from_brain_waves_in_real_time">press release</a>. “We did not expect that it contains sufficient information to even partially reconstruct an image observed by a person. Yet it turned out to be quite possible.”</p>
      <figure>
        <iframe src="https://www.youtube.com/embed/nf-P3b2AnZw" width="640" height="360" data-service="Youtube" scrolling="no"/>
      </figure>
      <p>The team, from the Moscow Institute of Physics and Technology and Russian corporation Neurobotics, started their <a href="https://www.biorxiv.org/content/10.1101/787101v2.full">study</a> — available on the preprint server <i>bioRxiv</i> — by placing a cap of electrodes on participants’ scalps so that they could record their brain waves.</p>
      <p>They then had each participant watch 20 minutes worth of 10-second-long video fragments. The subject of each fragment fell into one of five categories, and the researchers found they could tell which category of video a participant was watching just by looking at their EEG data.</p>
      <p>For the next phase of the research, the scientists developed two neural networks. They trained one to generate images in three of the tested categories from visual “noise,” and the other to turn EEG data into comparable noise. When paired together, the AIs were able to draw surprisingly accurate images of what a person was looking at solely from their real-time EEG data.</p>
      <p>“Under present-day technology, the invasive neural interfaces envisioned by Elon Musk face the challenges of complex surgery and rapid deterioration due to natural processes — they oxidize and fail within several months,” Rashkov said. “We hope we can eventually design more affordable neural interfaces that do not require implantation.”</p>
      <p><b>READ MORE:</b> <a href="https://mipt.ru/english/news/neural_network_reconstructs_human_thoughts_from_brain_waves_in_real_time">Neural network reconstructs human ‘thoughts’ from brain waves in real time</a> [Moscow Institute of Physics and Technology]</p>
      <p><b>More on AI:</b> <i><a href="https://futurism.com/mind-reading-ai">What Are YOU Looking At? Mind-Reading AI Knows</a></i></p>
    </article>
  </body>
</html>