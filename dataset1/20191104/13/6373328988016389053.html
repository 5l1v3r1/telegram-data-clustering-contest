<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <meta property="og:url" content="https://www.unilad.co.uk/technology/china-is-now-using-emotion-recognition-to-predict-and-identify-criminals/"/>
    <meta property="og:site_name" content="UNILAD"/>
    <meta property="article:published_time" content="2019-11-04T13:05:34+00:00"/>
    <meta property="og:title" content="China Is Now Using Emotion Recognition To Predict And Identify Criminals"/>
    <meta property="og:description" content="At a recent expo in China, surveillance companies revealed new technology designed to recognise emotions and predict criminal behaviour."/>
  </head>
  <body>
    <article>
      <h1>China Is Now Using Emotion Recognition To Predict And Identify Criminals</h1>
      <address><time datetime="2019-11-04T13:05:34+00:00">04 Nov 2019, 13:05</time> by <a rel="author" href="https://www.unilad.co.uk/author/ebrown/" target="_blank">Emily Brown</a></address>
      <p>
        <b>Anyone who has resting b*tch face might be in trouble – China is now using emotion recognition to predict and identify criminal behaviour. </b>
      </p>
      <p>Imagine if you’d had a bad day at work, or a passing driver splashed you with a puddle and you just couldn’t contain your anger. Getting labelled as suspicious by the government after that certainly wouldn’t be the cherry on top of your day.</p>
      <p>China often appears to be ahead of the game however, and apparently they do consider emotion recognition to be a valid way to predict criminal activity.</p>
      <figure>
        <img src="https://www.unilad.co.uk/wp-content/uploads/2019/11/cctv-1144366_1920.jpg"/>
        <figcaption>
          <cite>Pixabay</cite>
        </figcaption>
      </figure>
      <p>The news comes from <i><a href="https://www.ft.com/content/68155560-fbd1-11e9-a354-36acbbb0d9b6?sharetype=blocked">Financial Times</a></i> correspondent Sue-Lin Wong, who recently attended China’s largest surveillance tech expo, held once every two years in Shenzhen.</p>
      <p>
        <b>In a thread on Twitter, Wong spoke about the new system the country is rolling out, writing:</b>
      </p>
      <blockquote>A policing expert and party cadre from Xinjiang’s public security bureau told us they have started using emotion recognition to identity criminal suspects.</blockquote>
      <p>Emotion recognition systems work by identifying signs of aggressiveness and nervousness, as well as stress levels and a person’s potential to attack others.</p>
      <figure>
        <iframe data-src="https://twitter.com/suelinwong/status/1190194643226333184?ref_src=twsrc%5Etfw" data-embed-type="twitter-tweet" width="100%" height="0" data-service="Twitter" scrolling="no" nowide=""/>
      </figure>
      <p>However, the reliability of the system is questionable as individuals wear their emotions differently, and practised criminals may have become better at hiding their feelings.</p>
      <p>Representatives from internet company Baidu and software company Megvii reportedly told Wong the technology is being used by the government in public security bureaus and schools, though they admitted it ‘still doesn’t work very well.’</p>
      <figure>
        <iframe data-src="https://twitter.com/suelinwong/status/1190194661324836864?ref_src=twsrc%5Etfw" data-embed-type="twitter-tweet" width="100%" height="0" data-service="Twitter" scrolling="no" nowide=""/>
      </figure>
      <p>China is apparently not the only country testing out emotion recognition capabilities, as companies including Google and Microsoft are also working on the technology, <a href="https://technode.com/2019/11/04/china-emotion-monitoring-surveillance/"><i>Technode</i></a> reports. In the UK, however, there is concern about getting a proper legal framework in place for the use of live facial recognition.</p>
      <p>The Information Commissioner’s Office, a data protection watchdog, has urged police in the UK to hold back the use of live facial recognition use in public places until the government provides new legal guidance for the technology.</p>
      <figure>
        <img src="https://www.unilad.co.uk/wp-content/uploads/2019/11/eye-2771174_1920.jpg"/>
        <figcaption>
          <cite>Pixabay</cite>
        </figcaption>
      </figure>
      <p>Recent analysis by <i><a href="https://www.comparitech.com/vpn-privacy/the-worlds-most-surveilled-cities/">Comparitech</a></i> found eight out of the top 10 most surveilled cities are in China, with London and Atlanta, Georgia being the only exceptions.</p>
      <p>The report noted China is projected to have one public CCTV camera for every two people by 2022.</p>
      <p>While suspicions of FBI workers monitoring our phones are unfounded, having cameras monitor our every move in public is a very real and unnerving likelihood in the coming years.</p>
      <figure>
        <img src="https://www.unilad.co.uk/wp-content/uploads/2019/04/Emily-Brown-Sml-140x140.png"/>
      </figure>
      <p>
        <a href="https://www.unilad.co.uk/author/ebrown/">Emily Brown</a>
      </p>
      <p>Emily Brown first began delivering important news stories aged just 13, when she launched her career with a paper round. She graduated with a BA Hons in English Language in the Media from Lancaster University, and went on to become a freelance writer and blogger. Emily contributed to The Sunday Times Travel Magazine and Student Problems before becoming a journalist at UNILAD, where she works on breaking news as well as longer form features.</p>
      <footer><b>Credits<br/></b>  1. Financial Times<br/><a href="https://www.ft.com/content/464ce520-fcd4-11e9-98fd-4d6c20050229">Emotion recognition and cyber insecurities<br/></a>  2. Sue-Lin Wong/Twitter<br/><a href="https://twitter.com/suelinwong/status/1190194643226333184">@suelinwong<br/></a>  3. Comparitech<br/><a href="https://www.comparitech.com/vpn-privacy/the-worlds-most-surveilled-cities/">The world’s most-surveilled cities<br/></a>  4. Technode<br/><a href="https://technode.com/2019/11/04/china-emotion-monitoring-surveillance/">China is testing emotion recognition in surveillance push</a></footer>
    </article>
  </body>
</html>