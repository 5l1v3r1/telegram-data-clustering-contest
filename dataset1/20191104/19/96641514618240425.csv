,src,lang,text
0,"











Adobe, Twitter and the New York Times team up to fight digital fakes
They're working on a standard that gives credit to the original creators.
04 Nov 2019, 19:34 by Jon Fingas
Adobe, Twitter and the New York Times are tired of seeing fake media propagate, and they're teaming up to do something about it. The trio has launched a Content Authenticity Initiative that aims to create a standard for digital media attribution. Ideally, you'd know whether or not a picture or video is legitimate simply by examining the file -- you'd know if it had been manipulated.
The approach so far would include an optional Adobe system that lets both creators and publishers attach secure attribution info to whatever content they share. Producers would get credit, while everyday users would have an ""attribution trail"" tracing media back to its source. The current prototype sat within (what else?) Photoshop, but a standard by its nature could bring this technology to any creative app.
The Initiative won't officially start until there's a summit (potentially with more companies involved) in the ""coming months."" There are still questions to be answered in the meantime. How will the Initiative prevent forgeries of attribution info? Just which formats will get support? And will there be any costs for implementing this, potentially limiting it to major creative apps like Adobe's? If this is truly a universal standard, though, it may be easier to catch deepfakes and other attempts at misleading the public.
Source: Adobe Newsroom


",en,"











Adobe, Twitter and the New York Times team up to fight digital fakes
They're working on a standard that gives credit to the original creators.
04 Nov 2019, 19:34 by Jon Fingas
Adobe, Twitter and the New York Times are tired of seeing fake media propagate, and they're teaming up to do something about it. The trio has launched a Content Authenticity Initiative that aims to create a standard for digital media attribution. Ideally, you'd know whether or not a picture or video is legitimate simply by examining the file -- you'd know if it had been manipulated.
The approach so far would include an optional Adobe system that lets both creators and publishers attach secure attribution info to whatever content they share. Producers would get credit, while everyday users would have an ""attribution trail"" tracing media back to its source. The current prototype sat within (what else?) Photoshop, but a standard by its nature could bring this technology to any creative app.
The Initiative won't officially start until there's a summit (potentially with more companies involved) in the ""coming months."" There are still questions to be answered in the meantime. How will the Initiative prevent forgeries of attribution info? Just which formats will get support? And will there be any costs for implementing this, potentially limiting it to major creative apps like Adobe's? If this is truly a universal standard, though, it may be easier to catch deepfakes and other attempts at misleading the public.
Source: Adobe Newsroom


"
