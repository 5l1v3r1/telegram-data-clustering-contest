,src,lang,text
0,"











AI Altered Video Is A Threat To Society. How Do We Stop The Harm Deepfakes Can Cause?
01 Nov 2019 by Robert Anzalone


Kathryn Harrison of DeepTrust AllianceProvided by Kathryn Harrison

I was horrified when I understood the risks of deepfakes. The problem is becoming harder to stop.I interviewed Kathryn Harrison of DeepTrust Alliance, which is building open source tools leveraging smart contracts and blockchain technology to tackle the problem. 
Kathryn Harrison is the founder of the DeepTrust Alliance.  Ms. Harrison is an entrepreneur who spent nearly a decade at IBM, most recently leading product management at IBM Blockchain. She is now pivoting to tackle societal challenges.  Ms. Harrison discussed with me the technology and the threats associated with deepfakes.  Fake videos are just one problem in a web of misinformation.  There are many challenges.

What does deepfake mean?

Deepfake video is a technique that superimposes a manufactured image over a real source image to create a new synthetic model.  The fake model can perform and say anything the creator desires.  Deepfakes can be better defined as fraudulently authored material.  They are one of many elements in misinformation campaigns, both in the form of media and other sources, to fool the public.  Created by machine learning and artificial intelligence methods, deepfakes can be hard to identify.  They have been getting better at fooling the public into thinking they are real.  Public deceptions weaken society’s ability to govern itself.  Our objectivity could be altered by incorrect information.  
One Amsterdam based company called Deeptrace Labs proposes a deep learning online monitoring system for the detection of synthetic media. Deeptrace published a report on the problem in September 2019.  The report stated Deeptrace’s mission is to protect individuals and organizations from the damaging impacts of AI-generated synthetic media.  The information for this interview was based on my conversation with Ms. Harrison, the Deeptrace report, and other public information sources.
Deeptrace Labs’ report, “The State Of Deepfakes”, states the majority of AI-generated videos are pornographic, where celebrity faces are imposed on the authentic images.  Fake porn mainly targets female actors. 
Ms. Harrison commented, “The trend, however, is increasingly attempting to influence political campaigns and public opinion.”
Ms. Harrison commented, “The trend, however, is increasingly attempting to influence political campaigns and public opinion.”
Deepfakes, or altered video, is only one tool exploited by misinformation campaigns. A misinformation campaign generates a combination of content and behaviors working to change the targeted audience's perception of reality.  Ms. Harrison told me, misinformation campaign goals are broader than video.  For example, she pointed out:

The current Facebook Transparency Report stated that 2.2 billion fake Facebook accounts were removed between January 2019 to March 2019, “due to an increase in automated scripted attacks.”
The average person cannot identify 40% of deepfakes videos.
More than 3.6 trillion YouTube views per year are from fake video sources.

There are several companies interested in how content creators can source and track their content. Blockchain and cryptography could be used to confirm identity.  Some notable enterprise examples are Streambed and Trupic.  Ms. Harrison pointed out that DeepTrust Alliance counts Michael Casey of Streambed as one of their advisors. How Ms. Harrison wants to solve the problem goes beyond one product or tool.  
Ms. Harrison is convening a unique group, working with political, business, and technology leaders to create a series of open-source solutions.
Ms. Harrison continued,  “Today’s efforts to tackle the problem of deepfakes and misinformation are siloed and fractured. Each company is trying to solve the problem for their platforms and use-cases. But no single entity owns the end to end life cycle of digital content. For this ecosystem to be effective, it must drive both technical and societal solutions.  For example, you take a photo on your iPhone, edit it with Photoshop, post it to Facebook, then it goes viral on Twitter and proceeds to ricochet around the internet like a pinball. Not to mention the various cloud infrastructure players who create, host, store, deliver, and protect your content. It takes an extensive ecosystem to put in place the guardrails to begin to tackle these challenges.”
Other companies like Serelay, Zerofox, and Amber all have different approaches to identify unauthentic and synthetic content.  However, there are not many forensic solutions for finding and stopping fake videos. 
While deepfake video is one use-case, the problem of digital forgeries goes much deeper.
What about phony twitter accounts?
What about other public information sources? 
The societal challenges are complex. 
While several prominent fake videos, including Jordan Peele’s Obama deepfake and this summer’s cheap fake of Nancy Pelosi, have been widely circulated, the full scope of the risks and potential impacts of synthetic media are still emerging.  Universities are studying the problem across different disciplines and societal perspectives. Notably, Berkman Klein, the Shorestien Center, and the Belfer Center are three separate Harvard institutions dedicated to the problem.  Academic research has pursued the implications across technical, legal, political, sociological, and psychological impacts.  However, it seems that the rate of change and evolution of misinformation efforts can mutate quickly.  The spread of false information is difficult to stop.
Ms. Harrison feels it is essential to work across disciplines and industries to be effective. 

What is the full harm to society?

Ms. Harrison points out, “The technology that enables deepfakes offers an incredible opportunity to enhance and transform how humans communicate through video.  However, the ethical dilemmas created by nefarious actors have significant consequences for an open and democratic society. There are essential standards that need to be set at both technical and business levels to mitigate the risks, especially as we see these threats already spilling over from media and politics into banking, insurance, and telecom.”
Ms. Harrison sees her vision as unique and needed to get ahead of the problem by joining different groups together.  She pointed out, “The DeepTrust Alliance is building both the solutions and the ecosystem to tackle misinformation at scale. Unlike academic or purely commercial approaches, DeepTrust can drive an ecosystem approach to create innovative solutions.”
I asked Ms. Harrison why private enterprise cannot do this without groups or standards? Can the market solve this without regulatory control?  She said, “Technology must be built on open standards and done in an open way to gain internet-scale adoption.  The broader developer community is unlikely to adopt purely proprietary solutions.”
DeepTrust Alliance is hosting sessions in New York and Washington D.C. with senior executives to discuss and understand these problems and potential solutions. Ms. Harrison said, “There is no silver bullet for overcoming misinformation. The only successful approach will be a combination of technical and societal solutions that tackle where the technology comes from, how it is made, and how it is received and distributed by human beings.”


",en,"











AI Altered Video Is A Threat To Society. How Do We Stop The Harm Deepfakes Can Cause?
01 Nov 2019 by Robert Anzalone


Kathryn Harrison of DeepTrust AllianceProvided by Kathryn Harrison

I was horrified when I understood the risks of deepfakes. The problem is becoming harder to stop.I interviewed Kathryn Harrison of DeepTrust Alliance, which is building open source tools leveraging smart contracts and blockchain technology to tackle the problem. 
Kathryn Harrison is the founder of the DeepTrust Alliance.  Ms. Harrison is an entrepreneur who spent nearly a decade at IBM, most recently leading product management at IBM Blockchain. She is now pivoting to tackle societal challenges.  Ms. Harrison discussed with me the technology and the threats associated with deepfakes.  Fake videos are just one problem in a web of misinformation.  There are many challenges.

What does deepfake mean?

Deepfake video is a technique that superimposes a manufactured image over a real source image to create a new synthetic model.  The fake model can perform and say anything the creator desires.  Deepfakes can be better defined as fraudulently authored material.  They are one of many elements in misinformation campaigns, both in the form of media and other sources, to fool the public.  Created by machine learning and artificial intelligence methods, deepfakes can be hard to identify.  They have been getting better at fooling the public into thinking they are real.  Public deceptions weaken society’s ability to govern itself.  Our objectivity could be altered by incorrect information.  
One Amsterdam based company called Deeptrace Labs proposes a deep learning online monitoring system for the detection of synthetic media. Deeptrace published a report on the problem in September 2019.  The report stated Deeptrace’s mission is to protect individuals and organizations from the damaging impacts of AI-generated synthetic media.  The information for this interview was based on my conversation with Ms. Harrison, the Deeptrace report, and other public information sources.
Deeptrace Labs’ report, “The State Of Deepfakes”, states the majority of AI-generated videos are pornographic, where celebrity faces are imposed on the authentic images.  Fake porn mainly targets female actors. 
Ms. Harrison commented, “The trend, however, is increasingly attempting to influence political campaigns and public opinion.”
Ms. Harrison commented, “The trend, however, is increasingly attempting to influence political campaigns and public opinion.”
Deepfakes, or altered video, is only one tool exploited by misinformation campaigns. A misinformation campaign generates a combination of content and behaviors working to change the targeted audience's perception of reality.  Ms. Harrison told me, misinformation campaign goals are broader than video.  For example, she pointed out:

The current Facebook Transparency Report stated that 2.2 billion fake Facebook accounts were removed between January 2019 to March 2019, “due to an increase in automated scripted attacks.”
The average person cannot identify 40% of deepfakes videos.
More than 3.6 trillion YouTube views per year are from fake video sources.

There are several companies interested in how content creators can source and track their content. Blockchain and cryptography could be used to confirm identity.  Some notable enterprise examples are Streambed and Trupic.  Ms. Harrison pointed out that DeepTrust Alliance counts Michael Casey of Streambed as one of their advisors. How Ms. Harrison wants to solve the problem goes beyond one product or tool.  
Ms. Harrison is convening a unique group, working with political, business, and technology leaders to create a series of open-source solutions.
Ms. Harrison continued,  “Today’s efforts to tackle the problem of deepfakes and misinformation are siloed and fractured. Each company is trying to solve the problem for their platforms and use-cases. But no single entity owns the end to end life cycle of digital content. For this ecosystem to be effective, it must drive both technical and societal solutions.  For example, you take a photo on your iPhone, edit it with Photoshop, post it to Facebook, then it goes viral on Twitter and proceeds to ricochet around the internet like a pinball. Not to mention the various cloud infrastructure players who create, host, store, deliver, and protect your content. It takes an extensive ecosystem to put in place the guardrails to begin to tackle these challenges.”
Other companies like Serelay, Zerofox, and Amber all have different approaches to identify unauthentic and synthetic content.  However, there are not many forensic solutions for finding and stopping fake videos. 
While deepfake video is one use-case, the problem of digital forgeries goes much deeper.
What about phony twitter accounts?
What about other public information sources? 
The societal challenges are complex. 
While several prominent fake videos, including Jordan Peele’s Obama deepfake and this summer’s cheap fake of Nancy Pelosi, have been widely circulated, the full scope of the risks and potential impacts of synthetic media are still emerging.  Universities are studying the problem across different disciplines and societal perspectives. Notably, Berkman Klein, the Shorestien Center, and the Belfer Center are three separate Harvard institutions dedicated to the problem.  Academic research has pursued the implications across technical, legal, political, sociological, and psychological impacts.  However, it seems that the rate of change and evolution of misinformation efforts can mutate quickly.  The spread of false information is difficult to stop.
Ms. Harrison feels it is essential to work across disciplines and industries to be effective. 

What is the full harm to society?

Ms. Harrison points out, “The technology that enables deepfakes offers an incredible opportunity to enhance and transform how humans communicate through video.  However, the ethical dilemmas created by nefarious actors have significant consequences for an open and democratic society. There are essential standards that need to be set at both technical and business levels to mitigate the risks, especially as we see these threats already spilling over from media and politics into banking, insurance, and telecom.”
Ms. Harrison sees her vision as unique and needed to get ahead of the problem by joining different groups together.  She pointed out, “The DeepTrust Alliance is building both the solutions and the ecosystem to tackle misinformation at scale. Unlike academic or purely commercial approaches, DeepTrust can drive an ecosystem approach to create innovative solutions.”
I asked Ms. Harrison why private enterprise cannot do this without groups or standards? Can the market solve this without regulatory control?  She said, “Technology must be built on open standards and done in an open way to gain internet-scale adoption.  The broader developer community is unlikely to adopt purely proprietary solutions.”
DeepTrust Alliance is hosting sessions in New York and Washington D.C. with senior executives to discuss and understand these problems and potential solutions. Ms. Harrison said, “There is no silver bullet for overcoming misinformation. The only successful approach will be a combination of technical and societal solutions that tackle where the technology comes from, how it is made, and how it is received and distributed by human beings.”


"
