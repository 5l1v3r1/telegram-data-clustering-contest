,src,lang,text
0,"











Cómo la inteligencia artificial podría destruirnos por accidente
01 Nov 2019, 10:36 by BBC

Desde Stephen Hawking hasta Elon Musk, algunas de las mentes más importantes del mundo de la inteligencia artificial (IA) han expresado su preocupación de que esta represente una amenaza existencial para nuestra especie.

Pero según un nuevo libro, lo que debe preocuparnos no es que los robots tomen conciencia de sí mismos y se alcen contra sus amos humanos, sino que las máquinas se vuelvan tan buenas en la consecución de los objetivos que les fijamos, que terminemos siendo aniquilados inadvertidamente al establecerles tareas equivocadas.
Stuart Russell, profesor en la Universidad de California en Berkeley, es el autor de Human Compatible: AI and the Problem of Control (""Compatible con humanos: la IA y el problema del control"") y un experto en los avances que el aprendizaje automático ha hecho posibles.
""El meme de Hollywood siempre consiste en la máquina que espontáneamente toma conciencia de sí misma y luego decide que odia a los seres humanos y quiere matarnos a todos"", dijo a la BBC.
Pero los robots no tienen sentimientos humanos, por lo que ""es completamente equivocado preocuparse por eso"".
""No es realmente la conciencia maligna, sino su capacidad la que tiene que preocuparnos, solo su capacidad de alcanzar un objetivo mal especificado por nosotros"".
""Demasiado competente""En una entrevista con el programa Today de la BBC, el experto dio un ejemplo hipotético de la amenaza real que, en su opinión, la IA podría representar.
Imagina que tenemos un poderoso sistema de IA que es capaz de controlar el clima del planeta y que queremos usarlo para devolver los niveles de CO2 en nuestra atmósfera a la época preindustrial.
""El sistema descubre que la forma más fácil de hacerlo es deshacerse de todos los seres humanos, porque ellos son los que están produciendo todo este dióxido de carbono en primer lugar"", dijo Russell.
""Y podrías decir, bueno, puedes hacer lo que quieras, pero no puedes deshacerte de los seres humanos. Entonces ¿qué hace el sistema? Simplemente nos convence de tener menos hijos hasta que no queden seres humanos"".
El ejemplo sirve para resaltar los riesgos asociados a que la inteligencia artificial actúe bajo instrucciones en las que los humanos no hemos pensado.
SuperinteligenciaLa mayoría de los sistemas actuales de IA tienen aplicaciones ""débiles"", diseñadas específicamente para abordar un problema bien especificado en un área, según el Centro para el Estudio del Riesgo Existencial, de la Universidad de Cambridge, en Reino Unido.
Un momento importante para este campo llegó en 1997, cuando la computadora Deep Blue derrotó al campeón mundial de ajedrez, Garry Kasparov, en un torneo de seis partidas.
Pero a pesar de la hazaña, Deep Blue fue diseñado por humanos específicamente para jugar al ajedrez y no podría con un simple juego de damas.
Ese no es el caso de los avances posteriores en inteligencia artificial. El software AlphaGo Zero, por ejemplo, alcanzó un nivel de rendimiento sobrehumano después de solo tres días de jugar Go contra sí mismo.
Usando el aprendizaje profundo, un método de aprendizaje automático que emplea redes neuronales artificiales, AlphaGo Zero requirió mucha menos programación humana y resultó ser un muy buen jugador de Go, ajedrez y shōgi.
Fue completamente autodidacta, de una manera, tal vez, alarmante.
""A medida que un sistema de inteligencia artificial se vuelva más poderoso y más general, podría volverse súper inteligente, superior al rendimiento humano en muchos o casi todos los dominios"", dice el Centro de Riesgo Existencial.
Y es por eso que, según Russell, los humanos necesitamos retomar el control.
""No sabemos lo que queremos""Según Russell, dar a la inteligencia artificial objetivos más definidos no es la solución para este dilema, porque los humanos mismos no estamos seguros de cuáles son esas metas.
""No sabemos que algo no nos gusta hasta que sucede"", dice.
""Deberíamos cambiar toda la base sobre la cual construimos sistemas de IA"", dice, alejándose de la noción de dar a los robots objetivos fijos.
""En cambio, el sistema tiene que saber que desconoce cuál es el objetivo"".
""Y una vez que tienes sistemas que funcionan de esa manera, realmente serán diferentes a los seres humanos. Comenzarán a pedir permiso antes de hacer las cosas, porque no estarán seguros de si eso es lo que quieres"".
En especial, dice el profesor Russell, estarían ""felices de que los apaguen porque querrán evitar hacer cosas que no te vayan a gustar"".
El genio de la lámpara""La forma en que construimos la IA es un poco como la forma en que pensamos en un genio dentro de una lámpara. Si frotas la lámpara, sale el genio y dices: 'Me gustaría que esto sucediera'"", dijo Russell.
""Y, si el sistema de IA es lo suficientemente potente, hará exactamente lo que pides y obtendrás exactamente lo que pides"".
""Ahora, el problema con los genios en las lámparas es que el tercer deseo es siempre: 'Por favor, deshaga los dos primeros deseos porque no pudimos especificar los objetivos correctamente"".
""Entonces, una máquina que persigue un objetivo que no es el correcto se convierte, en efecto, en un enemigo de la raza humana, un enemigo que es mucho más poderoso que nosotros"".


",es,"











How artificial intelligence could destroy us by accident
01 Nov 2019, 10:36 by BBC

From Stephen Hawking to Elon Musk, some of the most important minds in the world of artificial intelligence (AI) have expressed concern that it represents an existential threat to our species.

But according to a new book, what should concern us is not that robots become aware of themselves and rise up against their human masters, but that the machines become so good in achieving the objectives we set for them, that we end up being annihilated inadvertently to set them wrong tasks.
Stuart Russell, a professor at the University of California at Berkeley, is the author of Human Compatible: AI and the Problem of Control (""Compatible with humans: AI and the problem of control"") and an expert on advances that machine learning It has made possible.
""The Hollywood meme always consists of the machine that spontaneously becomes aware of itself and then decides that it hates human beings and wants to kill us all,"" he told the BBC.
But robots have no human feelings, so ""it is completely wrong to worry about that.""
""It is not really the evil conscience, but its capacity that has to worry us, only its capacity to reach a goal badly specified by us.""
""Too competent"" In an interview with the BBC's Today program, the expert gave a hypothetical example of the real threat that, in his opinion, AI could represent.
Imagine that we have a powerful AI system that is capable of controlling the planet's climate and that we want to use it to return CO2 levels in our atmosphere to the pre-industrial era.
""The system discovers that the easiest way to do this is to get rid of all human beings, because they are the ones who are producing all this carbon dioxide in the first place,"" Russell said.
""And you could say, well, you can do whatever you want, but you can't get rid of human beings. So what does the system do? It just convinces us to have fewer children until there are no human beings left.""
The example serves to highlight the risks associated with artificial intelligence acting under instructions in which humans have not thought.
Superintelligence Most current AI systems have ""weak"" applications, specifically designed to address a well-specified problem in an area, according to the Center for the Study of Existential Risk, at the University of Cambridge, in the United Kingdom.
An important moment for this field came in 1997, when the Deep Blue computer defeated the world chess champion, Garry Kasparov, in a six-game tournament.
But despite the feat, Deep Blue was designed by humans specifically to play chess and could not with a simple game of checkers.
That is not the case with subsequent advances in artificial intelligence. AlphaGo Zero software, for example, reached a superhuman performance level after only three days of playing Go against itself.
Using deep learning, a machine learning method that employs artificial neural networks, AlphaGo Zero required much less human programming and proved to be a very good Go, chess and shōgi player.
It was completely self-taught, in a way, perhaps, alarming.
""As an artificial intelligence system becomes more powerful and more general, it could become super intelligent, superior to human performance in many or almost all domains,"" says the Existential Risk Center.
And that is why, according to Russell, we humans need to regain control.
""We don't know what we want"" According to Russell, giving artificial intelligence more defined goals is not the solution to this dilemma, because humans themselves are not sure what those goals are.
""We don't know that we don't like something until it happens,"" he says.
""We should change the entire base on which we build AI systems,"" he says, moving away from the notion of giving fixed target robots.
""Instead, the system has to know that it doesn't know what the objective is.""
""And once you have systems that work that way, they will really be different from human beings. They will start asking for permission before doing things, because they won't be sure if that's what you want.""
Especially, says Professor Russell, they would be ""happy to be turned off because they want to avoid doing things that you don't like.""
The genie of the lamp ""The way we build AI is a bit like the way we think of a genie inside a lamp. If you rub the lamp, the genie comes out and you say, 'I would like this to happen'"", said Russell.
""And, if the AI system is powerful enough, it will do exactly what you ask for and you will get exactly what you ask.""
""Now, the problem with the geniuses in the lamps is that the third wish is always: 'Please undo the first two wishes because we could not specify the objectives correctly.""
""Then, a machine that pursues an objective that is not the right one becomes, in effect, an enemy of the human race, an enemy that is much more powerful than us.""


"
