<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <meta property="og:url" content="https://www.heise.de/security/meldung/Sicherheitsforscher-befehligen-Alexa-Siri-Co-via-Laserstrahl-4579025.html"/>
    <meta property="og:site_name" content="Security"/>
    <meta property="article:published_time" content="2019-11-06T10:44:00+00:00"/>
    <meta property="og:title" content="Sicherheitsforscher befehligen Alexa, Siri &amp; Co. via Laserstrahl"/>
    <meta property="og:description" content="Angreifer könnten unter Umständen Sprachassistenten in einem Lichtstrahl codierte Befehle unterschieben und so etwa ein smartes Türschloss öffnen."/>
  </head>
  <body>
    <article>
      <h1>Sicherheitsforscher befehligen Alexa, Siri &amp; Co. via Laserstrahl</h1>
      <h2>Angreifer könnten unter Umständen Sprachassistenten in einem Lichtstrahl codierte Befehle unterschieben und so etwa ein smartes Türschloss öffnen.</h2>
      <address><time datetime="2019-11-06T10:44:00+00:00">06 Nov 2019, 10:44</time> by <a rel="author">Dennis Schirrmacher</a></address>
      <p>Die Sprachassistenzsysteme von unter anderem Amazon, Apple und Google sind für Attacken mit einem Laserstrahl anfällig. Dabei könnten Angreifer beispielsweise smarte Lautsprecher und Smartphones ins Visier nehmen und mit einem Lichtstrahl die Ausführung von Befehlen anstoßen.</p>
      <p>Klappt das, könnten sie so eventuell in ein <a href="https://www.heise.de/thema/Smart-Home">Smart Home</a> eingebundene Geräte steuern und Haustüren oder Garagentore öffnen. Attacken klappen aber nur, wenn die Geräte in Sichtweite sind und eine bestimmte Entfernung nicht überschritten wird.</p>
      <h3>Licht statt Sprache</h3>
      <p><a href="https://lightcommands.com/20191104-Light-Commands.pdf">In einer Abhandlung zeigen Sicherheitsforscher der University of Michigan und der japanischen University of Electro-Communications</a>, wie das aus 75 Metern Entfernung durch ein Fenster geklappt hat. Unter Laborbedingen ist ihnen das maximal aus einer Entfernung von 110 Metern gelungen. Voraussetzung für eine erfolgreiche Übermittlung ist, dass der Laserstrahl direkt auf das Mikrofon zielt.</p>
      <figure>
        <img src="https://www.heise.de/imgs/18/2/7/8/3/3/5/5/cheap_setup-d0f8d62a83c3eff6.png"/>
        <figcaption>In ihren Tests haben die Sicherheitsforscher auf Equipment im Wert von rund 500 Euro gesetzt.<cite>(Bild: <a href="https://lightcommands.com/">lightcommands.com/</a> )</cite></figcaption>
      </figure>
      <p>Mikrofone setzen aufgenommene Töne in elektrische Signale um. Die Sicherheitsforscher haben nun herausgefunden, dass man elektrische Signale in einen Lichtstrahl modulieren kann und damit das Mikrofon so anregen kann, als würde es einen Sprachbefehl bekommen. Dafür haben sie eigenen Angaben zufolge Equipment für rund 500 Euro benötigt.</p>
      <p>Den Sicherheitsforschern zufolge ist die Prüfung, ob ein Sprachbefehl von einem registrierten Nutzer stammt, bei smarten Lautsprechern standardmäßig nicht aktiv. Beim Großteil von Smartphones und Tablets sei das wiederum der Fall. So könnten potenzielle Angreifer smarte Lautsprecher attackieren, ohne die Stimme des Besitzers imitieren zu müssen. Weiterhin schreiben sie, dass man Wake-up-Befehle wie "Hey Siri" und die Spracherkennung für Befehle des Besitzers unter Umständen auch umgehen konnte.</p>
      <h3>Populäre Geräte anfällig</h3>
      <p><a href="https://lightcommands.com/">Auf einer Website zu ihren Ergebnissen listen die Sicherheitsforscher verschiedene Geräte auf</a>, mit denen sie ihre Laser-Attacke erfolgreich getestet haben. Darunter befinden sich beispielsweise die smarten Lautsprecher Amazon Echo, Google Home und die Smartphones iPhone XR und Samsung Galaxy S9. Auf der Seite findet man auch Angaben zur nötigen Leistung eines Laserstrahls und der maximalen Entfernungen für erfolgreiche Attacken.</p>
      <figure>
        <iframe src="https://www.youtube.com/embed/EtzP-mCwNAs" width="640" height="360" data-service="Youtube" scrolling="no"/>
        <figcaption>In einem Versuch übermitteln die Sicherheitsforscher den Befehl zum Öffnen eines Garagentors, indem sie mit einem Laserstrahl von einem Gebäude durch das Fensters eines anderen Gebäudes auf einen smarten Lautsprecher zielen.</figcaption>
      </figure>
      <h3>Angriffe möglich, aber eher unwahrscheinlich</h3>
      <p>Die Sicherheitsforscher gehen davon aus, dass alle Geräte betroffen sind, die auf sogenannte MEMS-Mikrofone (microelectro-mechanical systems) setzen. Schützen kann man sich vor solchen Laser-Attacken nur schwer. Bislang gehen die Forscher davon aus, dass es keine Angriffe dieser Art gegeben hat. Es ist eher unwahrscheinlich, dass ein Angreifer den smarten Lautsprecher im eigenen Schlafzimmer ins Visier nimmt.</p>
      <p>Um dem Angriffsszenario entgegenzuwirken, empfehlen sie Herstellern, weitere Authentifizierungsschichten zu implementieren. Beispielsweise könnte ein Gerät einem Nutzer eine individuelle Frage stellen. Außerdem könnten Hersteller die MEMS-Mikrofone mit Schutzbarrieren umhüllen, um Lichtstrahlen abzuhalten. Auf der Gegenseite könnten Angreifer aber dann die Leistung eines Laserstrahls erhöhen. (<a href="mailto:des@heise.de">des</a>)</p>
    </article>
  </body>
</html>