<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <meta property="og:url" content="https://multiplayer.it/notizie/amazon-alexa-apple-siri-google-assistant-possono-essere-hackerati-con-laser.html"/>
    <meta property="og:site_name" content="Multiplayer.it"/>
    <meta property="article:published_time" content="2019-11-06T00:00:00+00:00"/>
    <meta property="og:title" content="Amazon Alexa, Apple Siri e Google Assistant possono essere hackerate con un laser"/>
    <meta property="og:description" content="A quanto pare hackerare Amazon Alexa, Apple Siri e Google Assistant è davvero molto facile e basta l'utilizzo di un laser per farcela.. A quanto pare gli assistenti vocali come Alexa di Amazon, Si..."/>
  </head>
  <body>
    <article>
      <h1>Amazon Alexa, Apple Siri e Google Assistant possono essere hackerate con un laser</h1>
      <h2>A quanto pare hackerare Amazon Alexa, Apple Siri e Google Assistant è davvero molto facile e basta l'utilizzo di un laser per farcela.</h2>
      <address><time datetime="2019-11-06T00:00:00+00:00">06 Nov 2019</time> by <a rel="author" href="https://multiplayer.it/account/utente/57/karattolo/articoli/" target="_blank">Simone Tagliaferri</a></address>
      <p>A quanto pare gli assistenti vocali come <b>Alexa </b>di Amazon, <b>Siri </b>di Apple e <b>Google Assistant</b> sono facilissimi da hackerare. Per farlo basta puntare un laser sui loro microfoni, stando a un team di ricercatori dell'University of Electro-Communications di Tokyo e dell'University of Michigan.<br/><br/>L'hack si chiama Light Commands e consente agli aggressori di dare <b>comandi invisibili</b> a distanza agli <b>assistenti vocali</b>. Puntando e modulando un <b>laser </b>sui microfoni MEMS (Microelectro-Mechanical Systems) i ricercatori hanno scoperto di poter dare comandi agli assistenti vocali usando la luce come se fosse suono.<br/><br/>Gli autori dello studio hanno verificato di poter prendere il controllo di assistenti vocali posizionati a 110m di distanza dal laser, ma non si esclude che si possa fare anche da una distanza maggiore. In questo modo hanno dimostrato che in questi apparecchi l'autenticazione degli utenti è inesistente: chiunque può dargli ordini. Immaginate di aver collegato i sistemi di sicurezza della vostra abitazione a un assistente smart e capirete quale sia il pericolo di questa mancanza di controllo. <br/><br/>La ricerca è stata condivisa con le compagnie <a href="https://multiplayer.it/notizie/amazon-vendita-prodotti-nintendo-terze-parti-autorizzati-limitazioni-usato.html">Amazon</a>, <a href="https://multiplayer.it/notizie/apple-valve-insieme-per-nuovo-visore-ar.html">Apple</a>, <a href="https://multiplayer.it/notizie/google-pixel-4-xl-scocca-non-regge-test-jerryrig-ecco-video.html">Google</a>, Tesla e Ford e con gli enti ICS-CERT e FDA, con cui è stata concordata la pubblicazione per il 4 novembre 2019.</p>
      <figure>
        <img src="https://multiplayer.net-cdn.it/thumbs/images/2019/10/24/amazon-echo-header_jpg_1400x0_q85.jpg"/>
      </figure>
      <ul>
        <li>
          <a href="https://www.foxnews.com/tech/amazon-alexa-apple-siri-google-assistant-hack-lasers">Fonte</a>
        </li>
      </ul>
    </article>
  </body>
</html>