<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <meta property="og:url" content="https://www.heise.de/newsticker/meldung/Unesco-Direktorin-fordert-Gender-neutrale-Sprachassistenten-4579808.html"/>
    <meta property="og:site_name" content="heise online"/>
    <meta property="article:published_time" content="2019-11-06T15:16:00+00:00"/>
    <meta property="og:title" content="Unesco-Direktorin fordert Gender-neutrale Sprachassistenten"/>
    <meta property="og:description" content="Alexa, Siri &amp; Co. würden maßgeblich das Frauenbild ihrer Nutzer beeinflussen. Ihre Rollenbilder müssten deshalb überarbeitet und die Stimmen entgendert werden."/>
  </head>
  <body>
    <article>
      <h1>Unesco-Direktorin fordert Gender-neutrale Sprachassistenten</h1>
      <h2>Alexa, Siri &amp; Co. würden maßgeblich das Frauenbild ihrer Nutzer beeinflussen. Ihre Rollenbilder müssten deshalb überarbeitet und die Stimmen entgendert werden.</h2>
      <address><time datetime="2019-11-06T15:16:00+00:00">06 Nov 2019, 15:16</time> by <a rel="author">Hartmut Gieselmann</a></address>
      <p>"Ist Siri sexistisch?" Diese Frage sollte Saniye Gülser Corat, Direktorin für geschlechtliche Gleichstellung der Unesco auf dem Web Summit in Lissabon beantworten. Das Problem sei, meint Corat, dass die Mehrzahl der Sprachassistenten, die den Befehlen des Nutzers gehorchen und seine Befehle ausführen, in der Grundeinstellung weibliche Stimmen haben.</p>
      <p>Andere Assistenten, die dem Nutzer Anweisungen geben, beispielsweise in Navigations-Diensten, würden hingegen mehrheitlich mit männlichen Stimmen sprechen. "Anweisungen werden eher befolgt, wenn sie von einem Mann gegeben werden", erklärt Corat die Präferenzen der Hersteller. Männer würden so als Entscheidungsträger dargestellt und Frauen zu Befehlsempfängern degradiert.</p>
      <p>Allerdings gäbe es kulturelle Unterschiede: <a href="https://www.heise.de/thema/Siri">Apples Sprachassistentin Siri</a> habe in den Voreinstellungen in den meisten Ländern eine weibliche Stimme. In arabischen Ländern, Großbritannien, Frankreich und den Niederlanden spreche Siri hingegen in den Voreinstellungen mit einer Männerstimme.</p>
      <h3>Stimme mit Persönlichkeit</h3>
      <p>Doch die Assistenten seien nicht nur eine Stimme, die Hersteller würden um diese herum eine komplette Persönlichkeit entwerfen. Auf die Frage "Siri, wie schwer bist du?" antworte die KI "So leicht wie eine Wolke", und würde so das körperliche Idealbild verbreiten, das Frauen schlank zu sein haben.</p>
      <p>Der Einfluss der Assistenten werde in den kommenden Jahren steigen. In wenigen Jahren, so prophezeit Corat, würden Nutzer mehr mit ihren Sprachassistenten sprechen als mit ihrem Lebenspartner. Dazu passt die Ankündigung von Amazons Vizepräsident Rohit Prasad, die <a href="https://www.heise.de/thema/Amazon-Alexa">Sprachassistentin Alexa</a> möglichst jedem Menschen auf dem Planeten kostenlos zugänglich zu machen.</p>
      <h3>Synthetische Stimmen ohne Geschlecht</h3>
      <p>Corat betonte, dass Kinder und Jugendliche besonders stark beeinflussbar seien. Wenn diese mit Sprachassistenten sozialisiert würden, präge dies maßgeblich ihr Rollenbild von Männern und Frauen.</p>
      <p>Corat forderte die Hersteller deshalb dazu auf, die Assistenten mit synthetischen Stimmen auszustatten, denen kein spezifisches Geschlecht zugeordnet werden könne. Derartige Stimmen seien inzwischen bereits verfügbar, sodass Firmen sie ohne weiteres einsetzen könnten. (<a href="mailto:emw@heise.de">emw</a>)</p>
    </article>
  </body>
</html>