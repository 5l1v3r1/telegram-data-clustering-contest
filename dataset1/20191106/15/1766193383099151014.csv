,src,lang,text
0,"











Unesco-Direktorin fordert Gender-neutrale Sprachassistenten
Alexa, Siri & Co. würden maßgeblich das Frauenbild ihrer Nutzer beeinflussen. Ihre Rollenbilder müssten deshalb überarbeitet und die Stimmen entgendert werden.
06 Nov 2019, 15:16 by Hartmut Gieselmann
""Ist Siri sexistisch?"" Diese Frage sollte Saniye Gülser Corat, Direktorin für geschlechtliche Gleichstellung der Unesco auf dem Web Summit in Lissabon beantworten. Das Problem sei, meint Corat, dass die Mehrzahl der Sprachassistenten, die den Befehlen des Nutzers gehorchen und seine Befehle ausführen, in der Grundeinstellung weibliche Stimmen haben.
Andere Assistenten, die dem Nutzer Anweisungen geben, beispielsweise in Navigations-Diensten, würden hingegen mehrheitlich mit männlichen Stimmen sprechen. ""Anweisungen werden eher befolgt, wenn sie von einem Mann gegeben werden"", erklärt Corat die Präferenzen der Hersteller. Männer würden so als Entscheidungsträger dargestellt und Frauen zu Befehlsempfängern degradiert.
Allerdings gäbe es kulturelle Unterschiede: Apples Sprachassistentin Siri habe in den Voreinstellungen in den meisten Ländern eine weibliche Stimme. In arabischen Ländern, Großbritannien, Frankreich und den Niederlanden spreche Siri hingegen in den Voreinstellungen mit einer Männerstimme.
Stimme mit Persönlichkeit
Doch die Assistenten seien nicht nur eine Stimme, die Hersteller würden um diese herum eine komplette Persönlichkeit entwerfen. Auf die Frage ""Siri, wie schwer bist du?"" antworte die KI ""So leicht wie eine Wolke"", und würde so das körperliche Idealbild verbreiten, das Frauen schlank zu sein haben.
Der Einfluss der Assistenten werde in den kommenden Jahren steigen. In wenigen Jahren, so prophezeit Corat, würden Nutzer mehr mit ihren Sprachassistenten sprechen als mit ihrem Lebenspartner. Dazu passt die Ankündigung von Amazons Vizepräsident Rohit Prasad, die Sprachassistentin Alexa möglichst jedem Menschen auf dem Planeten kostenlos zugänglich zu machen.
Synthetische Stimmen ohne Geschlecht
Corat betonte, dass Kinder und Jugendliche besonders stark beeinflussbar seien. Wenn diese mit Sprachassistenten sozialisiert würden, präge dies maßgeblich ihr Rollenbild von Männern und Frauen.
Corat forderte die Hersteller deshalb dazu auf, die Assistenten mit synthetischen Stimmen auszustatten, denen kein spezifisches Geschlecht zugeordnet werden könne. Derartige Stimmen seien inzwischen bereits verfügbar, sodass Firmen sie ohne weiteres einsetzen könnten. (emw)


",de,"











UNESCO director calls for gender-neutral language assistants
Alexa, Siri & Co. would significantly influence the image of women of their users. Their roles should therefore be revised and the voices are demerged.
06 Nov 2019, 15:16 by Hartmut Gieselmann
""Is Siri sexist?"" This question should be answered by Saniye Gülser Corat, Director of Gender Equality at UNESCO's Web Summit in Lisbon. The problem, Corat says, is that the majority of language assistants who obey the user's commands and execute his orders have female voices by default.
Other assistants who give instructions to the user, for example in navigation services, would on the other hand speak for the most part with male voices. ""Instructions are more likely to be followed when given by a man,"" explains Corat's manufacturers' preferences. Men would be portrayed as decision makers and women would be degraded to command receivers.
However, there are cultural differences: Apple's voice assistant Siri has a female voice in the presets in most countries. In Arabic countries, the United Kingdom, France and the Netherlands Siri speak in the presets with a male voice.
Voice with personality
But the assistants are not just a voice, the manufacturers would design a complete personality around them. When asked, ""Siri, how hard are you?"" The AI answers ""As light as a cloud"", thus spreading the ideal body image that women need to be slim.
The influence of the assistants will increase in the coming years. In a few years, Corat predicts that users would talk more to their language assistants than to their life partner. This is in line with the announcement by Amazon's Vice President Rohit Prasad to make language assistant Alexa available to anyone on the planet for free.
Synthetic voices without gender
Corat emphasized that children and adolescents are particularly strongly influenced. If these were socialized with language assistants, this decisively shapes their role model of men and women.
Corat therefore called on the manufacturers to provide the assistants with synthetic voices that could not be assigned a specific gender. Such voices are now already available, so that companies could easily use them. (EMW)


"
