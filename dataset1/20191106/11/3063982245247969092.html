<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <meta property="og:url" content="https://www.golem.de/news/ermittlungsberichte-wie-die-uber-software-den-toedlichen-unfall-beguenstigte-1911-144832.html"/>
    <meta property="og:site_name" content="Golem.de"/>
    <meta property="article:published_time" content="2019-11-06T11:30:01+00:00"/>
    <meta property="og:title" content="Wie die Uber-Software den tödlichen Unfall begünstigte"/>
    <meta property="og:description" content="Neue Unterlagen geben detailliert Auskunft über die Ursachen des tödlichen Unfalls mit einem selbstfahrenden Uber-Auto. Der Taxidienst will die Software inzwischen verändert"/>
  </head>
  <body>
    <article>
      <h1>Wie die Uber-Software den tödlichen Unfall begünstigte</h1>
      <h2>Neue Unterlagen geben detailliert Auskunft über die Ursachen des tödlichen Unfalls mit einem selbstfahrenden <a href="https://www.golem.de/specials/uber/">Uber</a>-Auto. Der Taxidienst will die Software inzwischen verändert haben.</h2>
      <address><time datetime="2019-11-06T11:30:01+00:00">06 Nov 2019, 11:30</time> by <a rel="author">Friedhelm Greis</a></address>
      <p>Falsche Objekterkennung und unzureichende Trajektorienplanung der Software sowie die Unaufmerksamkeit der Testfahrerin haben im Wesentlichen zu dem tödlichen Unfall mit einem selbstfahrenden Uber-Auto beigetragen. Das geht aus Berichten hervor, die die US-Verkehrssicherheitsbehörde NTSB <a href="https://dms.ntsb.gov/pubdms/search/hitlist.cfm?docketID=62978&amp;CurrentPage=1&amp;EndRow=15&amp;StartRow=1&amp;order=1&amp;sort=0&amp;TXTSEARCHT=">am 5. November 2019 veröffentlicht hat</a>. Die 400-seitigen Unterlagen bestätigen die Ergebnisse <a href="https://www.golem.de/news/vorlaeufiger-bericht-softwarefehler-fuer-toedlichen-uber-unfall-mitverantwortlich-1805-134573.html">des vorläufigen Untersuchungsberichts vom Mai 2018</a>, wonach die Notbremsfunktion so programmiert war, trotz einer zu erwartenden Kollision zunächst nicht einzugreifen. Die NTSB will sich erst am 19. November 2019 final zu der Unfallursache äußern.</p>
      <p>Bei dem Unfall im März 2018 in Phoenix (Arizona) war ein Testfahrzeug vom Typ Volvo XC90 im nächtlichen Verkehr <a href="https://www.golem.de/news/uber-autonomes-auto-verletzt-fussgaengerin-toedlich-1803-133401.html">mit einer 49 Jahre alten Frau kollidiert</a>, die mit ihrem Fahrrad in der Dunkelheit eine vierspurige Straße überquerte. Anschließend hatte das Unternehmen sein Testprogramm <a href="https://www.golem.de/news/nach-toedlichem-unfall-uber-stoppt-dauerhaft-testfahrten-in-arizona-1805-134554.html">mit autonomen Autos dauerhaft gestoppt</a>, der Gouverneur von Arizona hatte die Testautos in seinem Bundesstaat stillgelegt.</p>
      <h4>Nicht als Fußgängerin erkannt</h4>
      <p><a href="https://dms.ntsb.gov/pubdms/search/document.cfm?docID=477717&amp;docketID=62978&amp;mkey=96894">Ein 16-seitiger Bericht</a> zur damals eingesetzten Automatisierungstechnik bestätigt nun bisherige Ergebnisse, wonach die Radar- und Lidarsensoren des Autos die Frau schon 5,6 beziehungsweise 5,2 Sekunden vor der Kollision wahrgenommen hatten. Allerdings zeigt die Auswertung der Fahrzeugdaten, dass beide Sensorsysteme aufgrund der besonderen Silhouette der Frau mit ihrem Fahrrad nicht in der Lage waren, ihr ein konstantes Objekt zuzuweisen und sie als Fußgängerin zu erkennen.</p>
      <p>Dem Bericht zufolge unterscheidet die Software zwischen den vier Objekttypen Fahrzeug, Fahrradfahrer, Fußgänger und andere (unbekannt). Aus den Daten geht hervor, dass das Radar die Frau anfangs als Fahrzeug identifizierte. Der Lidar klassifizierte sie zunächst als <i>"andere"</i>, schwankte dann zwischen Fahrzeug und <i>"andere"</i>, um sie dann 2,6 Sekunden vor der Kollision als Fahrradfahrer zu identifizieren. Die Objektklassifizierung hat entscheidenden Einfluss auf den zu erwartenden Pfad, den das System für das Objekt berechnet.</p>
      <h4>Positionen wurden wieder verworfen</h4>
      <p>So geht das System nicht davon aus, dass Fußgänger die Fahrbahn außerhalb von Fußgängerüberwegen und Zebrastreifen kreuzen können (<a href="https://en.wikipedia.org/wiki/Jaywalking">Jaywalking</a>). Eine an sich sinnvolle Annahme, da sonst bei jedem Passanten, der an der Straße steht, gebremst werden müsste. Von Fußgängern kann jedoch eine Trajektorie berechnet werden, wenn diese kontinuierlich als Fußgänger erkannt wurden. Von Fahrradfahrern oder Fahrzeugen wiederum erwartet die Software, dass diese sich in Fahrtrichtung des eigenen Fahrzeugs bewegen, wenn diese auf der eigenen Spur erkannt werden.</p>
      <p>Bei der Pfadplanung spielen allerdings die vorher registrierten Positionen des Objekts eine Rolle. Daher sollte das System eigentlich erkennen können, wenn sich jemand quer zur Fahrbahn in Richtung der eigenen Fahrspur bewegt. Das Problem in diesem Fall: Jedes Mal, wenn die Software dem Objekt eine neue Klasse zuwies, wurde der Positionsverlauf des Objekts bei der Pfadplanung nicht mehr berücksichtigt. Unbekannte Objekte (<i>"andere"</i>) wurden zudem als unbeweglich eingestuft. Befand sich deren Position nicht auf dem eigenen Pfad, werden sie nicht als Hindernis eingeschätzt.</p>
      <h3>System verhindert Notbremsung</h3>
      <p>Noch 2,5 Sekunden vor dem Unfall identifizierte der Lidar die Frau als Fahrradfahrerin. Das System ging davon aus, dass sie ihren Weg auf der linken Geradeausspur fortsetzen und daher nicht mit dem Uber-Fahrzeug auf der rechten Geradeausspur kollidieren würde. Eine Sekunde später wurde aus dem Fahrrad wieder ein unbekanntes und damit statisches Objekt, der bisherige Positionsverlauf damit verworfen. Das System ging erstmals davon aus, dass sich dieses Objekt auf dem eigenen Pfad befinden würde und berechnete ein leichtes Ausweichmanöver.</p>
      <p>Die letzte Objektänderung erfolgte 1,2 Sekunden vor der Kollision: Der Lidar erkannte die Frau wieder als Fahrrad und berechnete einen Pfad, der zum Zusammenstoß führe würde. Das Ausweichmanöver wurde als zu gefährlich eingeschätzt. Doch anstatt eine Notbremsung einzuleiten, setzte nun eine <i>"Aktionsunterdrückung"</i> (<i>"action suppression"</i>) von einer Sekunde Dauer ein. In dieser Sekunde soll entweder das System den Notfall genauer analysieren und einen alternativen Pfad berechnen oder der Fahrer die Kontrolle übernehmen. Damit soll verhindert werden, dass es im Falle fehlerhaft erkannter Gefahrensituationen zu gefährlichen Fahr- und Bremsmanövern kommt.</p>
      <h4>Volvo-System war deaktiviert</h4>
      <p>Erst eine Sekunde nach der <i>"Aktionsunterdrückung"</i> startet das System eine Notbremsung mit der maximal erlaubten Verzögerung von 7 m/s(hoch 2), wenn dadurch eine Kollision noch verhindert werden kann. Falls nicht, wie im vorliegenden Fall, gibt es lediglich eine akustische Warnung an den Fahrer, während das Fahrzeug langsam gebremst wird. Erst 20 Millisekunden vor der Kollision übernahm die Testfahrerin bei einer Geschwindigkeit von 63 Kilometern pro Stunde das Steuer. Erst 0,7 Sekunden später trat die Fahrerin auf die Bremse.</p>
      <figure>
        <iframe src="https://www.youtube.com/embed/XtTB8hTgHbM" width="640" height="360" data-service="Youtube" scrolling="no"/>
      </figure>
      <p>Möglicherweise hätte auch das serienmäßige Notbremssystem von Volvo den Unfall verhindern könne. Doch das wurde in Absprache mit dem Fahrzeughersteller deaktiviert, wenn sich das Testauto im autonomen Modus befand. Ein Grund dafür war, dass die Bremsaktoren nicht darauf ausgelegt waren, eines der beiden Steuerungssysteme priorisieren zu können. Zudem sollten sich die Radarsignale der beiden Systeme nicht gegenseitig stören.</p>
      <h4>Software bereits angepasst</h4>
      <p>Der Bericht macht deutlich, dass das autonome Testsystem von Uber darauf ausgelegt war, ständig von einem Sicherheitsfahrer überwacht zu werden. Gerade in tatsächlichen oder vermeintlichen Gefahrensituationen sollte der menschliche Fahrer noch eingreifen können, bevor das System möglicherweise eine falsche Entscheidung trifft und dadurch den Verkehr gefährdet. Die Testfahrerin gab jedoch <a href="https://dms.ntsb.gov/pubdms/search/document.cfm?docID=477716&amp;docketID=62978&amp;mkey=96894">in einem vorläufigen Bericht</a> an, dass sie in den Sekunden vor dem Unfall den Monitor des autonomen Systems beobachtet habe. Ihre privaten und beruflichen Mobiltelefone habe sie nicht genutzt.</p>
      <p>Dem Bericht zufolge hat die Uber-Tochter ATG inzwischen die Software angepasst. So wurde die <i>"Aktionsunterdrückung"</i> deaktiviert. Die Fahrzeuge können nun Notbremsungen mit einem <a href="https://de.wikipedia.org/wiki/Ruck">Ruck</a> von bis zu 20 m/s(hoch3) einleiten. Die Pfadplanung berücksichtige jetzt den Positionsverlauf von Objekten auch dann, wenn sie anders klassifiziert würden. Auf Basis der Software-Änderungen habe eine Simulation im September 2018 ergeben, dass die Frau bereits 4,5 Sekunden vor der ursprünglichen Kollision korrekt als Fußgängerin erkannt und ein Pfad berechnet worden sei, der den des Testfahrzeugs kreuzen würde. Daher hätte das Auto bereits vier Sekunden vor dem möglichen Zusammenstoß eine kontrollierte Bremsung eingeleitet.</p>
      <p>Uber hatte mehrere Monate nach dem Unfall wieder <a href="https://www.golem.de/news/autonomes-fahren-ubers-autos-sind-wieder-im-einsatz-aber-nicht-autonom-1807-135676.html">seine Testfahrten aufgenommen</a>, allerdings nicht in Arizona, sondern unter modifizierten Bedingungen in Pittsburgh im US-Bundesstaat Pennsylvania. Für den Unfall muss das Unternehmen jedoch <a href="https://www.golem.de/news/autonomes-fahren-uber-entgeht-klage-nach-toedlichem-unfall-1903-139828.html">nicht strafrechtlich haften</a>. Allerdings könnte die Testfahrerin noch belangt werden.</p>
    </article>
  </body>
</html>