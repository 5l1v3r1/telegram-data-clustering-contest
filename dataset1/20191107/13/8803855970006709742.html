<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <meta property="og:url" content="https://lenta.ru/news/2019/11/07/techno/"/>
    <meta property="og:site_name" content="lenta.ru"/>
    <meta property="article:published_time" content="2019-11-07T13:21:00+00:00"/>
    <meta property="og:title" content="Скандальная технология из порно поможет мошенникам обокрасть банковских клиентов"/>
    <meta property="og:description" content="Эксперты в области защиты данных назвали технологию deepfake реальной угрозой для клиентов банков. Сотрудник компании Антон Фишман призвал пользователей не разговаривать по телефону ни с «сотрудниками банка», ни с теми, кто представляется специалистами страховых компаний или пенсионного фонда."/>
  </head>
  <body>
    <article>
      <h1>Скандальная технология из порно поможет мошенникам обокрасть банковских клиентов</h1>
      <address>
        <time datetime="2019-11-07T13:21:00+00:00">07 Nov 2019, 13:21</time>
      </address>
      <p>Эксперты в области защиты данных назвали технологию deepfake реальной угрозой для клиентов банков. Об этом сообщается в <a href="https://t.me/Group_IB/1315">Telegram</a>-канале компании Group-IB.</p>
      <p>Сотрудник компании Антон Фишман призвал пользователей не разговаривать по телефону ни с «сотрудниками банка», ни с теми, кто представляется специалистами страховых компаний или пенсионного фонда. Однако, по его мнению, возможность сделать «аудиослепок» с голоса клиента все еще остается мифом. Он уточнил, что система верификации включает не один параметр, поэтому подделать биометрическую информацию очень сложно.</p>
      <p>Так Фишман прокомментировал появляющиеся в сети публикации о том, что в разговоре с неизвестными нельзя кратко соглашаться или говорить фразы вроде «да, я подтверждаю».</p>
      <p>При этом важной проблемой, по мнению эксперта, стала технология deepfake, позволяющая обучать искусственный интеллект. Он привел в пример инцидент, произошедший в Германии: там мошенники, используя обученный механизм, от лица директора компании заставили представителей другой фирмы перевести на неизвестный счет 220 тысяч евро.</p>
      <p>В начале 2018 года алгоритм deepfake стал скандально известен в сети. Он позволил создавать фейковые видео и аудиозаписи: к примеру, в сети распространились фальшивые порноролики, где вместо лиц профессиональных актеров были подставлены лица знаменитостей. Администрация Reddit и ряд порнохостингов <a href="https://lenta.ru/news/2018/02/08/reddit/">заблокировали</a> все подобные видео, опасаясь юридических последствий. Тогда специалисты <a href="https://lenta.ru/news/2018/03/14/presidents/">предположили</a>, что фальшивые ролики с участием политиков могут стать причиной начала ядерной войны.</p>
      <p>
        <i>Что происходит в России и в мире? Объясняем на нашем <a href="https://www.youtube.com/channel/UCfqU-kKXq868D6d4fy8fhkA?sub_confirmation=1">YouTube-канале</a>. Подпишись!</i>
      </p>
    </article>
  </body>
</html>