,src,lang,text
0,"











Скандальная технология из порно поможет мошенникам обокрасть банковских клиентов

07 Nov 2019, 13:21

Эксперты в области защиты данных назвали технологию deepfake реальной угрозой для клиентов банков. Об этом сообщается в Telegram-канале компании Group-IB.
Сотрудник компании Антон Фишман призвал пользователей не разговаривать по телефону ни с «сотрудниками банка», ни с теми, кто представляется специалистами страховых компаний или пенсионного фонда. Однако, по его мнению, возможность сделать «аудиослепок» с голоса клиента все еще остается мифом. Он уточнил, что система верификации включает не один параметр, поэтому подделать биометрическую информацию очень сложно.
Так Фишман прокомментировал появляющиеся в сети публикации о том, что в разговоре с неизвестными нельзя кратко соглашаться или говорить фразы вроде «да, я подтверждаю».
При этом важной проблемой, по мнению эксперта, стала технология deepfake, позволяющая обучать искусственный интеллект. Он привел в пример инцидент, произошедший в Германии: там мошенники, используя обученный механизм, от лица директора компании заставили представителей другой фирмы перевести на неизвестный счет 220 тысяч евро.
В начале 2018 года алгоритм deepfake стал скандально известен в сети. Он позволил создавать фейковые видео и аудиозаписи: к примеру, в сети распространились фальшивые порноролики, где вместо лиц профессиональных актеров были подставлены лица знаменитостей. Администрация Reddit и ряд порнохостингов заблокировали все подобные видео, опасаясь юридических последствий. Тогда специалисты предположили, что фальшивые ролики с участием политиков могут стать причиной начала ядерной войны.

Что происходит в России и в мире? Объясняем на нашем YouTube-канале. Подпишись!



",ru,"











Scandalous technology from porn will help fraudsters rob bank customers

07 Nov 2019, 13:21

Data protection experts called deepfake technology a real threat to bank customers. This was reported in the Telegram channel of Group-IB.
An employee of the company, Anton Fishman, urged users not to talk on the phone either with “bank employees” or with those who appear to be specialists from insurance companies or a pension fund. However, in his opinion, the ability to make an “audio cast” from the client’s voice is still a myth. He clarified that the verification system includes more than one parameter, so it is very difficult to fake biometric information.
So Fishman commented on publications appearing on the network that in a conversation with unknown people you can’t briefly agree or say phrases like “yes, I confirm”.
An important problem, according to experts, was the deepfake technology, which allows you to train artificial intelligence. He cited an example of an incident in Germany: there, scammers, using a trained mechanism, on behalf of the director of a company forced representatives of another company to transfer 220 thousand euros to an unknown account.
At the beginning of 2018, the deepfake algorithm became notorious on the network. He allowed to create fake videos and audio recordings: for example, fake porn videos spread on the network, where instead of the faces of professional actors, the faces of celebrities were substituted. The administration of Reddit and a number of pornhostings blocked all such videos, fearing legal consequences. Then experts suggested that fake videos with the participation of politicians could cause the start of a nuclear war.

What is happening in Russia and in the world? We explain on our YouTube channel. Subscribe!



"
