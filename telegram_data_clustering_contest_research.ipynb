{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "telegram-data-clustering-contest-research.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzpKEZNL_4Rv",
        "colab_type": "code",
        "outputId": "bc43b3bb-251a-44bd-d131-9e49108591b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "!wget -c https://github.com/roman-rybalko/telegram-data-clustering-contest/archive/master.zip -O master.zip\n",
        "!unzip -u -q master.zip\n",
        "!rm -Rf dataset1\n",
        "!mv -v */dataset1 ./"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-16 16:23:02--  https://github.com/roman-rybalko/telegram-data-clustering-contest/archive/master.zip\n",
            "Resolving github.com (github.com)... 140.82.118.4\n",
            "Connecting to github.com (github.com)|140.82.118.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/roman-rybalko/telegram-data-clustering-contest/zip/master [following]\n",
            "--2019-11-16 16:23:02--  https://codeload.github.com/roman-rybalko/telegram-data-clustering-contest/zip/master\n",
            "Resolving codeload.github.com (codeload.github.com)... 140.82.114.10\n",
            "Connecting to codeload.github.com (codeload.github.com)|140.82.114.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘master.zip’\n",
            "\n",
            "master.zip              [               <=>  ] 337.40M  14.6MB/s    in 32s     \n",
            "\n",
            "2019-11-16 16:23:35 (10.5 MB/s) - ‘master.zip’ saved [353785379]\n",
            "\n",
            "mv: cannot move 'telegram-data-clustering-contest-master/dataset1' to './dataset1': Directory not empty\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGQ-X43gC_Ep",
        "colab_type": "code",
        "outputId": "65276627-a057-4c2c-b866-0dd825069403",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "!find dataset1 -type f | head"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dataset1/20191102/16/1037429654120765477.html\n",
            "dataset1/20191102/16/1263816344780377759.html\n",
            "dataset1/20191102/16/3042595687948748901.html\n",
            "dataset1/20191102/16/8375520248854020726.html\n",
            "dataset1/20191102/16/8372747778614806218.html\n",
            "dataset1/20191102/16/3523410129310862537.html\n",
            "dataset1/20191102/16/6727595481920649055.html\n",
            "dataset1/20191102/16/8971816786934843292.html\n",
            "dataset1/20191102/16/2164628922605825208.html\n",
            "dataset1/20191102/16/3092672153744428172.html\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqUaymW1EYbB",
        "colab_type": "code",
        "outputId": "2c3cb509-2699-4b3e-85b5-66670d362960",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "!cat dataset1/20191102/16/1037429654120765477.html"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<!DOCTYPE html>\n",
            "<html>\n",
            "  <head>\n",
            "    <meta charset=\"utf-8\"/>\n",
            "    <meta property=\"og:url\" content=\"https://www.oantagonista.com/mundo/china-lanca-maior-rede-5g-do-mundo/\"/>\n",
            "    <meta property=\"og:site_name\" content=\"O Antagonista\"/>\n",
            "    <meta property=\"article:published_time\" content=\"2019-11-02T16:58:32+00:00\"/>\n",
            "    <meta property=\"og:title\" content=\"China lança maior rede 5G do mundo\"/>\n",
            "    <meta property=\"og:description\" content=\"A China lançou nesta sexta-feira a maior rede 5G do mundo, segundo a CNN. As maiores operadoras chinesas já oferecem...\"/>\n",
            "  </head>\n",
            "  <body>\n",
            "    <article>\n",
            "      <h1>China lança maior rede 5G do mundo</h1>\n",
            "      <address>\n",
            "        <time datetime=\"2019-11-02T16:58:32+00:00\">02 Nov 2019, 16:58</time>\n",
            "      </address>\n",
            "      <p>A China lançou nesta sexta-feira a maior rede 5G do mundo, segundo a CNN.</p>\n",
            "      <p>As maiores operadoras chinesas já oferecem planos de internet ultrarrápida da quinta geração.</p>\n",
            "    </article>\n",
            "  </body>\n",
            "</html>"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CW1WmJL1CjQU",
        "colab_type": "code",
        "outputId": "e3eee6ae-200f-4e0d-bf1e-3755a76b08af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "with open('dataset1/20191102/16/1037429654120765477.html', 'r') as f:\n",
        "  text = BeautifulSoup(f, 'html.parser').get_text()\n",
        "text"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nChina lança maior rede 5G do mundo\\n\\n02 Nov 2019, 16:58\\n\\nA China lançou nesta sexta-feira a maior rede 5G do mundo, segundo a CNN.\\nAs maiores operadoras chinesas já oferecem planos de internet ultrarrápida da quinta geração.\\n\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8b8uOBFEh3Y",
        "colab_type": "code",
        "outputId": "b10ca60b-6e33-4d23-d711-6f1c2f8510ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        " import string\n",
        " string.punctuation"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7o4YT3fFxOA",
        "colab_type": "code",
        "outputId": "fd183013-9939-44ee-a7a8-d189cd9cf036",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "!pip install langdetect"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting langdetect\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/59/4bc44158a767a6d66de18c4136c8aa90491d56cc951c10b74dd1e13213c9/langdetect-1.0.7.zip (998kB)\n",
            "\r\u001b[K     |▎                               | 10kB 15.7MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 7.5MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 10.4MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 6.3MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 7.6MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 8.9MB/s eta 0:00:01\r\u001b[K     |██▎                             | 71kB 10.1MB/s eta 0:00:01\r\u001b[K     |██▋                             | 81kB 11.2MB/s eta 0:00:01\r\u001b[K     |███                             | 92kB 12.3MB/s eta 0:00:01\r\u001b[K     |███▎                            | 102kB 10.2MB/s eta 0:00:01\r\u001b[K     |███▋                            | 112kB 10.2MB/s eta 0:00:01\r\u001b[K     |████                            | 122kB 10.2MB/s eta 0:00:01\r\u001b[K     |████▎                           | 133kB 10.2MB/s eta 0:00:01\r\u001b[K     |████▋                           | 143kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████                           | 153kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 163kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 174kB 10.2MB/s eta 0:00:01\r\u001b[K     |██████                          | 184kB 10.2MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 194kB 10.2MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 204kB 10.2MB/s eta 0:00:01\r\u001b[K     |███████                         | 215kB 10.2MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 225kB 10.2MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 235kB 10.2MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 245kB 10.2MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 256kB 10.2MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 266kB 10.2MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 276kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 286kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 296kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 307kB 10.2MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 317kB 10.2MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 327kB 10.2MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 337kB 10.2MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 348kB 10.2MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 358kB 10.2MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 368kB 10.2MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 378kB 10.2MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 389kB 10.2MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 399kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 409kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 419kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 430kB 10.2MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 440kB 10.2MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 450kB 10.2MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 460kB 10.2MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 471kB 10.2MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 481kB 10.2MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 491kB 10.2MB/s eta 0:00:01\r\u001b[K     |████████████████                | 501kB 10.2MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 512kB 10.2MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 522kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 532kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 542kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 552kB 10.2MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 563kB 10.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 573kB 10.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 583kB 10.2MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 593kB 10.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 604kB 10.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 614kB 10.2MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 624kB 10.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 634kB 10.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 645kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 655kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 665kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 675kB 10.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 686kB 10.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 696kB 10.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 706kB 10.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 716kB 10.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 727kB 10.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 737kB 10.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 747kB 10.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 757kB 10.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 768kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 778kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 788kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 798kB 10.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 808kB 10.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 819kB 10.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 829kB 10.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 839kB 10.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 849kB 10.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 860kB 10.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 870kB 10.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 880kB 10.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 890kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 901kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 911kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 921kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 931kB 10.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 942kB 10.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 952kB 10.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 962kB 10.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 972kB 10.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 983kB 10.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 993kB 10.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.0MB 10.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from langdetect) (1.12.0)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.7-cp36-none-any.whl size=993460 sha256=41f2826a5cb0125dca08d0376b9e41e05eb0a3c27417199843c90fc1030d3479\n",
            "  Stored in directory: /root/.cache/pip/wheels/ec/0c/a9/1647275e7ef5014e7b83ff30105180e332867d65e7617ddafe\n",
            "Successfully built langdetect\n",
            "Installing collected packages: langdetect\n",
            "Successfully installed langdetect-1.0.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1staQniFut3",
        "colab_type": "code",
        "outputId": "0a35f156-54c7-46b6-c95c-1c6dc061dbd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        " from langdetect import detect\n",
        " lang = detect(text)\n",
        " lang"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'pt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92PAu9KWGQmZ",
        "colab_type": "code",
        "outputId": "7dbad6db-d305-4a42-da69-468593506486",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lyqlo9vDGmf6",
        "colab_type": "code",
        "outputId": "5d63be8b-d916-45b5-93bc-8680c2bc0f1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        }
      },
      "source": [
        "!ls -l /root/nltk_data/corpora/stopwords/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 112\n",
            "-rw-r--r-- 1 root root  1928 Nov 16 16:43 arabic\n",
            "-rw-r--r-- 1 root root   967 Nov 16 16:43 azerbaijani\n",
            "-rw-r--r-- 1 root root   424 Nov 16 16:43 danish\n",
            "-rw-r--r-- 1 root root   453 Nov 16 16:43 dutch\n",
            "-rw-r--r-- 1 root root   936 Nov 16 16:43 english\n",
            "-rw-r--r-- 1 root root  1579 Nov 16 16:43 finnish\n",
            "-rw-r--r-- 1 root root   813 Nov 16 16:43 french\n",
            "-rw-r--r-- 1 root root  1362 Nov 16 16:43 german\n",
            "-rw-r--r-- 1 root root  2167 Nov 16 16:43 greek\n",
            "-rw-r--r-- 1 root root  1227 Nov 16 16:43 hungarian\n",
            "-rw-r--r-- 1 root root  6446 Nov 16 16:43 indonesian\n",
            "-rw-r--r-- 1 root root  1654 Nov 16 16:43 italian\n",
            "-rw-r--r-- 1 root root  3880 Nov 16 16:43 kazakh\n",
            "-rw-r--r-- 1 root root  3610 Nov 16 16:43 nepali\n",
            "-rw-r--r-- 1 root root   851 Nov 16 16:43 norwegian\n",
            "-rw-r--r-- 1 root root  1270 Nov 16 16:43 portuguese\n",
            "-rw-r--r-- 1 root root   909 Nov 16 16:43 README\n",
            "-rw-r--r-- 1 root root  1910 Nov 16 16:43 romanian\n",
            "-rw-r--r-- 1 root root  1235 Nov 16 16:43 russian\n",
            "-rw-r--r-- 1 root root 15980 Nov 16 16:43 slovene\n",
            "-rw-r--r-- 1 root root  2176 Nov 16 16:43 spanish\n",
            "-rw-r--r-- 1 root root   559 Nov 16 16:43 swedish\n",
            "-rw-r--r-- 1 root root  1818 Nov 16 16:43 tajik\n",
            "-rw-r--r-- 1 root root   260 Nov 16 16:43 turkish\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cO6sYlvzF_gR",
        "colab_type": "code",
        "outputId": "d3afac46-4e53-4789-9057-2bddf357e07c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "stopwords.words('english')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7nwfi62HODZ",
        "colab_type": "code",
        "outputId": "e610678d-1e93-4162-e524-65e5507f17cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "!pip install pycountry"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pycountry\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/b6/154fe93072051d8ce7bf197690957b6d0ac9a21d51c9a1d05bd7c6fdb16f/pycountry-19.8.18.tar.gz (10.0MB)\n",
            "\u001b[K     |████████████████████████████████| 10.0MB 7.8MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pycountry\n",
            "  Building wheel for pycountry (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycountry: filename=pycountry-19.8.18-py2.py3-none-any.whl size=10627360 sha256=94b1d8b12accd9e67c5090ba1354f988cd3f1a312e4052ba00fc919891d73ec5\n",
            "  Stored in directory: /root/.cache/pip/wheels/a2/98/bf/f0fa1c6bf8cf2cbdb750d583f84be51c2cd8272460b8b36bd3\n",
            "Successfully built pycountry\n",
            "Installing collected packages: pycountry\n",
            "Successfully installed pycountry-19.8.18\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljJ2uOz1HMc2",
        "colab_type": "code",
        "outputId": "125e4396-2789-41ef-adfb-44fb630886f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from pycountry import languages\n",
        "lang2 = languages.get(alpha_2=lang).name.lower()\n",
        "lang2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'portuguese'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhvCKIBmIC2S",
        "colab_type": "code",
        "outputId": "253efe23-8e00-41a3-ea0d-348f1a09361d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "stopwords.words(lang2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['de',\n",
              " 'a',\n",
              " 'o',\n",
              " 'que',\n",
              " 'e',\n",
              " 'é',\n",
              " 'do',\n",
              " 'da',\n",
              " 'em',\n",
              " 'um',\n",
              " 'para',\n",
              " 'com',\n",
              " 'não',\n",
              " 'uma',\n",
              " 'os',\n",
              " 'no',\n",
              " 'se',\n",
              " 'na',\n",
              " 'por',\n",
              " 'mais',\n",
              " 'as',\n",
              " 'dos',\n",
              " 'como',\n",
              " 'mas',\n",
              " 'ao',\n",
              " 'ele',\n",
              " 'das',\n",
              " 'à',\n",
              " 'seu',\n",
              " 'sua',\n",
              " 'ou',\n",
              " 'quando',\n",
              " 'muito',\n",
              " 'nos',\n",
              " 'já',\n",
              " 'eu',\n",
              " 'também',\n",
              " 'só',\n",
              " 'pelo',\n",
              " 'pela',\n",
              " 'até',\n",
              " 'isso',\n",
              " 'ela',\n",
              " 'entre',\n",
              " 'depois',\n",
              " 'sem',\n",
              " 'mesmo',\n",
              " 'aos',\n",
              " 'seus',\n",
              " 'quem',\n",
              " 'nas',\n",
              " 'me',\n",
              " 'esse',\n",
              " 'eles',\n",
              " 'você',\n",
              " 'essa',\n",
              " 'num',\n",
              " 'nem',\n",
              " 'suas',\n",
              " 'meu',\n",
              " 'às',\n",
              " 'minha',\n",
              " 'numa',\n",
              " 'pelos',\n",
              " 'elas',\n",
              " 'qual',\n",
              " 'nós',\n",
              " 'lhe',\n",
              " 'deles',\n",
              " 'essas',\n",
              " 'esses',\n",
              " 'pelas',\n",
              " 'este',\n",
              " 'dele',\n",
              " 'tu',\n",
              " 'te',\n",
              " 'vocês',\n",
              " 'vos',\n",
              " 'lhes',\n",
              " 'meus',\n",
              " 'minhas',\n",
              " 'teu',\n",
              " 'tua',\n",
              " 'teus',\n",
              " 'tuas',\n",
              " 'nosso',\n",
              " 'nossa',\n",
              " 'nossos',\n",
              " 'nossas',\n",
              " 'dela',\n",
              " 'delas',\n",
              " 'esta',\n",
              " 'estes',\n",
              " 'estas',\n",
              " 'aquele',\n",
              " 'aquela',\n",
              " 'aqueles',\n",
              " 'aquelas',\n",
              " 'isto',\n",
              " 'aquilo',\n",
              " 'estou',\n",
              " 'está',\n",
              " 'estamos',\n",
              " 'estão',\n",
              " 'estive',\n",
              " 'esteve',\n",
              " 'estivemos',\n",
              " 'estiveram',\n",
              " 'estava',\n",
              " 'estávamos',\n",
              " 'estavam',\n",
              " 'estivera',\n",
              " 'estivéramos',\n",
              " 'esteja',\n",
              " 'estejamos',\n",
              " 'estejam',\n",
              " 'estivesse',\n",
              " 'estivéssemos',\n",
              " 'estivessem',\n",
              " 'estiver',\n",
              " 'estivermos',\n",
              " 'estiverem',\n",
              " 'hei',\n",
              " 'há',\n",
              " 'havemos',\n",
              " 'hão',\n",
              " 'houve',\n",
              " 'houvemos',\n",
              " 'houveram',\n",
              " 'houvera',\n",
              " 'houvéramos',\n",
              " 'haja',\n",
              " 'hajamos',\n",
              " 'hajam',\n",
              " 'houvesse',\n",
              " 'houvéssemos',\n",
              " 'houvessem',\n",
              " 'houver',\n",
              " 'houvermos',\n",
              " 'houverem',\n",
              " 'houverei',\n",
              " 'houverá',\n",
              " 'houveremos',\n",
              " 'houverão',\n",
              " 'houveria',\n",
              " 'houveríamos',\n",
              " 'houveriam',\n",
              " 'sou',\n",
              " 'somos',\n",
              " 'são',\n",
              " 'era',\n",
              " 'éramos',\n",
              " 'eram',\n",
              " 'fui',\n",
              " 'foi',\n",
              " 'fomos',\n",
              " 'foram',\n",
              " 'fora',\n",
              " 'fôramos',\n",
              " 'seja',\n",
              " 'sejamos',\n",
              " 'sejam',\n",
              " 'fosse',\n",
              " 'fôssemos',\n",
              " 'fossem',\n",
              " 'for',\n",
              " 'formos',\n",
              " 'forem',\n",
              " 'serei',\n",
              " 'será',\n",
              " 'seremos',\n",
              " 'serão',\n",
              " 'seria',\n",
              " 'seríamos',\n",
              " 'seriam',\n",
              " 'tenho',\n",
              " 'tem',\n",
              " 'temos',\n",
              " 'tém',\n",
              " 'tinha',\n",
              " 'tínhamos',\n",
              " 'tinham',\n",
              " 'tive',\n",
              " 'teve',\n",
              " 'tivemos',\n",
              " 'tiveram',\n",
              " 'tivera',\n",
              " 'tivéramos',\n",
              " 'tenha',\n",
              " 'tenhamos',\n",
              " 'tenham',\n",
              " 'tivesse',\n",
              " 'tivéssemos',\n",
              " 'tivessem',\n",
              " 'tiver',\n",
              " 'tivermos',\n",
              " 'tiverem',\n",
              " 'terei',\n",
              " 'terá',\n",
              " 'teremos',\n",
              " 'terão',\n",
              " 'teria',\n",
              " 'teríamos',\n",
              " 'teriam']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhmZcGpuIVdp",
        "colab_type": "code",
        "outputId": "1681742a-4332-4f8a-9bb7-75a5a7bbc1fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "stop = set(stopwords.words(lang2) + list(string.punctuation))\n",
        "stop"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'!',\n",
              " '\"',\n",
              " '#',\n",
              " '$',\n",
              " '%',\n",
              " '&',\n",
              " \"'\",\n",
              " '(',\n",
              " ')',\n",
              " '*',\n",
              " '+',\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '/',\n",
              " ':',\n",
              " ';',\n",
              " '<',\n",
              " '=',\n",
              " '>',\n",
              " '?',\n",
              " '@',\n",
              " '[',\n",
              " '\\\\',\n",
              " ']',\n",
              " '^',\n",
              " '_',\n",
              " '`',\n",
              " 'a',\n",
              " 'ao',\n",
              " 'aos',\n",
              " 'aquela',\n",
              " 'aquelas',\n",
              " 'aquele',\n",
              " 'aqueles',\n",
              " 'aquilo',\n",
              " 'as',\n",
              " 'até',\n",
              " 'com',\n",
              " 'como',\n",
              " 'da',\n",
              " 'das',\n",
              " 'de',\n",
              " 'dela',\n",
              " 'delas',\n",
              " 'dele',\n",
              " 'deles',\n",
              " 'depois',\n",
              " 'do',\n",
              " 'dos',\n",
              " 'e',\n",
              " 'ela',\n",
              " 'elas',\n",
              " 'ele',\n",
              " 'eles',\n",
              " 'em',\n",
              " 'entre',\n",
              " 'era',\n",
              " 'eram',\n",
              " 'essa',\n",
              " 'essas',\n",
              " 'esse',\n",
              " 'esses',\n",
              " 'esta',\n",
              " 'estamos',\n",
              " 'estas',\n",
              " 'estava',\n",
              " 'estavam',\n",
              " 'este',\n",
              " 'esteja',\n",
              " 'estejam',\n",
              " 'estejamos',\n",
              " 'estes',\n",
              " 'esteve',\n",
              " 'estive',\n",
              " 'estivemos',\n",
              " 'estiver',\n",
              " 'estivera',\n",
              " 'estiveram',\n",
              " 'estiverem',\n",
              " 'estivermos',\n",
              " 'estivesse',\n",
              " 'estivessem',\n",
              " 'estivéramos',\n",
              " 'estivéssemos',\n",
              " 'estou',\n",
              " 'está',\n",
              " 'estávamos',\n",
              " 'estão',\n",
              " 'eu',\n",
              " 'foi',\n",
              " 'fomos',\n",
              " 'for',\n",
              " 'fora',\n",
              " 'foram',\n",
              " 'forem',\n",
              " 'formos',\n",
              " 'fosse',\n",
              " 'fossem',\n",
              " 'fui',\n",
              " 'fôramos',\n",
              " 'fôssemos',\n",
              " 'haja',\n",
              " 'hajam',\n",
              " 'hajamos',\n",
              " 'havemos',\n",
              " 'hei',\n",
              " 'houve',\n",
              " 'houvemos',\n",
              " 'houver',\n",
              " 'houvera',\n",
              " 'houveram',\n",
              " 'houverei',\n",
              " 'houverem',\n",
              " 'houveremos',\n",
              " 'houveria',\n",
              " 'houveriam',\n",
              " 'houvermos',\n",
              " 'houverá',\n",
              " 'houverão',\n",
              " 'houveríamos',\n",
              " 'houvesse',\n",
              " 'houvessem',\n",
              " 'houvéramos',\n",
              " 'houvéssemos',\n",
              " 'há',\n",
              " 'hão',\n",
              " 'isso',\n",
              " 'isto',\n",
              " 'já',\n",
              " 'lhe',\n",
              " 'lhes',\n",
              " 'mais',\n",
              " 'mas',\n",
              " 'me',\n",
              " 'mesmo',\n",
              " 'meu',\n",
              " 'meus',\n",
              " 'minha',\n",
              " 'minhas',\n",
              " 'muito',\n",
              " 'na',\n",
              " 'nas',\n",
              " 'nem',\n",
              " 'no',\n",
              " 'nos',\n",
              " 'nossa',\n",
              " 'nossas',\n",
              " 'nosso',\n",
              " 'nossos',\n",
              " 'num',\n",
              " 'numa',\n",
              " 'não',\n",
              " 'nós',\n",
              " 'o',\n",
              " 'os',\n",
              " 'ou',\n",
              " 'para',\n",
              " 'pela',\n",
              " 'pelas',\n",
              " 'pelo',\n",
              " 'pelos',\n",
              " 'por',\n",
              " 'qual',\n",
              " 'quando',\n",
              " 'que',\n",
              " 'quem',\n",
              " 'se',\n",
              " 'seja',\n",
              " 'sejam',\n",
              " 'sejamos',\n",
              " 'sem',\n",
              " 'serei',\n",
              " 'seremos',\n",
              " 'seria',\n",
              " 'seriam',\n",
              " 'será',\n",
              " 'serão',\n",
              " 'seríamos',\n",
              " 'seu',\n",
              " 'seus',\n",
              " 'somos',\n",
              " 'sou',\n",
              " 'sua',\n",
              " 'suas',\n",
              " 'são',\n",
              " 'só',\n",
              " 'também',\n",
              " 'te',\n",
              " 'tem',\n",
              " 'temos',\n",
              " 'tenha',\n",
              " 'tenham',\n",
              " 'tenhamos',\n",
              " 'tenho',\n",
              " 'terei',\n",
              " 'teremos',\n",
              " 'teria',\n",
              " 'teriam',\n",
              " 'terá',\n",
              " 'terão',\n",
              " 'teríamos',\n",
              " 'teu',\n",
              " 'teus',\n",
              " 'teve',\n",
              " 'tinha',\n",
              " 'tinham',\n",
              " 'tive',\n",
              " 'tivemos',\n",
              " 'tiver',\n",
              " 'tivera',\n",
              " 'tiveram',\n",
              " 'tiverem',\n",
              " 'tivermos',\n",
              " 'tivesse',\n",
              " 'tivessem',\n",
              " 'tivéramos',\n",
              " 'tivéssemos',\n",
              " 'tu',\n",
              " 'tua',\n",
              " 'tuas',\n",
              " 'tém',\n",
              " 'tínhamos',\n",
              " 'um',\n",
              " 'uma',\n",
              " 'você',\n",
              " 'vocês',\n",
              " 'vos',\n",
              " '{',\n",
              " '|',\n",
              " '}',\n",
              " '~',\n",
              " 'à',\n",
              " 'às',\n",
              " 'é',\n",
              " 'éramos'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXsGHSIZIdQx",
        "colab_type": "code",
        "outputId": "96c536d7-5528-46f8-f378-d2aa93b06d14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "source": [
        "[x for x in nltk.word_tokenize(text.lower()) if x not in stop]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['china',\n",
              " 'lança',\n",
              " 'maior',\n",
              " 'rede',\n",
              " '5g',\n",
              " 'mundo',\n",
              " '02',\n",
              " 'nov',\n",
              " '2019',\n",
              " '16:58',\n",
              " 'china',\n",
              " 'lançou',\n",
              " 'nesta',\n",
              " 'sexta-feira',\n",
              " 'maior',\n",
              " 'rede',\n",
              " '5g',\n",
              " 'mundo',\n",
              " 'segundo',\n",
              " 'cnn',\n",
              " 'maiores',\n",
              " 'operadoras',\n",
              " 'chinesas',\n",
              " 'oferecem',\n",
              " 'planos',\n",
              " 'internet',\n",
              " 'ultrarrápida',\n",
              " 'quinta',\n",
              " 'geração']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OltQFwy7KNbo",
        "colab_type": "code",
        "outputId": "7d43a4ce-c128-43cd-c576-347d33e4cf55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "source": [
        "!pip install googletrans"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting googletrans\n",
            "  Downloading https://files.pythonhosted.org/packages/fd/f0/a22d41d3846d1f46a4f20086141e0428ccc9c6d644aacbfd30990cf46886/googletrans-2.4.0.tar.gz\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from googletrans) (2.21.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->googletrans) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->googletrans) (2019.9.11)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->googletrans) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->googletrans) (1.24.3)\n",
            "Building wheels for collected packages: googletrans\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-2.4.0-cp36-none-any.whl size=15776 sha256=9e862344044366918f655d33288ad4b80715bec23d36041fa481e25d0e2835be\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/d6/e7/a8efd5f2427d5eb258070048718fa56ee5ac57fd6f53505f95\n",
            "Successfully built googletrans\n",
            "Installing collected packages: googletrans\n",
            "Successfully installed googletrans-2.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XkxbJ-bKJoS",
        "colab_type": "code",
        "outputId": "ee119008-fbee-43d7-9af0-12e1c2bd6ff1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from googletrans import Translator\n",
        "tr = Translator().translate(text)\n",
        "tr"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<googletrans.models.Translated at 0x7fc540b690f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5WUvXkfKgiM",
        "colab_type": "code",
        "outputId": "60b83d0e-1c70-42a6-e261-da15f2e5f119",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "tr.src, tr.text"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('pt',\n",
              " 'China launches largest 5G network in the world\\n\\n02 Nov 2019 16:58\\n\\nChina launched on Friday the biggest 5G network in the world, according to CNN.\\nThe largest Chinese carriers now offer ultra fast internet plans of the fifth generation.')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWhvSvLpLEz6",
        "colab_type": "code",
        "outputId": "d9143db4-5cf7-49bc-baaf-3e8f076d00a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "stop2 = set(stopwords.words('english') + list(string.punctuation))\n",
        "stop2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'!',\n",
              " '\"',\n",
              " '#',\n",
              " '$',\n",
              " '%',\n",
              " '&',\n",
              " \"'\",\n",
              " '(',\n",
              " ')',\n",
              " '*',\n",
              " '+',\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '/',\n",
              " ':',\n",
              " ';',\n",
              " '<',\n",
              " '=',\n",
              " '>',\n",
              " '?',\n",
              " '@',\n",
              " '[',\n",
              " '\\\\',\n",
              " ']',\n",
              " '^',\n",
              " '_',\n",
              " '`',\n",
              " 'a',\n",
              " 'about',\n",
              " 'above',\n",
              " 'after',\n",
              " 'again',\n",
              " 'against',\n",
              " 'ain',\n",
              " 'all',\n",
              " 'am',\n",
              " 'an',\n",
              " 'and',\n",
              " 'any',\n",
              " 'are',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'as',\n",
              " 'at',\n",
              " 'be',\n",
              " 'because',\n",
              " 'been',\n",
              " 'before',\n",
              " 'being',\n",
              " 'below',\n",
              " 'between',\n",
              " 'both',\n",
              " 'but',\n",
              " 'by',\n",
              " 'can',\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'd',\n",
              " 'did',\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'do',\n",
              " 'does',\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'doing',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'down',\n",
              " 'during',\n",
              " 'each',\n",
              " 'few',\n",
              " 'for',\n",
              " 'from',\n",
              " 'further',\n",
              " 'had',\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'has',\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'have',\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'having',\n",
              " 'he',\n",
              " 'her',\n",
              " 'here',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'him',\n",
              " 'himself',\n",
              " 'his',\n",
              " 'how',\n",
              " 'i',\n",
              " 'if',\n",
              " 'in',\n",
              " 'into',\n",
              " 'is',\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'just',\n",
              " 'll',\n",
              " 'm',\n",
              " 'ma',\n",
              " 'me',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'more',\n",
              " 'most',\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'my',\n",
              " 'myself',\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'now',\n",
              " 'o',\n",
              " 'of',\n",
              " 'off',\n",
              " 'on',\n",
              " 'once',\n",
              " 'only',\n",
              " 'or',\n",
              " 'other',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'out',\n",
              " 'over',\n",
              " 'own',\n",
              " 're',\n",
              " 's',\n",
              " 'same',\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'so',\n",
              " 'some',\n",
              " 'such',\n",
              " 't',\n",
              " 'than',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'the',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'them',\n",
              " 'themselves',\n",
              " 'then',\n",
              " 'there',\n",
              " 'these',\n",
              " 'they',\n",
              " 'this',\n",
              " 'those',\n",
              " 'through',\n",
              " 'to',\n",
              " 'too',\n",
              " 'under',\n",
              " 'until',\n",
              " 'up',\n",
              " 've',\n",
              " 'very',\n",
              " 'was',\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'we',\n",
              " 'were',\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'what',\n",
              " 'when',\n",
              " 'where',\n",
              " 'which',\n",
              " 'while',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'why',\n",
              " 'will',\n",
              " 'with',\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\",\n",
              " 'y',\n",
              " 'you',\n",
              " \"you'd\",\n",
              " \"you'll\",\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " '{',\n",
              " '|',\n",
              " '}',\n",
              " '~'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QDxzLRaLUIq",
        "colab_type": "code",
        "outputId": "e8b0c418-90fc-456b-83dc-bf91e6cc61f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "source": [
        "[x for x in nltk.word_tokenize(tr.text.lower()) if x not in stop2]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['china',\n",
              " 'launches',\n",
              " 'largest',\n",
              " '5g',\n",
              " 'network',\n",
              " 'world',\n",
              " '02',\n",
              " 'nov',\n",
              " '2019',\n",
              " '16:58',\n",
              " 'china',\n",
              " 'launched',\n",
              " 'friday',\n",
              " 'biggest',\n",
              " '5g',\n",
              " 'network',\n",
              " 'world',\n",
              " 'according',\n",
              " 'cnn',\n",
              " 'largest',\n",
              " 'chinese',\n",
              " 'carriers',\n",
              " 'offer',\n",
              " 'ultra',\n",
              " 'fast',\n",
              " 'internet',\n",
              " 'plans',\n",
              " 'fifth',\n",
              " 'generation']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    }
  ]
}