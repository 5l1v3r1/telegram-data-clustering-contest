<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <meta property="og:url" content="https://mspoweruser.com/microsofts-onnx-joins-linux-foundation/"/>
    <meta property="og:site_name" content="MSPoweruser"/>
    <meta property="article:published_time" content="2019-11-15T17:07:00+00:00"/>
    <meta property="og:title" content="Microsoft’s ONNX joins Linux Foundation"/>
    <meta property="og:description" content="Back in 2017, Microsoft announced its collaboration with Facebook to introduce Open Neural Network Exchange (ONNX) format. ONNX brings interoperability to the AI framework ecosystem providing a definition of an extensible computation graph model, as well as definitions of built-in operators and standard data types. ONNX enables models to be trained in one framework and transferred to another …"/>
  </head>
  <body>
    <article>
      <h1>Microsoft’s ONNX joins Linux Foundation</h1>
      <address><time datetime="2019-11-15T17:07:00+00:00">15 Nov 2019, 17:07</time> by <a rel="author">Pradeep</a></address>
      <figure>
        <a href="https://mspoweruser.com/wp-content/uploads/2017/10/Microsoft-ONNX-Facebook.jpg">
          <img src="https://mspoweruser.com/wp-content/uploads/2017/10/Microsoft-ONNX-Facebook.jpg"/>
        </a>
      </figure>
      <p>Back in 2017, Microsoft <a href="https://mspoweruser.com/microsoft-joins-hands-facebook-standardize-ai-framework-ecosystem/">announced</a> its collaboration with Facebook to introduce Open Neural Network Exchange (ONNX) format. ONNX brings interoperability to the <a href="https://mspoweruser.com/microsoft-and-facebooks-open-ai-model-gains-support-from-major-tech-companies/">AI framework ecosystem</a> providing a definition of an extensible computation graph model, as well as definitions of built-in operators and standard data types. ONNX enables models to be trained in one framework and transferred to another for inference. Last year, Microsoft announced that it is <a href="https://mspoweruser.com/microsoft-open-sources-high-performance-inference-engine-for-machine-learning-models/">open sourcing ONNX Runtime</a>, a high-performance inference engine for machine learning models in the ONNX format on Linux, Windows, and Mac.</p>
      <p>Today, Microsoft announced that ONNX is joining the LF AI Foundation, an umbrella foundation of the Linux Foundation.</p>
      <p>“We are excited that LF AI will host ONNX and continue the open-governance model, which encourages community participation and contributions. LF AI will provide long term leadership to ONNX enabling a community focused on accelerating the adoption of machine learning and fostering ONNX’s next wave of innovation and adoption,” wrote Eric Boyd, Corporate Vice President, Azure AI at Microsoft.</p>
      <p>Microsoft is hoping that ONNX will get a rich ecosystem of frameworks, compilers, runtimes, accelerators, and visualizers under Linux Foundation.</p>
      <p>“ONNX is not just a spec that companies endorse, it’s already being actively implemented in their products. This is because ONNX is an open format and is committed to developing and supporting a wide choice of frameworks and platforms. Joining the LF AI shows a determination to continue on this path, and will help accelerate technical development and connections with the wider open source AI community around the world,” said Dr. Ibrahim Haddad, Executive Director of the LF AI Foundation. “We’re happy to provide ONNX an independent home and work with the community to boost its profile as a vendor neutral standard. ONNX will retain its existing OSI-approved open source license, its governance structure and their established development practices. We are committed to providing ONNX with a host of supporting services especially in the area of marketing and community events to extend its reach and adoption.”</p>
      <p>Source: <a href="https://cloudblogs.microsoft.com/opensource/2019/11/14/onnx-joins-linux-foundation/">Microsoft</a></p>
    </article>
  </body>
</html>