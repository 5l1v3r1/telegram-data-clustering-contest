<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <meta property="og:url" content="https://www.heise.de/developer/meldung/Machine-Learning-Linux-Foundation-uebernimmt-das-ONNX-Projekt-4586969.html"/>
    <meta property="og:site_name" content="Developer"/>
    <meta property="article:published_time" content="2019-11-15T12:08:00+00:00"/>
    <meta property="og:title" content="Machine Learning: Linux Foundation übernimmt das ONNX-Projekt"/>
    <meta property="og:description" content="Die Linux Foundation kümmert sich im Rahmen eines Graduate-Level-Projektes um die Weiterentwicklung des Austauschformats für Machine-Learning-Modelle."/>
  </head>
  <body>
    <article>
      <h1>Machine Learning: Linux Foundation übernimmt das ONNX-Projekt</h1>
      <h2>Die Linux Foundation kümmert sich im Rahmen eines Graduate-Level-Projektes um die Weiterentwicklung des Austauschformats für Machine-Learning-Modelle.</h2>
      <address><time datetime="2019-11-15T12:08:00+00:00">15 Nov 2019, 12:08</time> by <a rel="author">Matthias Parbel</a></address>
      <p>Um ONNX (Open Neural Network Exchange) als herstellerunabhängiges Standardaustauschformat für Machine-Learning-Modelle zu etablieren und weiterzuentwickeln, nimmt die Linux Foundation das Projekt ab sofort unter ihre Fittiche. Die Verwaltung und Governance des Graduate-Level-Projekts rücken unter die Verantwortung der LF AI Foundation, die als Unterorganisation der Linux Foundation das Ziel verfolgt, ein Ökosystem zu schaffen, das Open-Source-Innovationen in den Bereichen Künstliche Intelligenz (KI), Machine Learning (ML) und Deep Learning (DL) voranzutreiben.</p>
      <h3>Offener Standard für den Modellaustausch</h3>
      <p>ONNX geht auf eine gemeinsame Entwicklung von Microsoft und Facebook zurück, die das Austauschformat 2017 vorgestellt haben. Seither ist rund um das unter MIT-Lizenz verfügbare ONNX-Format eine große Community gewachsen. Das <a href="https://github.com/onnx/onnx">auf GitHub gehostete Projekt</a> zählt circa 140 Beitragende, konnte bereits über 7000 Sterne sammeln und verzeichnet mehr als 1000 Forks. Darüber hinaus vereint ONNX mehr als 30 namhafte Unternehmen hinter sich, die das Austauschformat in ihren Produkten unterstützen beziehungsweise integriert haben – darunter AWS, Apple, IBM, Intel, Nvidia und Qualcomm.</p>
      <p>Mit populären Frameworks wie TensorFlow oder PyTorch können Data Scientists ihre ML-Modelle vergleichsweise einfach erstellen und trainieren. Die Überführung in den produktiven Betrieb oder die Weiterverwendung mit anderen Tools führt in der Regel jedoch zu Problemen. ONNX schafft hier Abhilfe mit einer standardisierten Repräsentation sowohl für DL- wie auch die klassischen ML-Modelle. Dadurch eröffnet sich Entwicklern und Data Scientists die Möglichkeit, mit den jeweils für ihre Anforderungen geeigneten Tools zu arbeiten, ohne unüberwindbare Kompatibilitätsprobleme fürchten zu müssen. Damit hat sich das quelloffene ONNX-Format binnen kurzer Zeit als Quasistandard für den Austausch von ML-Modellen etabliert.</p>
      <h3>ONNX Runtime bleibt ein Microsoft-Projekt</h3>
      <p>Microsoft will die Open-Source-Community und das ONNX-Projekt auch unter dem Dach der Linux Foundation weiter unterstützen. Als Teil dieser Bemühungen entwickelt das Unternehmen die seit Ende 2018 quelloffen verfügbare ONNX Runtime weiter – zumindest vorläufig noch in Eigenregie. Die vor wenigen Wochen <a href="https://cloudblogs.microsoft.com/opensource/2019/10/30/announcing-onnx-runtime-1-0/">in Version 1.0 veröffentlichte Inferenzmaschine</a> für Machine-Learning-Modelle soll das Deployment über verschiedene Plattformen hinweg erleichtern und die Performance beim Einsatz auf GPUs, CPUs, Cloud- oder Edge-Diensten verbessern.</p>
      <p>
        <i>Siehe dazu auf heise Developer:</i>
      </p>
      <ul>
        <li>
          <a href="https://www.heise.de/developer/artikel/Portabilitaet-fuer-Deep-Learning-Modelle-mit-ONNX-4467247.html">Portabilität für Deep-Learning-Modelle mit ONNX</a>
        </li>
      </ul>
      <p>(<a href="mailto:map@heise.de">map</a>)</p>
    </article>
  </body>
</html>