<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <meta property="og:url" content="https://www.theguardian.com/technology/2019/nov/12/far-right-use-russian-style-propaganda-to-spread-misinformation"/>
    <meta property="og:site_name" content="the Guardian"/>
    <meta property="article:published_time" content="2019-11-12T16:36:54+00:00"/>
    <meta property="og:title" content="Far right 'use Russian-style propaganda to spread misinformation'"/>
    <meta property="og:description" content="Speakers at event in Oxford say ‘junk news’ tools pioneered by Russians now originate in UK"/>
  </head>
  <body>
    <article>
      <h1>Far right 'use Russian-style propaganda to spread misinformation'</h1>
      <address><time datetime="2019-11-12T16:36:54+00:00">12 Nov 2019, 16:36</time> by <a rel="author" href="https://www.theguardian.com/profile/alex-hern" target="_blank">Alex Hern</a></address>
      <p>
        <i>Speakers at event in Oxford say ‘junk news’ tools pioneered by Russians now originate in UK</i>
      </p>
      <p>Misinformation techniques first deployed by Russian agents are now more commonly used in Britain by the far right, as well as by politicians to convince their own voters, an audience in Oxford has been told.</p>
      <p>At an event hosted by Oxford University’s <a href="https://www.theguardian.com/technology/internet">Internet</a> Institute, which has been studying the effects of “computational propaganda” in elections around the world, speakers said the evidence of foreign interference in Britain’s election was slim, but that strategies first deployed by foreign actors were still going strong. The event was held under the Chatham House rule, meaning speakers can be quoted but not named.</p>
      <p>“The communications strategies pioneered by the Russians have migrated to become strategies that the far right, [and] white supremacists, use in this country, and strategies that politicians use in this country on their own voters,” said one attender.</p>
      <p>Researchers from the institute identified other changing trends in how misinformation spreads online. Compared with earlier elections, a significant amount of “junk news” was posted directly to social networks such as Twitter, Facebook and Instagram, rather than linking to external websites. That made it harder to trace, and also increased the ability of normal users to source and spread such news themselves.</p>
      <p>“A lot of the misinformation and junk that we did identify was home-grown hybrid content, as opposed to content that was of foreign origin,” attenders were told. “I want to underscore that point … a lot of the tools and techniques that we have seen since 2016 have been not only democratised, but the barrier to entry is extremely low for anyone to really start pushing dubious or low-quality content.</p>
      <p>“We identified a lot of sites that were nimble operations – sometimes they even had a small editorial team – but what they did was often publish content that contained a kernel of truth, but was packaged and rendered with accompanying mistruths. Or outlets that reported on factual information but selectively reported on stories in such a way that people who visited them would have a skewed view.”</p>
      <p>So far in this election, junk news publishers have been across the ideological spectrum, with Jo Swinson a specific target of much of the most-shared content. But the event was told that it would be a mistake to treat the issue as symmetrical.</p>
      <p>“There are examples of far-left URLs that we’ve caught – in the US mostly, and maybe some in <a href="https://www.theguardian.com/world/europe-news">Europe</a> – but I think it’s fractional enough that the story really should be about the far right,” one speaker said. “To me, it’s a bit like climate change: I don’t think we should ‘teach the controversy’ and say that the far left and far right are doing it. It really is white supremacists, sexist content and ultraconservative groups.”</p>
    </article>
  </body>
</html>