<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <meta property="og:url" content="https://www.seonews.ru/analytics/optimization-2019-oshibki-tekstovykh-analizatorov/"/>
    <meta property="og:site_name" content="SEOnews"/>
    <meta property="article:published_time" content="2019-11-14T12:50:00+00:00"/>
    <meta property="og:title" content="Optimization 2019: Ошибки текстовых анализаторов"/>
    <meta property="og:description" content="Юрий Хаит (Bitkey Digital Agency) сравнил работу таких анализаторов, как SerpStat, Just Magic, RushAnalytics, Engine.Seointellect, SeoLib и PRakula, и поделился выводами"/>
  </head>
  <body>
    <article>
      <h1>Optimization 2019: Ошибки текстовых анализаторов</h1>
      <address><time datetime="2019-11-14T12:50:00+00:00">14 Nov 2019, 12:50</time> by <a rel="author">Дорогая Редакция</a></address>
      <p>В конце октября прошла 18-я конференция по поисковому маркетингу <a href="https://www.seonews.ru/tags/optimization-2019/"><b>Optimization 2019</b></a>. SEOnews с радостью делится обзорами с этого мероприятия. В рамках секции «Современные исследования в SEO» выступил <b>Юрий Хаит</b> (Bitkey Digital Agency) с докладом «Ошибки текстовых анализаторов».</p>
      <p>При массовой работе с посадочными страницами специалисты понимают, если стоит задача проработать 30-50 страниц на одном сайте, это не получится сделать целиком вручную (т.к. бюджет ограничен). Это нужно автоматизировать.</p>
      <p>Многие SEO-специалисты обращаются к текстовым анализаторам, которые дают данные по вхождениям разных ключей на страницах сайтов-конкурентов. Но использование таких анализаторов в итоге может привести к не самым приятным результатам.</p>
      <h3>Как работают анализаторы</h3>
      <p>Что у нас есть:</p>
      <ul>
        <li>Кластер запросов, который кластеризован по харду с точностью 3. Это значит, что, как минимум, три документа в выдаче (в данном случае Яндекса) одновременно находятся в ТОПе по всем этим запросам.</li>
        <li>Кластер находится целиком в ТОПе.</li>
        <li>Он достаточно низкочастотный, чтобы на него могли сильно повлиять поведенческие и ссылочные факторы.</li>
      </ul>
      <figure>
        <img src="https://www.seonews.ru/upload/medialibrary/788/788f9765dcec224ba744c5ac135fc9e4.png"/>
      </figure>
      <p>Первый текстовый анализатор, который рассмотрел Юрий – это простой текстовый анализатор, который есть в сервисе SerpStat. Стоит отметить, что им нельзя воспользоваться, если в самом SerpStat не сделать кластеризацию (но ее качество невысокое), и в итоге приходится собирать кластеры вручную.</p>
      <h3>SerpStat</h3>
      <p>Итак, SerpStat дает рекомендации исходя из определенных параметров, учитываются зоны вхождения ключа Title, H1, тело документа, внутри которого разбивки уже нет (что справедливо только при оптимизации под Google).</p>
      <p><b>Плюс сервиса</b> в том, что для одной страницы можно отправить хоть тысячу запросов.</p>
      <p><b>Минусы</b>: он анализирует неизвестные сайты (непонятно, он берет ТОП-10 или ТОП-20, какие документы он отсекает при анализе), дает рекомендации по изменению для запросов, которые в большинстве случаев уже находятся в ТОП-1.</p>
      <figure>
        <img src="https://www.seonews.ru/upload/medialibrary/763/76333c61b677ade326b09dbf46d278d2.png"/>
      </figure>
      <h3>Just Magic</h3>
      <p>Следующий сервис Just Magic:</p>
      <ul>
        <li>дает больше всего данных по длинным запросам (более 2х слов);</li>
        <li>позволяет анализировать, в том числе, разбавленные вхождения;</li>
        <li>анализирует большее количество вхождения зон ключа. Здесь уже, по крайней мере, появились анкоры исходящих ссылок, но почему-то исчез H1. Зато появилась разбивка на текстовые фрагменты и plain-текст;</li>
        <li>можно на входе фильтровать те документы, по которым проводить анализ.</li>
      </ul>
      <p>И вот появляется рекомендация добавить слово «анализ» 40 раз и «операция» 10 раз. Самое интересное, поскольку ранее вручную уже проанализировали те документы, которые находятся в ТОПе, известно, что нигде такого количества вхождений нет. И числа эти 40 и 10 не являются ни средними значениями, ни медианами. Откуда они взяты, непонятно.</p>
      <figure>
        <img src="https://www.seonews.ru/upload/medialibrary/764/7640c07415702fd60b8f9edc8c93a157.png"/>
      </figure>
      <h3>RushAnalytics</h3>
      <p>Следующий сервис – RushAnalytics. Кластер тот же самый. Слова уже другие, здесь нет разбавленных вхождений как таковых. Но опять появляется рекомендации, похожие на предыдущий сервис – добавить «анализы» в разных словоформах 36 раз.</p>
      <p>Интересно, что тут специально сравнивали с Just Magic: отдают выдачу эти два сервиса одну и ту же, зафильтрованы одни и те же домены, но рекомендации разные.</p>
      <figure>
        <img src="https://www.seonews.ru/upload/medialibrary/18f/18f9e860829935af14c519ff6bda78a6.png"/>
      </figure>
      <h3>Engine.Seointellect</h3>
      <p>Еще одним анализатором – Engine.Seointellect – на практике особо не смогли воспользоваться, т.к. он дает разобщенные данные, не в том виде как предыдущие сервисы. Поэтому в дальнейшем в анализе его будет не очень много.</p>
      <figure>
        <img src="https://www.seonews.ru/upload/medialibrary/5b4/5b40d6013a827123ecfecdebee194fb0.png"/>
      </figure>
      <p>Сводная таблица по тому, какие зоны вхождения ключевых слов используют эти анализаторы:</p>
      <figure>
        <img src="https://www.seonews.ru/upload/medialibrary/75b/75ba5242df035778020c485eff7babae.png"/>
      </figure>
      <p>Самое интересное, что все эти зоны вхождения актуальны, просто для разных типов страниц.</p>
      <h3>SeoLib и PRakula</h3>
      <p>В рамках исследования рассмотрели еще два сервиса – SeoLib и PRakula.</p>
      <p><b>Минус SeoLib</b> – он дает рекомендации отдельно по каждому запросу. Т.е. мы берем ТОП выдачи по одному запросу, смотрим и делаем выводы для этого конкретного запроса. Это очень неудобно, использовать на практике можно, только если у нас есть кластеры из одного запроса, т.е. просто запрос на страницу и все. Также у SeoLib не очень удобная настройка фильтрации конкурентов: можно выбрать ТОП-10 и 20 либо подать список вручную. Получается, нельзя взять ТОП и выбрать сайты, по которым мы провели кластеризацию и которые имеют тот же тип документа.</p>
      <p>Но зато этот сервис анализирует огромное количество зон вхождения ключа: можно померить не только заголовок H1, H2, H3 и т.д., но и alt картинок.</p>
      <figure>
        <img src="https://www.seonews.ru/upload/medialibrary/28c/28ce0a2647e9a6e1eacd289d7a4e60d8.png"/>
      </figure>
      <p>Еще один сервис – PRakula. Позволяет оптимизировать одну страницу только под один ключ и выдает в итоге некорректные данные.</p>
      <figure>
        <img src="https://www.seonews.ru/upload/medialibrary/37f/37f92dce7fb89d3f736885881d768bcb.png"/>
      </figure>
      <h3>Эксперимент</h3>
      <p>Что решили сделать, увидев на примере кластера, что анализаторы дают не совсем корректные значения:</p>
      <ul>
        <li>взяли 1243 страниц-кластеров в ТОПе и 1757 страниц, которые не попали в ТОП после проработки с помощью текстовых анализаторов (всего 86 455 запросов);</li>
        <li>замерили расхождения автоматического анализа и «ручного парсинга» и сделали выводы;</li>
        <li>исключили влияние ссылочных и поведенческих факторов.</li>
      </ul>
      <p>И посмотрели насколько ошибаются анализаторы на этих конкретных кластерах.</p>
      <p>Полученные результаты:</p>
      <figure>
        <img src="https://www.seonews.ru/upload/medialibrary/6b9/6b9045c0b0fc3baf979cdd5062b6faa9.png"/>
      </figure>
      <p>1. <b>Некорректно определена зона вхождения ключа</b>: проблемы начинаются в текстовых фрагментах, в анкорах исходящих ссылок, в alt изображений. SerpStat смешивает это все в единую зону, плюс неизвестно, с какими сайтами он сравнивает, поэтому у него стоит знак вопроса.</p>
      <p>2. <b>Рандомные документы при парсинге</b>: если на сайте конкурента стоит защита от парсинга, анализатор будет искать случайные сайты для анализа. В итоге получаются некорректные данные.</p>
      <p>3. <b>Сколько было получено неверных рекомендаций и сколько рекомендаций не привели к результату</b>: как видим, практически у всех сервисов более 50% случаев некорректных рекомендаций, а процент страниц, которые после внедрения рекомендаций, позиции не поменяли, также впечатляющий – до 30-40%.</p>
      <h3>Что делать?</h3>
      <p>Как добиваться результатов несмотря на ошибки анализаторов:</p>
      <ul>
        <li>Есть множество сервисов и программ, которые позволяют парсить, к этому прибавляем Excel и ручной анализ.</li>
        <li>Необходимо сравнение по типу документа помимо кластеризации по топам (листинги с листингами, статьи со статьями, товары с товарами).</li>
        <li>Анализировать важность «текстовых» до проведения анализа. Для Google вообще как будто нет разницы между text-fragments / a / plaintext.</li>
      </ul>
      <p>В сухом остатке:</p>
      <ul>
        <li>Зоны вхождения ключей неизменны: TITLE, H1, Plain Text + Text Fragments + BODY (если речь идет о листингах).</li>
        <li>Текстовые анализаторы можно использовать, но для каждого нужно делать «прогоны» документов конкурентов – все 100% должны быть спаршены. Плюс необходим выбор типа документа для сравнения.</li>
        <li>Очень много конкурентов с плохими текстовыми в ТОПе. Важно отсекать домены с огромным количеством входящих ссылок на URL, а не агрегаторы (если у вас, например, магазин).</li>
        <li>Текстовый анализ – это долго (по 3-4 часа на страницу). Имеет смысл для «жирных» по семантике листингов. (SUM “WS” &gt; 500).</li>
      </ul>
      <blockquote>Презентацию доклада Юрия Хаита вы найдете <a href="https://2019.optimization.ru/static/files/prezentation/3-oshibki-tekstovyh-analizatorov.pdf">по ссылке</a>.</blockquote>
      <h3>Интересное с Optimization 2019:</h3>
      <p>1. <b><a href="https://www.seonews.ru/analytics/optimization-2019-kak-sozdat-kontent-strategiyu-dlya-seo-i-piara-za-9-shagov/">Optimization 2019: Как создать контент-стратегию для SEO и пиара за 9 шагов</a></b></p>
      <p>2. <a href="https://www.seonews.ru/analytics/optimization-2019-pyat-trendov-poiskovogo-marketinga-ot-sayrusa-sheparda/"><b>Optimization 2019: Пять трендов поискового маркетинга от Сайруса Шепарда</b></a></p>
      <p>3. <a href="https://www.seonews.ru/analytics/optimization-2019-sovremennye-problemy-seo-spetsialistov/"><b>Optimization 2019: Современные проблемы SEO-специалистов</b></a></p>
      <p>4. <a href="https://www.seonews.ru/analytics/seo-trendy-kak-probitsya-v-top-v-2020-godu/"><b>SEO-тренды: как пробиться в ТОП в 2020 году</b></a></p>
      <p>5. <b><a href="https://www.seonews.ru/events/issledovanie-faktorov-ranzhirovaniya-v-yandekse-i-google-v-2019-godu/">Исследование факторов ранжирования в Яндексе и Google в 2019 году</a></b></p>
    </article>
  </body>
</html>