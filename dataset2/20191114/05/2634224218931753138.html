<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <meta property="og:url" content="https://www.letemps.ch/economie/facebook-supprime-54-milliards-faux-comptes-2019"/>
    <meta property="og:site_name" content="Le Temps"/>
    <meta property="article:published_time" content="2019-11-14T05:51:00+00:00"/>
    <meta property="og:title" content="Facebook a supprimé 5,4 milliards de faux comptes en 2019"/>
    <meta property="og:description" content="Facebook a publié son rapport bi-annuel sur la transparence, faisant état de progrès. Les algorithmes du réseau social sont «capables d'identifier environ 80% des contenus» retirés"/>
  </head>
  <body>
    <article>
      <h6 class="kicker">Réseau social</h6>
      <h1>Facebook a supprimé 5,4 milliards de faux comptes en 2019</h1>
      <h2>Facebook a publié son rapport bi-annuel sur la transparence, faisant état de progrès. Les algorithmes du réseau social sont «capables d'identifier environ 80% des contenus» retirés</h2>
      <address><time datetime="2019-11-14T05:51:00+00:00">14 Nov 2019, 05:51</time> by <a rel="author">AFP</a></address>
      <p>L'intelligence artificielle joue un rôle exponentiel dans la chasse de Facebook aux vidéos terroristes ou aux images faisant l'apologie du suicide, mais le géant des technologies a aussi besoin de nombreux experts en chair et en os pour ne pas se faire rattraper par les nombreux risques de scandales.</p>
      <p>«Nos efforts sont en train de payer», assure d'emblée Mark Zuckerberg, lors d'une conférence de presse mercredi, à l'occasion de la publication d'un rapport bi-annuel de Facebook sur la transparence, se targuant dans le même temps d'avoir supprimé 5,4 milliards de faux comptes d'utilisateurs depuis le début de l'année (contre 2,1 milliards l'année dernière à la même période).</p>
      <figure>
        <iframe data-src="https://twitter.com/facebook/status/1194669960938700800?ref_src=twsrc%5Etfw" data-embed-type="twitter-tweet" width="100%" height="0" data-service="Twitter" scrolling="no" nowide=""/>
      </figure>
      <p>Les algorithmes du réseau social «sont désormais capable d'identifier de façon pro-active environ 80% des contenus que nous retirons», «contre quasiment 0% il y a deux ans», s'est félicité le fondateur du géant des réseaux.</p>
      <h3>Les difficultés pour repérer les vidéos</h3>
      <p>Mais il reconnaît que les technologies d'intelligence artificielle (IA) ont plus de mal à repérer les discours haineux que les vidéos comportant de la nudité, à cause des «nombreuses nuances linguistiques».</p>
      <p>C'est tout le problème du contexte: une vidéo montrant une attaque raciste peut être partagée à des fins de condamnation... ou de glorification. Difficile par exemple de savoir dans quel but des utilisateurs ont essayé, et essaient encore, de republier la vidéo de la tuerie de Christchurch. Mais les algorithmes de Facebook ont su bloquer en amont 95% de leurs tentatives.</p>
      <p><b>Lire aussi:</b> <a href="https://www.letemps.ch/economie/facebook-machine-scandales">Facebook, machine à scandales</a></p>
      <p>En tout, depuis l'attaque le 15 mars dernier, 4,5 millions d'extraits de cette vidéo ont été détectés par l'IA. L'assaillant, un suprémaciste blanc, s'était filmé en direct en train de massacrer des fidèles dans une mosquée en Nouvelle-Zélande. Le réseau avait mis 17 minutes à stopper la diffusion.</p>
      <h3>Des spécialistes du terrorisme recrutés</h3>
      <p>Pour Facebook, l'enjeu est d'anticiper d'où va venir la menace, avant qu'elle n'arrive, pour empêcher que ce genre de scénario ne se reproduise. «Nous avons désormais plus 350 personnes dans l'entreprise dont la responsabilité première est d'empêcher des membres de groupes terroristes d'utiliser notre service», remarque Monika Bickert, vice-présidente en charge de la modération de Facebook. «Une partie d'entre eux sont des spécialistes du terrorisme, que nous avons embauchés pour leur expertise.»</p>
      <p>Même stratégie sur Instagram, qui a récemment durci sa réglementation pour lutter contre la circulation de contenus susceptibles d'encourager le suicide ou l'automutilation. Le réseau a interdit les photos, puis les dessins et illustrations sur le sujet après qu'un père eut accusé le réseau social d'avoir une responsabilité dans le suicide de sa fille de 14 ans. L'adolescente avait, selon son père, consulté beaucoup de contenus sur ce sujet.</p>
      <p><b>Lire également:</b> <a href="https://www.letemps.ch/economie/facebook-presente-plan-elections-americaines-2020">Facebook présente son plan pour les élections américaines de 2020</a></p>
      <p>Dans le même temps, Facebook ne veut pas censurer les personnes qui se serviraient de ses services pour exprimer leurs émotions ou appeler à l'aide. «Nous avons intensifié le rythme de nos rencontres avec des experts de l'autodestruction à une fois par mois» précise Monica Bickert. En tout, Facebook compte 35 000 personnes qui travaillent, en interne et chez des entreprises partenaires, à la sécurité et à la modération de contenus sur ses plateformes.</p>
      <h3>Une «très faible proportion de contenus nocifs», selon Zuckerberg</h3>
      <p>Dans son rapport il explique avoir «amélioré ses capacités à détecter et bloquer» les créations de comptes «faux ou abusifs» au point d'empêcher des millions de tentatives tous les jours.</p>
      <p>«La probabilité que des utilisateurs voient des contenus interdits par notre règlement (...) est très faible. Quand nous faisons des tests il arrive que nous ne trouvions rien du tout», constate Guy Rosen, vice-président en charge de l'intégrité du réseau.</p>
      <p>Selon Mark Zuckerberg, la «très faible proportion de contenus nocifs» sur la plateforme prouve que Facebook ne cherche pas à profiter de contenus viraux, donc lucratifs, comme l'accusent certains détracteurs.</p>
      <p>Le groupe tire l'essentiel de ses revenus de la publicité, mais «les annonceurs ne veulent pas que leurs marques apparaissent à côté des contenus problématiques», insiste-t-il. «Donc si nos affaires nous influencent, c'est plutôt pour nous encourager à nous attaquer à ces contenus de façon encore plus agressive.»</p>
    </article>
  </body>
</html>