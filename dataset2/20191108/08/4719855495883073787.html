<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <meta property="og:url" content="https://www.xataka.com/inteligencia-artificial/openai-ha-publicado-fin-generador-noticias-falsas-que-censuro-hace-unos-meses-ser-demasiado-peligroso"/>
    <meta property="og:site_name" content="Xataka"/>
    <meta property="article:published_time" content="2019-11-08T08:35:04+00:00"/>
    <meta property="og:title" content="OpenAI ha publicado por fin el generador de noticias falsas que censuró hace unos meses por ser demasiado &quot;peligroso&quot;"/>
    <meta property="og:description" content="¿Recuerdas la inteligencia artificial bautizada como GPT-2, especializada en la generación de textos realistas y cuyos desarrolladores (OpenAI), en una..."/>
  </head>
  <body>
    <article>
      <h1>OpenAI ha publicado por fin el generador de noticias falsas que censuró hace unos meses por ser demasiado "peligroso"</h1>
      <address><time datetime="2019-11-08T08:35:04+00:00">08 Nov 2019, 08:35</time> by <a rel="author" href="https://www.xataka.com/autor/marcos-merino" target="_blank">Marcos Merino</a></address>
      <p>¿Recuerdas la inteligencia artificial bautizada como <a href="https://www.xataka.com/inteligencia-artificial/openai-crea-ia-capaz-escribir-deep-fakes-texto-luego-se-niega-difundirla-para-evitar-malos-usos">GPT-2, especializada en la generación de textos realistas</a> y cuyos desarrolladores (OpenAI), en una decisión sin precedentes (y bastante criticada), <b>decidieron no publicarla</b>, a causa del peligro que estimaban que le confería su capacidad de difusión de noticias falsas?</p>
      <p>Eso fue el pasado mes de febrero. Pues bien, ahora (9 meses más tarde), OpenAI ha decidido que no era tan fiero el león como (ellos mismos) lo pintaban, o -dicho de otro modo- que <b>"no existen fuertes evidencias de un mal uso"</b> de las <a href="https://www.xataka.com/inteligencia-artificial/openai-defiende-publicacion-incremental-su-generador-textos-fake-lanza-version-equivalente-al-50-completa">versiones más incompletas que han ido lanzado en estos meses</a>, por lo que han procedido a liberar el modelo completo.</p>
      <p>GPT-2 se basa en una evolucionada técnica de procesamiento de lenguaje natural conocida como 'modelos de lenguaje', que vienen a ser modelos de machine learning dedicado a <b>predecir cuál ha de ser la siguiente palabra de un texto en virtud de todas las palabras anteriores</b>.</p>
      <related>
        <a href="https://www.xataka.com/inteligencia-artificial/gpt-2-que-sabemos-que-no-generador-textos-ia-que-openai-dice-haber-censurado-ser-demasiado-peligroso"/>
      </related>
      <p>Una de las particularidades de GPT-2 radica en que, a partir de un texto inicial (aportado por nosotros), es capaz no sólo de continuarlo para generar un texto más amplio, sino que también <b>se le puede configurar para realizar traducciones o resúmenes del mismo</b>, y hasta para contestar preguntas sobre su contenido.</p>
      <p>Cuando nuestro objetivo es generar noticias falsas, podemos encontrarnos con textos muy convincentes que puedan parecer producto de una inteligencia, por el modo en que se hilan las frases y los temas, pero <b>a poco que juguemos con GPT-2 el tiempo suficiente empiezan a quedar claras las limitaciones del modelo</b>.</p>
      <h3>Quizá no era para tanto...</h3>
      <p>Uno de sus grandes fallos, por ejemplo, es la coherencia a largo plazo: los nombres y características de los personajes mencionados en el texto pueden terminar variando a lo largo del mismo. También se han registrado casos en los que GPT-2 ha generado <b>textos que hablan sobre los "cuatro cuernos" o sobre "incendios bajo el agua"</b> .Puedes comprobarlo tú mismo usando GPT-2 a través de una interfaz web como la de <a href="https://talktotransformer.com/">TalkToTransformer.com</a>.</p>
      <related>
        <a href="https://www.xataka.com/robotica-e-ia/complicado-que-maquinas-nos-entiendan-lenguaje-natural-espanol"/>
      </related>
      <p>Jack Clark, director de Políticas de OpenAI, explicaba en febrero que el motivo que llevó a no publicar la versión completa de GPT-2 ya en febrero no sólo radicaba en que pudiese ser utilizado para generar 'fake news' muy convincentes, sino en que <b>facilitaría su automatización y su optimización</b> (en base a factores demográficos) para sectores sociales concretos.</p>
      <p>La directora de investigación de Nvidia, Anima Anandkumar, criticó entonces con fiereza la decisión de OpenAI de que no hacer público el modelo:</p>
      <blockquote>"¿Dónde hay alguna evidencia de que vuestro sistema sea capaz de hacer eso [que decís que hace]? ¿Qué investigadores independientes han analizado sus sistema? Nadie. Si crees que realmente es capaz de eso, lo abrirás a los investigadores, no a los medios de comunicación que buscan con ansia el clickbait".</blockquote>
      <p>De todos modos, *por si acaso hubiera algo de verdad en las sospechas de OpenAI, éstos han seguido investigando en el campo** de los sistemas automatizados, no ya tanto para escribir nuevas 'fake news' como para ayudar a detectar textos que hayan sido creados recurriendo a GPT-2.</p>
      <p>Vía | <a href="https://www.theverge.com/2019/11/7/20953040/openai-text-generation-ai-gpt-2-full-model-release-1-5b-parameters">The Verge</a></p>
      <p>Imagen | <a href="https://www.piqsels.com/en/public-domain-photo-skghq">Piqsels</a></p>
    </article>
  </body>
</html>