<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <meta property="og:url" content="https://www.reuters.com/article/us-facebook-enforcement-idUSKBN1XN2B2"/>
    <meta property="og:site_name" content="Reuters"/>
    <meta property="article:published_time" content="2019-11-13T17:51:16+00:00"/>
    <meta property="og:title" content="Facebook adds Instagram data to content moderation transparency report"/>
    <meta property="og:description" content="(Reuters) - Facebook Inc (FB.O) released its fourth report on enforcement against content that violates its policies on Wednesday, adding data on photo-sharing app Instagram and content depicting suicide or self-harm for the first time."/>
  </head>
  <body>
    <article>
      <h1>Facebook removes 3.2 billion fake accounts, millions of child abuse posts</h1>
      <address>
        <time datetime="2019-11-13T21:08:34+00:00">13 Nov 2019, 21:08</time>
      </address>
      <p>(Reuters) - Facebook Inc (<a href="https://www.reuters.com/companies/FB.O">FB.O</a>) removed 3.2 billion fake accounts between April and September this year, along with millions of posts depicting child abuse and suicide, according to its latest content moderation report released on Wednesday.</p>
      <slideshow>
        <figure>
          <img src="https://s2.reutersmedia.net/resources/r/?m=02&amp;d=20191113&amp;t=2&amp;i=1451859200&amp;r=LYNXMPEFAC1ZE&amp;w=1280"/>
          <figcaption>FILE PHOTO: Stickers bearing the Facebook logo are pictured at Facebook Inc's F8 developers conference in San Jose, California, U.S., April 30, 2019. REUTERS/Stephen Lam/File Photo</figcaption>
        </figure>
        <figure>
          <img src="https://s4.reutersmedia.net/resources/r/?m=02&amp;d=20191113&amp;t=2&amp;i=1451860990&amp;r=LYNXMPEFAC1ZS&amp;w=1280"/>
          <figcaption>FILE PHOTO: The Instagram application is seen on a phone screen August 3, 2017. REUTERS/Thomas White/File Photo</figcaption>
        </figure>
      </slideshow>
      <p>That more than doubles the number of fake accounts taken down during the same period last year, when 1.55 billion accounts were removed, according to the report. (<a href="https://bit.ly/2OcsCVI">bit.ly/2OcsCVI</a>)</p>
      <p>The world’s biggest social network also disclosed for the first time how many posts it removed from popular photo-sharing app Instagram, which has been identified as a growing area of concern about fake news by disinformation researchers.</p>
      <p>Proactive detection of violating content was lower across all categories on Instagram than on Facebook’s flagship app, where the company initially implemented many of its detection tools, the company said in its fourth content moderation report.</p>
      <p>For example, the company said it proactively detected content affiliated with terrorist organizations 98.5% of the time on Facebook and 92.2% of the time on Instagram.</p>
      <p>It removed more than 11.6 million pieces of content depicting child nudity and sexual exploitation of children on Facebook and 754,000 pieces on Instagram during the third quarter.</p>
      <p>Law enforcement is concerned that Facebook’s plans to provide greater privacy to users by encrypting the company’s messaging services will hamper efforts to fight child abuse.</p>
      <p>Last month, FBI Director Christopher Wray said the changes would turn the platform into a “dream come true for predators and child pornographers.”</p>
      <p>Facebook also added data on actions it took around content involving self-harm for the first time in the report. It said it had removed about 2.5 million posts in the third quarter that depicted or encouraged suicide or self-injury.</p>
      <p>The company also removed about 4.4 million pieces involving drug sales during the quarter, it said in a blog post. (<a href="https://bit.ly/33MCdsX">bit.ly/33MCdsX</a>)</p>
      <footer>Reporting by Akanksha Rana in Bengaluru and Katie Paul in San Francisco; Editing by Maju Samuel and Lisa Shumaker</footer>
    </article>
  </body>
</html>