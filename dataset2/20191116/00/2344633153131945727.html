<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <meta property="og:url" content="http://rusjev.net/2019/11/16/google-nauchilas-realistichno-perenosit-cheloveka-v-virtualnoe-okruzhenie-video/"/>
    <meta property="og:site_name" content="Русский Еврей"/>
    <meta property="article:published_time" content="2019-11-16T00:00:00+00:00"/>
    <meta property="og:title" content="Google научилась реалистично переносить человека в виртуальное окружение (видео)"/>
    <meta property="og:description" content="Инженеры из Google научились создавать реалистичную модель двигающегося человека и встраивать ее в виртуальное пространство, меняя освещение модели соответствующим образом. Они создали стенд с несколькими десятками камер и сотнями управляемых источников освещения, внутри которого находится человек. Система быстро меняет освещение и снимает человека с разных сторон, а затем объединяет эти данные и создает модель, которая с высокой точностью описывает как форму тела и одежды, так и их оптические свойства. Разработка будет представлена на конференции SIGGRAPH Asia 2019, статья о ней опубликована на сайте авторов. Технологии захвата движения и создания виртуальных аватаров уже не первый год используются в различных сферах. Некоторые из них (например, те, которые применяют при съемках фильмов) основаны на захвате именно движений лица и других частей тела, записи чего потом используются для анимации другого персонажа. В тех случаях, когда важно сохранять внешний вид человека, используются системы из множества камер.…"/>
  </head>
  <body>
    <article>
      <h1>Google научилась реалистично переносить человека в виртуальное окружение (видео)</h1>
      <address>
        <time datetime="2019-11-16T00:00:00+00:00">16 Nov 2019</time>
      </address>
      <figure>
        <video src="https://nplus1.ru/images/2019/11/15/8895510c3520d66745577f09d71ba880.gif" autoplay="" loop=""/>
        <figcaption>
          <cite>Google</cite>
        </figcaption>
      </figure>
      <p>Инженеры из Google научились создавать реалистичную модель двигающегося человека и встраивать ее в виртуальное пространство, меняя освещение модели соответствующим образом. Они создали стенд с несколькими десятками камер и сотнями управляемых источников освещения, внутри которого находится человек. Система быстро меняет освещение и снимает человека с разных сторон, а затем объединяет эти данные и создает модель, которая с высокой точностью описывает как форму тела и одежды, так и их оптические свойства. Разработка будет представлена на конференции SIGGRAPH Asia 2019, статья о ней <a href="https://augmentedperception.github.io/therelightables/">опубликована</a> на сайте авторов.</p>
      <p>Технологии захвата движения и создания виртуальных аватаров уже не первый год используются в различных сферах. Некоторые из них (например, те, которые применяют при съемках фильмов) основаны на захвате именно движений лица и других частей тела, записи чего потом используются для анимации другого персонажа. В тех случаях, когда важно сохранять внешний вид человека, используются системы из множества камер.</p>
      <p>Некоторым разработчикам в этой сфере удалось достичь достаточно качественных результатов. Например, Intel использует на некоторых спортивных стадионах систему, позволяющую воспроизводить повторы с любого ракурса. Однако такие системы не умеют собирать данные об оптических свойствах предметов и получаемую с их помощью модель нельзя реалистично перенести в окружение с другим освещением.</p>
      <p>Группа инженеров Google под руководством Пола Дебевека (Paul Debevec) и Шахрама Изади (Shahram Izadi) создала съемочный стенд и программное обеспечение, позволяющие создавать модель, реалистично отражающую как форму, так и оптические свойства человека в движении, а также переносить эту модель в другое окружение и подстраивать освещение под него.</p>
      <figure>
        <iframe src="https://www.youtube.com/embed/fj8n76shZ_g" width="620" height="349" data-service="Youtube" scrolling="no"/>
      </figure>
      <p>Стенд имеет практически сферическую конструкцию с проемом, через который входит человек. На стойках, из которых состоит сфера, установлен 331 блок освещения, каждый из которых состоит из отдельных светодиодов определенного цвета, 42 цветные камеры, а также 16 блоков захвата глубины, каждый из которых состоит из одной цветной и двух инфракрасных камер, и инфракрасного лазерного проектора. Поскольку система создает огромный объем данных, их обработка происходит на облачных серверах.</p>
      <figure>
        <img src="https://nplus1.ru/images/2019/11/15/3e13a9b31fbe36e27acc2c750e3b1641.jpg"/>
        <figcaption>Схема работы системы<cite>Kaiwen Guo et al. / SIGGRAPH Asia 2019</cite></figcaption>
      </figure>
      <p>Поделиться</p>
      <ul>
        <li/>
        <li/>
        <li/>
        <li/>
      </ul>
      <p>Во время работы лазер проецирует на человека инфракрасный узор, состоящий из тонких линий. Благодаря этому система может с высокой точностью восстанавливать форму человека, сравнивая получаемые инфракрасными данные с исходным узором. Светодиоды проецируют на человека свет с нужным пространственным распределением, причем они быстро (60 раз в секунду) чередуют два цветовых градиента, обратных друг другу. Это позволяет создавать не только карту распределения цвета на теле и одежде, но и карту отражения, которая позволяет в дальнейшем программным образом менять освещение человека, реалистично встраивая его в новое окружение.</p>
      <figure>
        <img src="https://nplus1.ru/images/2019/11/15/49ec85f32124247e42191b83fb1cedc8.jpg"/>
        <figcaption>Чередующиеся градиенты<cite>Kaiwen Guo et al. / SIGGRAPH Asia 2019</cite></figcaption>
      </figure>
      <p>Поделиться</p>
      <ul>
        <li/>
        <li/>
        <li/>
        <li/>
      </ul>
      <p>Авторы сравнили свою разработку с предыдущими похожими системами. Новая система позволяет получать модель с более высоким разрешением, а также меньшим количеством артефактов. Кроме того, она гораздо лучше работает с быстро движущимися в кадре объектами, к примеру, подбрасываемым мячом. Разработчики также создали демонстрационное приложение для смартфона, которое работает в режиме дополненной реальности и реалистично встраивает модель человека в мир перед смартфоном. Оно работает на основе предыдущей <a href="https://arxiv.org/abs/1904.01175">разработки</a>, которая определяет характеристики освещения и отражения объектов по данным с камеры.</p>
      <related>
        <a href="http://rusjev.net/2019/10/24/google-obyavil-o-dostizhenii-kvantovogo-prevoshodstva-teper-mir-izmenilsya/"/>
        <a href="http://rusjev.net/2017/06/27/evrosoyuz-oshtrafoval-google-na-2-4-milliarda-evro/"/>
        <a href="http://rusjev.net/2018/09/26/revolyutsiya-korporatsiya-google-zapatentovala-linzyi-proektoryi-dlya-ochkov/"/>
        <a href="http://rusjev.net/2019/03/28/polmilliarda-polzovateley-android-okazalis-uyazvimyi-dlya-atak-iz-za-brauzera/"/>
      </related>
    </article>
  </body>
</html>