<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <meta property="og:url" content="http://almanar.com.lb/5938396"/>
    <meta property="og:site_name" content="almanar.com.lb"/>
    <meta property="article:published_time" content="2019-11-11T00:00:00+00:00"/>
    <meta property="og:title" content="ذكاء اصطناعي خطير جداً في الأسواق"/>
    <meta property="og:description" content="أُطلِق ذكاء اصطناعيّ جديد في الأسواق على الرغم من أنّه كان يُعتبر في نظر مطوِّريه خطيراً جداً لدرجة لا يمكن طرحه للجمهور."/>
  </head>
  <body>
    <article>
      <h1>ذكاء اصطناعي خطير جداً في الأسواق</h1>
      <address>
        <time datetime="2019-11-11T00:00:00+00:00">11 Nov 2019</time>
      </address>
      <p>أُطلِق ذكاء اصطناعيّ جديد في الأسواق على الرغم من أنّه كان يُعتبر في نظر مطوِّريه خطيراً جداً لدرجة لا يمكن طرحه للجمهور.</p>
      <p>كانت المخاوف تعتري الباحثين بشأن النموذج الذي يحمل اسم “جي. بي. تي- 2” على اعتبار أنّه يملك قدرات هائلة بحيث يمكن أن يُستخدم بشكل ضار من جانب أيّ شخص، بدءاً بالسياسيين وصولاً إلى المخادعين الذين ينشرون أخباراً مزيّفة بغية تضليل روّاد الإنترنت.</p>
      <p>في الواقع، ابتكر المطوِّرون “جي. بي. تي- 2” لهدف واحد بسيط، إذ يستطيع هذا النموذج من الذكاء الاصطناعيّ، بعد تزويده بفقرة نصيّة مكتوبة، أن يتنبأ بالكلمات التالية التي يُفترض أن تُكمل النص حتى النهاية. وعبر اتباعه هذا النهج، يسعه إنشاء سلاسل طويلة من كتابات تتميّز بأنّها تشبه إلى حد كبير النصوص التي يكتبها البشر، بالتالي لا يمكن أن يكتشف المرء أنّها من ابتكار ذكاء اصطناعيّ.</p>
      <p>ولكن اتّضح أنّ النموذج كان جيّداً على نحو مثير للقلق في أداء تلك الوظيفة، إذ في مقدوره استحداث نص فائق القوة يمكن استغلاله في خداع الناس، وقد يقوِّض الثقة في الكتابات التي نقرأها من أخبار وغيرها.</p>
      <p>فضلاً عن ذلك، يمكن أن تستخدم الجماعات المتطرِّفة ذلك النموذج بشكل مؤذٍ فتستفيد منه في إنشاء “دعاية نصيّة من صنع الآلة”، تتيح لها تلقائياً كتابة خطابات أو مقالات طويلة تروِّج للفكر العنصريّ الذي ينادي بتفوّق العرق الأبيض أو تدعم الإسلاميين الجهاديين، على سبيل المثال.</p>
      <p>في هذا الصدد، نشرت “أوبين أي. آي” مؤسسة البحوث غير الربحية المتخصِّصة في الذكاء الاصطناعيّ مدونة في فبراير (شباط) الماضي تزامناً مع الإعلان عن النموذج، وذكرت فيها آنذاك أنّ “مخاوفنا بشأن التطبيقات التكنولوجيّة الضارة تحتّم علينا ألا نصدر النموذج الذي خضع للتدريب اللازم. ولكن كتجربة لاكتشاف أيّ ثغرات، نصدر عوض ذلك نموذجاً مصغّراً يكون في متناول الباحثين بهدف تجربته، فضلاً عن ورقة تقنيّة.”</p>
      <p>وفي فبراير (شباط) الماضي، ذكر الباحثون أنّ ثمة مجموعة متنوِّعة من الطرق يمكن أن يتكئ عليها المخادعون في استخدام البرنامج بطريقة تضرّ بالآخرين. من بين تلك الطرق، اللجوء إلى النص الذي يبتكره النموذج من أجل كتابة مقالات إخباريّة مضلِّلة، وانتحال صفة أشخاص آخرين، وإنشاء محتوى مسيء أو مزيف بشكل تلقائي على وسائل التواصل الاجتماعيّ، أو استخدام الذكاء الاصطناعيّ في إرسال رسائل غير مرغوب فيها إلى الناس… إلى جانب مجموعة متنوِّعة من الاستخدامات المحتملة التي ربما لم يكن يتصوّرها أحد.</p>
      <p>كذلك قالوا إن مثل تلك الاستخدامات المسيئة ستتطلّب من الجمهور أن يكون أكثر حذراً وانتقاداً بشأن النص الذي يقرأه عبر الإنترنت، إذ يُحتمل أن يكون من صنع الذكاء الاصطناعيّ.</p>
      <p> </p>
      <p><b>المصدر: </b>الاندبندنت</p>
    </article>
  </body>
</html>