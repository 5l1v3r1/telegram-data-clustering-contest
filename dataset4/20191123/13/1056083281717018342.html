<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <meta property="og:url" content="https://www.isna.ir/news/98090200959/%D8%A7%D8%A8%D8%AF%D8%A7%D8%B9-%D8%A7%D9%84%DA%AF%D9%88%D8%B1%DB%8C%D8%AA%D9%85-%D9%87%D8%A7%DB%8C%DB%8C-%D8%A8%D8%B1%D8%A7%DB%8C-%D8%A7%D8%B5%D9%84%D8%A7%D8%AD-%D8%B1%D9%81%D8%AA%D8%A7%D8%B1-%D9%87%D9%88%D8%B4-%D9%85%D8%B5%D9%86%D9%88%D8%B9%DB%8C"/>
    <meta property="og:site_name" content="ایسنا"/>
    <meta property="article:published_time" content="2019-11-23T13:06:30+00:00"/>
    <meta property="og:title" content="ابداع الگوریتم‌هایی برای اصلاح رفتار هوش مصنوعی"/>
    <meta property="og:description" content="پژوهشگران &quot;دانشگاه استنفورد&quot;، الگوریتم‌هایی را ابداع کرده‌اند تا به اصلاح رفتارهای منفی مانند تبعیض در سیستم‌های مبتنی بر هوش مصنوعی کمک کنند."/>
  </head>
  <body>
    <article>
      <h6 class="kicker">در "دانشگاه استنفورد" صورت گرفت</h6>
      <h1>ابداع الگوریتم‌هایی برای اصلاح رفتار هوش مصنوعی</h1>
      <address><time datetime="2019-11-23T13:06:30+00:00">23 Nov 2019, 13:06</time> by <a rel="author">مسعود جعفرشعار</a></address>
      <p>پژوهشگران "دانشگاه استنفورد"، الگوریتم‌هایی را ابداع کرده‌اند تا به اصلاح رفتارهای منفی مانند تبعیض در سیستم‌های مبتنی بر هوش مصنوعی کمک کنند.</p>
      <p><b>به گزارش ایسنا و به نقل از وب سایت رسمی دانشگاه استنفورد، </b>شاید به زودی امکان داشتن رفتار بهتر برای ربات‌ها، خودروهای خودران و دیگر ماشین‌های هوشمند فراهم شود. پژوهشگران "دانشگاه استنفورد"(stanford university)، روش جدیدی ارائه داده‌اند تا به طراحان حوزه یادگیری ماشینی کمک کنند که کاربردهای هوش مصنوعی را با دوری از مواردی مانند تبعیض جنسیتی یا نژادی افزایش دهند.</p>
      <p>هوش مصنوعی به خاطر پیشرفت الگوریتم‌های یادگیری ماشینی که رایانه‌ها را برای کارهایی مانند راندن خودرو، کنترل ربات‌ها یا تصمیم‌گیری خودکار آموزش می‌دهند، در حال ورود به حوزه تجاری است. در هر حال همان گونه که هوش مصنوعی، اداره کارهای حساس را به دست می‌گیرد، می‌تواند پیامدهای منفی مانند تبعیض نژادی یا جنسیتی را نیز به همراه داشته باشد.</p>
      <p>دانشگاه استنفورد با همکاری پژوهشگران "دانشگاه ماساچوست در امهرست"(UMass)، روشی ارائه داده‌اند تا اطمینان لازم را برای استفاده از هوش مصنوعی فراهم کنند. هدف آنها از ابداع این روش، جلوگیری از پیش آمدن تبعیض‌ با ارائه معیاری است که این امکان را برای الگوریتم یادگیری ماشینی فراهم می‌کند تا هوش مصنوعی را برای دوری از چنین رفتارهایی آموزش دهد.</p>
      <p>"اما برونسکیل"(Emma Brunskill)، استادیار علوم رایانه دانشگاه استنفورد و از نویسندگان این پژوهش گفت: ما قصد داریم هوش مصنوعی را آنقدر ارتقا دهیم تا بتواند ارزش‌های انسانی را رعایت کند و قابلیت لازم را برای استفاده در سیستم‌های خودران به دست آورد.</p>
      <p>
        <b> پیشگیری از رفتارهای منفی</b>
      </p>
      <p>فرضیه پژوهشگران این بود که اگر بتوان رفتارهای غیر ایمن یا ناعادلانه را به صورت ریاضی تعریف کرد، ابداع الگوریتم‌هایی که می‌توانند دوری از چنین رفتاری را از داده‌ها یاد بگیرند نیز باید امکان‌پذیر شود.</p>
      <p>پژوهشگران تصمیم گرفتند روش‌هایی ابداع کنند که کاربران بتوانند با استفاده از آنها، رفتارهای نامطلوب را مشخص کنند و از عهده پیش‌بینی رفتار سیستم با استفاده از داده‌ها برآیند.</p>
      <figure>
        <img src="https://cdn.isna.ir/d/2019/11/23/3/61492560.jpg"/>
      </figure>
      <p>"فیلیپ توماس"(Philip Thomas)، استادیار علوم رایانه دانشگاه ماساچوست در امهرست و نویسنده ارشد این پژوهش گفت: ما در این پژوهش نشان داده‌ایم که چگونه طراحان الگوریتم‌های یادگیری ماشینی می‌توانند به افرادی که می‌خواهند هوش مصنوعی را برای ارائه محصولات و خدمات خود به کار ببرند، کمک کنند تا رفتارهای سیستم هوش مصنوعی را تحت کنترل درآورند.</p>
      <p>
        <b>عدالت و اطمینان</b>
      </p>
      <p>پژوهشگران، به آزمایش روش جدید خود پرداختند تا به بهبود الگوریتم‌هایی که نمرات دانشجویان را بر اساس نتیجه امتحانات آنها پیش‌بینی می‌کنند، کمک کنند. آنها در این آزمایش، دستورالعمل‌های ریاضی را با استفاده از یک مجموعه داده آزمایشی انجام دادند تا یک روش پیش‌بینی را برای پیش‌بینی نمره دانشجویان ارائه دهند.</p>
      <p>الگوریتم هوش مصنوعی با کمک این دستورالعمل‌ها توانست روش بهتری را برای پیش‌بینی نمرات ارائه دهد که تبعیض‌های جنسیتی آن بسیار کمتر از دیگر روش‌های کنونی بود. روش‌های پیشین، هیچ محدودیتی در زمینه عدالت و اطمینان نداشتند و محدودیت آنها نیز بیش از حد بود.</p>
      <p>این پژوهش، در مجله "Science" به چاپ رسید.</p>
      <p>انتهای پیام</p>
    </article>
  </body>
</html>