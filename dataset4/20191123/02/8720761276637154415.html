<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <meta property="og:url" content="https://tech.slashdot.org/story/19/11/23/0231216/what-caused-ubers-fatal-2018-crash-ntsb-reveals-its-findings?utm_source=atom1.0mainlinkanon&amp;utm_medium=feed"/>
    <meta property="og:site_name" content="tech.slashdot.org"/>
    <meta property="article:published_time" content="2019-11-23T02:34:00+00:00"/>
    <meta property="og:title" content="What Caused Uber's Fatal 2018 Crash? NTSB Reveals Its Findings"/>
    <meta property="og:description" content="This week America's National Transportation Safety Board presented its findings on the fatal 2018 crash of a Uber test robocar with a pedestrian in Arizona. Forbes reports: The NTSB's final determination of probable cause put primary blame on the safety driver's inattention. Contributory causes we..."/>
  </head>
  <body>
    <article>
      <h1>What Caused Uber's Fatal 2018 Crash? NTSB Reveals Its Findings</h1>
      <address><time datetime="2019-11-23T02:34:00+00:00">23 Nov 2019, 02:34</time> by <a rel="author">EditorDavid</a></address>
      <p>This week America's National Transportation Safety Board presented its findings on <a href="https://tech.slashdot.org/story/18/03/19/1736231/self-driving-uber-car-kills-arizona-woman-in-first-fatal-crash-involving-pedestrian">the fatal 2018 crash of a Uber test robocar with a pedestrian</a> in Arizona. Forbes reports: <i>The NTSB's final determination of probable cause <a href="https://www.forbes.com/sites/bradtempleton/2019/11/19/ntsb-hearing-blames-humans-software-and-policy-for-fatal-uber-robocar-crash/">put primary blame on the safety driver's inattention</a>. Contributory causes were Uber's lack of safety culture, poor monitoring of safety drivers, and lack of countermeasures for automation complacency. They put tertiary blame on the pedestrian's impaired crossing of the road, and the lack of good regulations at the Arizona and Federal levels... When it comes to human fault, the report noted that [pedestrian] Herzberg had a "high concentration of methamphetamine" (more than 10 times the medicinal dose) in her blood which would alter her perception. She also had some marijuana residue. She did not look to her right at the oncoming vehicle until 1 second before the crash. <br/><br/>There was also confirmation that the safety driver had indeed pulled out a cell phone and <a href="https://tech.slashdot.org/story/18/06/22/1914225/uber-driver-was-streaming-hulu-just-before-fatal-self-driving-car-crash-says-police">was streaming a TV show on it</a>, looking down at it 34% of the time during her driving session, with a full 5 second "glance" from 6 to 1 seconds prior to the impact. While Uber recorded videos of safety drivers, they never reviewed those of this driver to learn that she was violating the policy against cell phone use. She had received no reprimands, and driven this stretch of road 73 times before... Had the vehicle operator been attentive, she would likely have had sufficient time to detect and react to the crossing pedestrian to avoid the crash or mitigate the impact. The vehicle operator's prolonged visual distraction, a typical effect of automation complacency, led to her failure to detect the pedestrian in time to avoid the collision. The Uber Advanced Technologies Group did not adequately recognize the risk of automation complacency and develop effective countermeasures to control the risk of vehicle operator disengagement, which contributed to the crash... The detrimental effect of the company's ineffective oversight was exacerbated by its decision to remove the second vehicle operator during testing of the automated driving system...<br/><br/>Most notably, they do not attribute the technology failures as causes of the crash. This is a correct cause ruling -- all tested vehicles, while generally better than Uber's, have flaws which would lead to a crash with a negligent safety driver, and to blame those flaws would be to blame the idea of testing this way at all.</i> <br/>Forbes also notes the report criticizes Arizona's "shortcomings" in safeguarding the public because of the state's lack of a safety-focused application-approval process for automated driving system testing. <br/><br/>The article adds that today Uber "is only doing very limited testing -- just a one mile loop around their HQ limited to 25 miles per hour."</p>
      <aside>
        <b>
          <a href="https://www.forbes.com/sites/bradtempleton/2019/11/19/ntsb-hearing-blames-humans-software-and-policy-for-fatal-uber-robocar-crash/">(forbes.com)</a>
        </b>
      </aside>
    </article>
  </body>
</html>