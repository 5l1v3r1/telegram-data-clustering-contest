<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <meta property="og:url" content="https://futurism.com/the-byte/google-stop-training-ai-homeless-peoples-faces"/>
    <meta property="og:site_name" content="Futurism"/>
    <meta property="article:published_time" content="2019-11-22T00:00:00+00:00"/>
    <meta property="og:title" content="Google Decides to Stop Training AI on Homeless People’s Faces"/>
    <meta property="og:description" content="Google is reportedly ending its controversial program where it scanned homeless people's faces and turned them into AI training data."/>
  </head>
  <body>
    <article>
      <h1>Google Decides to Stop Training AI on Homeless People’s Faces</h1>
      <address><time datetime="2019-11-22T00:00:00+00:00">22 Nov 2019</time> by <a rel="author">Dan Robitzski</a></address>
      <h3>Fixing AI</h3>
      <p>Google has announced that it’s ending a controversial program that <a href="https://futurism.com/google-homeless-people-face-scans">targeted homeless black people</a> and scanned their faces to create AI training data in exchange for measly $5 gift cards.</p>
      <p>After an internal investigation prompted by news reports about the practice, Google says it’s no longer sending third-party contractors out to gather face scans, <a href="https://www.nydailynews.com/news/national/ny-google-admits-finding-policy-violations-facial-recognition-project-20191121-gn4hmahb4zeoncxnabxb2dfxz4-story.html">according to <i>New York Daily News</i></a>. Instead, it will gather faces exclusively within Google campuses. But, bizarrely, a Google spokesperson is still defending the now-cancelled program.</p>
      <h3>Diversity Problem</h3>
      <p>The original goal was to acquire face scans of dark-skinned people so that Google could present its facial recognition algorithms with a more diverse set of training data, <a href="https://futurism.com/microsoft-announces-tool-catch-biased-ai">a longstanding problem</a> within AI that has led to <a href="https://futurism.com/human-rights-discriminatory-artificial-intelligence">widespread algorithmic bias</a> against black people and other racial minorities.</p>
      <p>To that end, a Google spokesperson told <i>NY Daily News</i> that the program was “important and necessary.”</p>
      <h3>Covert Ops</h3>
      <p>Google’s contractors told <i>NY Daily News</i> that they felt pressured to gather as many faces as possible, often feeling the need to rush people through their consent forms. Some reportedly went into college campuses dressed in casual clothing, scanning students’ faces and telling them very little about what the data would be used for.</p>
      <p>“Going forward, the work will be done on Google sites only, to ensure we have better control over the research and the interactions with participants,” the company spokesperson said.</p>
      <p><b>READ MORE: </b><a href="https://www.nydailynews.com/news/national/ny-google-admits-finding-policy-violations-facial-recognition-project-20191121-gn4hmahb4zeoncxnabxb2dfxz4-story.html">Google admits its ‘dark skin’ face scan project violated internal policy, leading to overhaul of data collection after Daily News exposé</a> [<i>New York Daily News</i>]</p>
      <p>
        <b>More on AI: </b>
        <i>
          <a href="https://futurism.com/google-homeless-people-face-scans">Google Contractors Tricked Homeless Black People Into Face Scans</a>
        </i>
      </p>
    </article>
  </body>
</html>