<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <meta property="og:url" content="https://www.calcalist.co.il/conference/articles/0,7340,L-3774447,00.html"/>
    <meta property="og:site_name" content="כלכליסט - www.calcalist.co.il"/>
    <meta property="article:published_time" content="2019-11-25T00:00:00+00:00"/>
    <meta property="og:title" content="ד&quot;ר איה סופר: &quot;איך אפשר להפוך AI להוגנת? פשוט לבחון, לדווח ולתקן&quot;"/>
    <meta property="og:description" content="מנהלת מחקר ה-AI של IBM העולמית התייחסה בוועידת Mind The Tech TLV של כלכליסט ובנק לאומי לתחום השקיפות והשוותה את הבינה המלאכותית לתוויות המזון שמפרטות אילו רכיבים יש בו. &quot;אפשר לתת אמון במערכות בינה מלאכותית בתנאי שיש לנו את המידע המתאים&quot;, הדגישה"/>
  </head>
  <body>
    <article>
      <h1>ד"ר איה סופר: "איך אפשר להפוך AI להוגנת? פשוט לבחון, לדווח ולתקן"</h1>
      <h2>מנהלת מחקר ה-AI של IBM העולמית התייחסה בוועידת Mind The Tech TLV של כלכליסט ובנק לאומי לתחום השקיפות והשוותה את הבינה המלאכותית לתוויות המזון שמפרטות אילו רכיבים יש בו. "אפשר לתת אמון במערכות בינה מלאכותית בתנאי שיש לנו את המידע המתאים", הדגישה</h2>
      <address><time datetime="2019-11-25T00:00:00+00:00">25 Nov 2019</time> by <a rel="author">הגר רבט</a></address>
      <p>"מה נדרש כדי שנוכל לתת אמון בהחלטות שנעשות על ידי בינה מלאכותית?" שואלת ד"ר <a href="https://www.calcalist.co.il/internet/articles/0,7340,L-3739955,00.html">איה סופר</a>, מנהלת מחקר ה-AI של IBM העולמית, בוועידת Mind The Tech TLV של כלכליסט ובנק לאומי.</p>
      <p>"כבר היום בינה מלאכותית (AI) משמשת ככלי עזר בארגונים להחלטות קריטיות - האם לקבל עובד לעבודה ובאיזה שכר, האם לקבל סטודנט לאוניברסיטה ובארה"ב גם במערכת השיפוט והענשיה לקציבת עונשים".</p>
      <p>לדבריה במעבדות של IBM "זיהינו במעבדות שלנו 4 שאלות מרכזיות:</p>
      <p>1. האם המערכת הוגנת</p>
      <p>2. האם אפשר להבין מדוע קיבלה את ההחלטה</p>
      <p>3. האם אני יכולה להיות בטוחה שלא חיבלו בה</p>
      <p>4. האם יש שקיפות במערכת"</p>
      <p>"אז איך אפשר להפוך AI להוגנת?", שואלת סופר, "רק לפני שבוע שמענו על מערכת שנתנה קו אשראי גבוה פי 20 לגבר מאשר לאישה עם פרמטרים דומים. התשובה היא לבחון, לדווח ולתקן. מה לבחון? את הדאטה, המודלים והתוצאות".</p>
      <figure>
        <img src="https://images1.calcalist.co.il/PicServer3/2019/11/25/949879/2_l.jpg"/>
        <figcaption>ד"ר איה סופר <br/>צילום: יריב כץ</figcaption>
      </figure>
      <p>סופר הראתה דוגמה למערכת שממליצה האם לתת הלוואה ללקוח מסוים. במקרה זה המערכת זיהתה שאמריקאי ממוצא אינדיאני מקבל אישור רק 75% מהמקרים בהשווואה למשל ל-90% עבור אמריקאים ממוצא אסיאתי. החשיבות, היא מדגישה, שהמערכת זיהתה את הבעיה והתריעה עליה.</p>
      <p>"לגבי השאלה מה עומד מאחורי המערכת", אמר סופר, "זו שאלה מורכבת משום שלכל צד אינטרסים שונים, במקרה הזה למשל הצדדים של הלווה, המלווה והרגולטור. כמה מהפתרונות האפשריים הם למשל לבחור במודלים שהם יותר ברי הסברה. דוגמה פשוטה אחת מהמערכת שלנו היא הסבר מה נכנס לשקלול שהביא לאישור ההלוואה, גורמים בעד ונגד.</p>
      <p>"נושא החבלה הוא נושא מאוד חם בעולם היום", אומרת סופר ומספקת כמה דוגמאות לדרכים לעיוות מידע או היתול במערכת המתמחה בזיהוי פנים. "המערכת של IBM מדמה סוגי התקפות ומתאימה להן הגנות הולמות", אמרה.</p>
      <p>בתחום השקיפות סופר משווה את הבינה המלאכותית לתוויות המזון שמפרטות אילו רכיבים יש בו ואומרת שבעתיד יש להכיל סטנדרטים דומים על כלי בינה מלאכותית.</p>
      <p>"אפשר לתת אמון במערכות בינה מלאכותית בתנאי שיש לנו את המידע המתאים, אני ממליצה שכל ארגון שרוצה לעשות שימוש בבינה מלאכותית ייפתח כלי בדיקה כמו אלה שהראיתי עכשיו", אמרה סופר. </p>
    </article>
  </body>
</html>