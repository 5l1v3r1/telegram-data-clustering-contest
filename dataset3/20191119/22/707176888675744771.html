<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <meta property="og:url" content="https://www.ft.com/content/6d0c5544-0afb-11ea-bb52-34c8d9dc6d84"/>
    <meta property="og:site_name" content="Financial Times"/>
    <meta property="article:published_time" content="2019-11-19T22:16:20+00:00"/>
    <meta property="og:title" content="Uber back-up driver faulted in fatal autonomous car crash"/>
    <meta property="og:description" content="Regulator criticises company’s ‘safety culture’ and failure to prevent ‘automation complacency’"/>
  </head>
  <body>
    <article>
      <h1>Uber back-up driver faulted in fatal autonomous car crash</h1>
      <h2>Regulator criticises company’s ‘safety culture’ and failure to prevent ‘automation complacency’</h2>
      <address><time datetime="2019-11-19T22:16:20+00:00">19 Nov 2019, 22:16</time> by <a rel="author">Patrick McGee</a></address>
      <p>The primary cause of a <a href="https://www.ft.com/content/1e2a73d6-2b9e-11e8-9b4b-bc4b9f08f381">fatal accident</a> involving a self-driving Uber in March 2018 was the safety driver’s failure to monitor the road, the US National Transportation Safety Board determined on Tuesday, with Uber’s “inadequate <a href="https://www.ft.com/content/2c3d8efc-5fb2-11e8-9334-2218e7146b04">safety culture</a>” only listed as a contributing factor.</p>
      <p>The accident in Tempe, Arizona, was believed to be the first time an autonomous car had killed a pedestrian, prompting Uber to <a href="https://www.ft.com/content/771300d6-03ce-11e9-99df-6183d3002ee1">suspend testing</a> for several months and intensifying a debate about the safety of the nascent industry.</p>
      <p>At a public hearing in Washington, three board members from the NTSB unanimously approved 19 findings about the incident and recommended six new safety regulations to improve oversight of the testing of self-driving cars.</p>
      <p>The NTSB said the safety driver, Rafaela Vasquez, had taken a cell phone from her bag, placed it below the dashboard, and was “streaming a television show” in the lead-up to the crash.</p>
      <p>Using her cell phone violated Uber’s policies, but the NTSB said Uber’s oversight was “ineffective” and it criticised the car-booking giant for “a lack of adequate mechanisms for addressing operator’s automation complacency”.</p>
      <p>In the 31-minute journey, she spent 34 per cent of her time glancing at the phone, with one glance lasting 26 seconds. Her final glance was six seconds before impact.</p>
      <p>The pedestrian killed was 49-year old Elaine Herzberg, who was struck by the Volvo SUV outfitted with Uber self-driving technology, travelling 39mph, as she crossed the street with a bicycle.</p>
      <p>The NTSB also placed cause on the victim, noting Ms Herzberg had “a very high level of methamphetamine in her body postmortem” and likely experienced “diminished perception resulting from drug use”.</p>
      <blockquote>There is a major failing on the federal government’s part and the state of Arizona . . . for failing to regulate these operations<cite>Jennifer Homendy, NTSB board member</cite></blockquote>
      <p>The National Highway Traffic Safety Administration came under heavy fire, as did the Arizona Department of Transportation, for its “insufficient oversight of automated vehicle testing”.</p>
      <p>NTSB board member Jennifer Homendy ridiculed NHTSA’s safety guidelines, noting one of them was that self-driving groups “should consider the possible scenario of another vehicle crashing into them”.</p>
      <p>She responded: “Duh. I would hope that is a requirement.”</p>
      <p>Each of six safety recommendations involve measures to make the testing of self-driving cars more rigorous, transparent, and standardised. Two were for NHTSA, two were for Arizona, one was for American Association of Motor Vehicle Administrators and the final one was for Uber.</p>
      <p>The most significant was for NHTSA to make its safety assessments mandatory.</p>
      <p>“There is a big difference between the words ‘should’, ‘encouraged to’ and ‘shall’,” Ms Homendy said. “And so I actually think that there is a major failing on the federal government’s part and the state of Arizona, because they also didn’t have any standards in place and still don’t, for failing to regulate these operations.”</p>
      <p>NTSB vice-chairman Bruce Landsberg added: “Aircraft are child’s play compared to the challenges we have on [self-driving cars]. This is extremely complex . . . And I think the role of the federal and state agencies is to ensure that the process of this testing is done safely at both levels. And I’m not sure that we’re seeing that.”</p>
      <h3>Recommended</h3>
      <p><a href="https://www.ft.com/brooke-masters">Brooke Masters <br/></a><a href="https://www.ft.com/content/39c01b56-9be5-11e9-9c06-a4640c9feebb"> It is difficult for self-driving car companies to go it alone <br/></a>Tuesday, 2 July, 2019</p>
      <p>As the findings spread the blame, the hearing is likely to be seen as a win for Uber.</p>
      <p>NTSB chairman Robert Sumwalt concluded the event by saying Uber had learned lessons from the tragedy. “Uber has truly embraced those lessons, and we want to encourage them to continue on that journey,” he said.</p>
      <p>“Over the last 20 months, we have provided the NTSB with complete access to information about our technology and the developments we have made since the crash,” said Nat Beuse, head of safety at Uber’s advanced technologies group, which is developing self-driving cars.</p>
      <p>“While we are proud of our progress, we will never lose sight of what brought us here or our responsibility to continue raising the bar on safety,” he added.</p>
    </article>
  </body>
</html>