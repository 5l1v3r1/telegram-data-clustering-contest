<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <meta property="og:url" content="https://www.heise.de/newsticker/meldung/Nvidia-CUDA-fuer-ARM-Supercomputer-4589725.html"/>
    <meta property="og:site_name" content="c't Magazin"/>
    <meta property="article:published_time" content="2019-11-19T01:00:00+00:00"/>
    <meta property="og:title" content="Nvidia CUDA für ARM-Supercomputer"/>
    <meta property="og:description" content="Nvidia will Tesla-Karten auch für ARM-Supercomputer verkaufen und die I/O-Performance bei Clustern verbessern."/>
  </head>
  <body>
    <article>
      <h1>Nvidia CUDA für ARM-Supercomputer</h1>
      <h2>Nvidia will Tesla-Karten auch für ARM-Supercomputer verkaufen und die I/O-Performance bei Clustern verbessern.</h2>
      <address><time datetime="2019-11-19T01:00:00+00:00">19 Nov 2019, 01:00</time> by <a rel="author">Christof Windeck</a></address>
      <p>Nvidia-Tesla-Rechenbeschleuniger lassen sich künftig auch in Systemen mit ARMv8-CPUs nutzen. CUDA-X ist ab sofort in einer Preview-Version erhältlich, die auf Servern mit Marvell ThunderX2, Ampere A1 und Fujitsu A64FX mit Tesla-(V100-)Karten läuft. Damit fügt Nvidia nach x86-Prozessoren (von AMD und Intel) sowie IBM Power/OpenPower eine dritte CPU-Familie zu CUDA hinzu.</p>
      <p>Schon in der vor-vorletzten Top500-Liste waren <a href="https://www.heise.de/meldung/Supercomputer-erste-ARM-und-Epyc-Rechner-in-der-Top500-Liste-4218568.html">erste Supercomputer mit ARM-Prozessoren</a> aufgetaucht; in Zukunft dürfte das Angebot deutlich wachsen, vor allem auch durch die <a href="https://www.heise.de/meldung/Cray-und-Fujitsu-bauen-gemeinsam-Exascale-Supercomputer-mit-ARM-Prozessoren-4587915.html">Kooperation zwischen HPE/Cray und Fujitsu</a> bei A64FX-Systemen. Aber auch die <a href="https://www.heise.de/ct/artikel/Bit-Rauschen-AMDs-neuer-16-Kerner-Radeon-Lizenz-EU-CPU-4449734.html">European Processor Initiative (EPI) setzt auf ARM</a> (und RISC-V) und mit <a href="https://www.heise.de/meldung/Drei-ehemalige-Apple-Mitarbeiter-gruenden-neue-Firma-fuer-Server-Chips-4587724.html">Nuvia</a> könnte ein weiterer ARM-Server-SoC-Hersteller hinzukommen. Nvidia hatte CUDA für ARM allerdings schon <a href="https://www.heise.de/meldung/Supercomputing-Nvidia-glaenzt-durch-Abwesenheit-und-viele-Ankuendigungen-4448755.html">auf der ISC19 angekündigt</a>.</p>
      <h3>Schnelleres I/O</h3>
      <p>Außerdem kündigt Nvidia das Software-Paket Magnum IO an, um I/O-Operationen beim Rechnen auf Clustern mit Tesla-Karten zu beschleunigen. Magnum IO stellt dazu einen Datenpfad bereit, der die CPU umgeht und direkt auf schnelle Netzwerkkarten zugreift.</p>
      <p>Nividia kooperiert bei Magnum IO mit IBM, Excelero, DataDirect Networks, WekaIO und dem im Frühjahr übernommenen Interconnect-Spezialisten Mellanox. Die Magnum-IO-Funktion GPUDirect Storage soll erst ab 2020 nutzbar sein. <a href="https://developer.nvidia.com/gpudirect">Andere GPUDirect-Funktionen</a> gibt es bei Nvidia schon seit 2010.</p>
      <h3>Tesla-V100-Supercomputer zum Mieten</h3>
      <p>Anlässlich der HPC-Konferenz Supercomputing SC'19 kündigt Nvidia außerdem an, dass Microsoft Azure nun auch extrem leistungsfähige <a href="https://docs.microsoft.com/de-de/azure/virtual-machines/windows/sizes-gpu#ndv2-series-preview">NDv2-Instanzen</a> offeriert, bei denen sich bis zu 800 Tesla-V100-Beschleuniger über Infiniband-Dapter von Meallnox koppeln lassen. (<a href="mailto:ciw@ct.de">ciw</a>)</p>
    </article>
  </body>
</html>