<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <meta property="og:url" content="https://www.usine-digitale.fr/article/pourquoi-l-ethique-de-l-intelligence-artificielle-en-sante-est-elle-un-faux-debat.N904944"/>
    <meta property="og:site_name" content="L'Usine Digitale"/>
    <meta property="article:published_time" content="2019-11-19T07:00:00+00:00"/>
    <meta property="og:title" content="Pourquoi l'éthique de l'intelligence artificielle en santé est-elle un faux débat ?"/>
    <meta property="og:description" content="Nombreux sont les discours et les rapports officiels qui débattent sur le cadre éthique qu'il conviendrait d'imposer à l'IA dans le domaine de la santé. Ethique et droit sont alors très souvent confondus. Pourtant, derrière ces considérations étymologiques se cache une véritable problématique, abordée lors d'un colloque consacré aux données de santé : la violation d'un principe éthique n'équivaut pas à celle d'un principe juridiquement obligatoire."/>
  </head>
  <body>
    <article>
      <h1>Pourquoi l'éthique de l'intelligence artificielle en santé est-elle un faux débat ?</h1>
      <address><time datetime="2019-11-19T07:00:00+00:00">19 Nov 2019, 07:00</time> by <a rel="author" href="https://www.usinenouvelle.com/la-redaction/alice-vitard.14315" target="_blank">Alice Vitard</a></address>
      <figure>
        <img src="https://www.usine-digitale.fr/mediatheque/9/7/8/000821879_homePageUne/e-sante-logo.jpg"/>
        <figcaption>Pourquoi l'éthique de l'intelligence artificielle en santé est-elle un faux débat ?<cite>© Pixabay/rawpixel</cite></figcaption>
      </figure>
      <p>"<i>L'éthique pratique de l'intelligence artificielle en santé"</i>. C'est en ces termes que le colloque consacré aux données de santé, organisé par le ministère des Solidarités et de la Santé le 18 novembre 2019, a décidé d'aborder les risques liés à l'utilisation de l'intelligence artificielle dans ce secteur. Un thème très intéressant même s'il cache un problème majeur : l'éthique n'est jamais définie et sert, le plus souvent, à édulcorer le débat. Explications.</p>
      <p>Le terme "éthique" vient du grec <i>éthos</i> qui fait référence aux mœurs. L'éthique a pour fonction de transposer la morale dans le fonctionnement et la dynamique de la société. Bien évidemment, l'IA en santé doit respecter des principes éthiques, mais ce n'est qu'un préalable. L'IA doit aussi et surtout respecter la loi.</p>
      <h3>Distinguer éthique et droit</h3>
      <p>En mars 2018, Cédric Villani a remis <a href="https://www.aiforhumanity.fr/pdfs/9782111457089_Rapport_Villani_accessible.pdf">un rapport</a> intitulé "<i>Donner du sens à l'intelligence artificielle : pour une stratégie nationale et européenne</i>". La partie cinq traitait de l'éthique mais mélangeait complètement les notions. "<i>Elles (ces discussions) ont investi l’espace disponible entre ce qui est rendu possible par l’IA et ce qui est permis par la loi pour discuter de ce qui est souhaitable</i>", peut-on lire. Un problème similaire s'est posé dans <a href="https://ec.europa.eu/commission/news/artificial-intelligence-2019-apr-08_fr">la proposition</a> de la Commission européenne sur une "<i>IA digne de confiance</i>", publiée en avril 2019.</p>
      <p>Parmi les sept "<i>éléments essentiels"</i>, on trouve le respect de la vie privée, la non-discrimination ou encore la responsabilisation. Certes, ces principes appliqués spécifiquement à l'IA n'existent pas encore par le droit européen. Mais ils sont présents dans plusieurs textes généraux et donc ne relèvent pas seulement de considérations éthiques. Il est indispensable de bien distinguer l'éthique du droit car ce dernier est strictement cadré et obéit à des règles claires, son non-respect entraînant des sanctions. L'éthique en comparaison est un concept vague qui ne saurait se substituer au droit comme point de référence.</p>
      <h3>Un logiciel discriminatoire donc illégal</h3>
      <p>Pour entraîner les systèmes à base d'IA, le monde de la santé utilise des données récoltées par différents organismes publiques comme les établissements hospitaliers ou le système national d'information inter-régimes de l'Assurance maladie (SNIIRAM). Ainsi, un système a été mise en place par deux établissements de l'Assistance publique-Hôpitaux de Paris (AP-HP) pour <a href="https://www.usine-digitale.fr/article/l-ap-hp-experimente-un-dispositif-d-aide-a-la-detection-precoce-du-cancer-colorectal-base-sur-l-ia.N895394">détecter précocement un cancer colorectal</a>. Or les informations traitées sont particulières car elles abordent l'état de santé des citoyens. Soucieux de leur haut niveau de protection, le Règlement général sur la protection des données (RGPD) procède d'ailleurs à <a href="https://www.cnil.fr/fr/quest-ce-ce-quune-donnee-de-sante">une définition très large des données de santé</a> qui comprennent les informations relatives à une personne physique, les informations obtenues lors d'un test ou d'un examen d'une partie du corps et celles concernant une maladie.</p>
      <p>La France n'a pas (encore) été le théâtre de dérapages de systèmes automatisés de ce type mais ce n'est pas le cas de tous les Etats. Pour ne citer qu'un exemple, un <a href="https://www.washingtonpost.com/">article</a> du <i>Washington Post</i> publié le 24 octobre 2019 relayait <a href="https://science.sciencemag.org/content/366/6464/447">une étude</a> de la revue <i>Science</i>. Cette dernière prouvait que des millions de patients noirs, aux <a href="https://www.usinenouvelle.com/etats-unis/">Etats-Unis</a>, avaient bénéficié de soins de qualité moindre à cause de leur couleur de peau. Utilisé par de nombreux médecins, l'algorithme devait évaluer le risque d'une personne de développer des problèmes de santé graves. Selon lui, les personnes à la peau noire présentaient moins de risques que les personnes à la peau blanche. Par conséquent, on leur prescrivait moins d'examens et de traitements médicaux. En fait, ces conclusions étaient liées à un biais algorithmique.</p>
      <p>En 2018, le Centre national des statistiques de santé déclarait que 9% de la population vivait sans couverture maladie, dispositif très coûteux aux Etats-Unis. Dans ce pourcentage, les personnes noires étaient surreprésentées. L'algorithme aurait donc seulement intégré qu'elles dépensaient moins d'argent dans les soins de santé sans prendre en compte les raisons. Le système estimait alors que moins d'argent dépensé est équivalent à "moins de soucis de santé". En bref, le logiciel était discriminatoire.</p>
      <p>Cela pose évidemment un problème éthique... mais pas que. Le droit interdit toute différence de traitement fondé sur la couleur de peau. Ce principe est reconnu au niveau international par la Convention sur l'élimination de toutes les formes de discrimination raciale adoptée le 4 janvier 1969. Ce logiciel est donc tout simplement illégal. Ne réfléchir que par le prisme de l'éthique pourrait fausser le débat, car cela signifierait que l'utilisation de systèmes discriminatoires est laissée à l'appréciation des Etats et des acteurs privés, sans d'autre contrainte que leur moralité.</p>
      <h3>De l'éthique-washing ?</h3>
      <p>Dans les débats autour des innovations technologies, l'éthique est en fait une notion vide de sens et qu'il est facile de manipuler. Il faut dire que ce mot a bonne presse et est plutôt valorisant. Plusieurs personnes plaident notamment pour la création d'un label "IA éthique", qui permettrait de rassurer les usagers d'une bonne utilisation de leurs données. Mais c'est également un bon stratagème pour vendre une solution sans être trop embêté par des questions réglementaires, en profitant de l'assimilation de l'éthique au droit. En bref, les entreprises pourraient elles-mêmes se déclarer "RGPD safe", un peu à la matière de "l'auto-régulation" que prêchent les GAFAM.</p>
      <h3>Le droit s'adapte difficilement</h3>
      <p>Les critiques formulées précédemment n'empêchent pas de pointer du doigt l'inadaptation du droit face à l'IA en santé. Contrairement aux normes, la notion d'éthique évolue beaucoup plus facilement car elle ne se s'encombre pas de la procédure législative, caractéristique essentielle de la démocratie représentative. La transformation de la société sous l'effet du numérique est d'ailleurs mal appréhendée par le droit de manière générale, ce dernier étant accusé d'être constamment en retard. Mais ce n'est pas pour cette raison qu'il faut changer d'outil, il faut peut-être simplement le remodeler, le repenser. On peut également estimer que le temps législatif est le prix à payer pour correctement débattre et choisir le meilleur compromis dans ce secteur, si sensible.</p>
      <related>
        <a href="https://www.usine-digitale.fr/article/la-medecine-du-futur-devra-se-baser-sur-des-donnees-de-sante-mesurees-dans-la-vie-reelle.N901084"/>
        <a href="https://www.usine-digitale.fr/article/pourquoi-les-gafam-prennent-ils-une-posture-pro-regulation.N886719"/>
      </related>
    </article>
  </body>
</html>