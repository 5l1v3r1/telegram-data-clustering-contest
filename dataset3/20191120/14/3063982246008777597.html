<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <meta property="og:url" content="https://www.golem.de/news/gpu-beschleunigung-nvidia-baut-arm-referenzplattform-1911-145115.html"/>
    <meta property="og:site_name" content="Golem.de"/>
    <meta property="article:published_time" content="2019-11-20T14:08:02+00:00"/>
    <meta property="og:title" content="Nvidia baut ARM-Referenzplattform"/>
    <meta property="og:description" content="Gemeinsam mit Partnern hat Nvidia eine Referenzplattform entworfen, um die eigenen Tesla-V100-Grafikmodule mit ARM-Prozessoren zu kombinieren. Passend dazu gibt es Cuda X als"/>
  </head>
  <body>
    <article>
      <h1>Nvidia baut ARM-Referenzplattform</h1>
      <h2>Gemeinsam mit Partnern hat <a href="https://www.golem.de/specials/nvidia/">Nvidia</a> eine Referenzplattform entworfen, um die eigenen Tesla-V100-Grafikmodule mit <a href="https://www.golem.de/specials/arm/">ARM</a>-Prozessoren zu kombinieren. Passend dazu gibt es Cuda X als Software-Stack und Magnum I/O, um Netzwerk sowie Storage per GPU zu beschleunigen.</h2>
      <address><time datetime="2019-11-20T14:08:02+00:00">20 Nov 2019, 14:08</time> by <a rel="author">Marc Sauter</a></address>
      <p>Nachdem Nvidia vor einigen Wochen mit <a href="https://www.golem.de/news/cuda-x-nvidia-oeffnet-software-stack-fuer-arm-supercomputer-1906-141944.html">Cuda X</a> einen Software-Stack für Tesla-GPUs in ARM-Servern angekündigt hat, erfolgt nun die Veröffentlichung als Preview. Um die Verbreitung voranzutreiben, hat Nvidia eine ARM-Referenzplattform entwickelt. Daran beteiligt waren Partner wie Ampere, Cray, Fujitsu, HPE und Marvell.</p>
      <p>Die Referenzplattform, scherzhaft Ebac (Everything but a CPU) genannt, nutzt acht Tesla V100 als Mezzanine-Module, welche per NV-Link-Chip verbunden sind. Darunter befindet sich - zumindest auf dem von Nvidia verteilten Bild - ein Server mit zwei ThunderX2 von Cavium, einer Marvell-Tochter.</p>
      <p>Passend dazu hat Nvidia mit Magnum I/O eine Software entwickelt, welche per <a href="https://devblogs.nvidia.com/gpudirect-storage/">GPUDirect Storage</a> die CPU umgeht und per PCIe-Switch die Tesla V100 direkt an Speichermedien wie NVMe-SSDs anbindet. Diese Funktion soll jedoch erst im ersten Halbjahr 2020 verfügbar sein.</p>
      <p>Bisher sind ARM-Systeme im Supercomputer-Segment selten, es gibt aber mehrere Anbieter: Ampere hat den Emag alias <a href="https://www.golem.de/news/armv8-prozessor-x-gene-3-kehrt-als-ampere-32-kern-chip-zurueck-1802-132603.html">Ampere A1</a> mit 32 Kernen entwickelt (früher X-Gene), von Cavium/Marvell stammt der <a href="https://www.golem.de/news/arm-cpus-cavium-bringt-thunderx2-und-qualcomm-plant-rueckzug-1805-134279.html">ThunderX2</a> mit 56 Kernen und von Fujitsu der <a href="https://www.golem.de/news/a64fx-fujitsu-erlaeutert-arm-chip-fuer-japans-supercomputer-1808-136146.html">A64FX</a> mit 52 Kernen. Zudem existiert noch der Hi1620 alias Kunpeng 920 von Huawei, wohingegen Qualcomm seine Centriq-CPUs eingestellt hat.</p>
      <p>Microsoft verwendet die <a href="https://www.golem.de/news/prozessor-arm-server-cpus-werden-in-azure-und-supercomputern-verbaut-1911-145055.html">ThunderX2 in Azure-Instanzen</a>, zudem bietet Cray mit dem CS500 mit dem Fujitsu A64FX bestückte Systeme an. Auch die <a href="https://www.top500.org/lists/2019/11/">November-Liste der Top500</a> zeigt, dass die Anzahl der ARM-Supercomputer steigt: Der Astra ist schon älter, der Fugaku-Prototyp mit A64FX hingegen neu. Das System steigt zudem auf dem ersten Platz der Green500 ein, ist also extrem effizient.</p>
    </article>
  </body>
</html>