<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <meta property="og:url" content="https://ko.com.ua/reshenie_nvidia_magnum_io_optimiziruet_rabotu_s_dannymi_v_prilozheniyah_ii_i_hpc_130951"/>
    <meta property="og:site_name" content="Компьютерное Обозрение"/>
    <meta property="article:published_time" content="2019-11-20T16:25:00+00:00"/>
    <meta property="og:title" content="Решение Nvidia Magnum IO оптимизирует работу с данными в приложениях ИИ и HPC"/>
    <meta property="og:description" content="Компания Nvidia представила набор программного обеспечения Magnum IO, позволяющее исследователям в области ИИ и HPC обрабатывать большие объемы данных за считанные минуты вместо нескольких часов."/>
  </head>
  <body>
    <article>
      <h1>Решение Nvidia Magnum IO оптимизирует работу с данными в приложениях ИИ и HPC</h1>
      <address>
        <time datetime="2019-11-20T16:25:00+00:00">20 Nov 2019, 16:25</time>
      </address>
      <figure>
        <img src="https://ko.com.ua/files/u5101/nvidia_magnumIO.png"/>
      </figure>
      <p>Компания Nvidia представила набор программного обеспечения Magnum IO, позволяющее исследователям в области ИИ и HPC обрабатывать большие объемы данных за считанные минуты вместо нескольких часов.</p>
      <p>ПО Magnum IO призвано устранять узкие места при хранении и передаче данных, ускоряя до 20 раз обработку массивов данных в многосерверных мульти-GPU вычислительных узлах и позволяя быстро выполнять финансовый анализ, моделирование климата и другие HPC-задачи.</p>
      <p>Nvidia разработала Magnum IO в сотрудничестве с лидерами индустрии в сегменте передачи и хранения данных, включая DataDirect Networks, Excelero, IBM, Mellanox и WekaIO.</p>
      <p>«В основе всего того, что связано с ИИ, находится обработка больших объемов собранных или смоделированных данных, — говорит Дженсен Хуанг (Jensen Huang), учредитель и генеральный директор NVIDIA. — По мере экспоненциального увеличения объемов и скорости поступления данных их обработка становится одной из самых важных, но и крайне затратных задач для ЦОД.»</p>
      <p>«Для экстремальных вычислений нужны экстремально быстрые интерфейсы. Именно это и обеспечивает ПО Magnum IO, применяя GPU-ускорение, кардинально изменившее вычисления, к передаче и хранению данных. Исследователям больше не придется долго ожидать окончания обработки данных. Теперь они смогут сконцентрироваться на сути своей работы», — добавил Дженсен.</p>
      <p>В основе ПО Magnum IO лежит технология GPUDirect, позволяющая данным обходить CPU и перемещаться по магистралям, созданным графическими процессорами, накопителями и сетевыми устройствами. GPUDirect совместима с широким спектром интерфейсов и API, включая NVIDIA NVLink и NCCL, а также OpenMPI и UCX, и состоит из одно-ранговых (peer-to-peer) и RDMA элементов.</p>
      <p>Новейшим элементом является GPUDirect Storage, позволяющий исследователям в обход CPU получать доступ к хранимым файлам для моделирования, анализа и визуализации.</p>
      <p>ПО NVIDIA Magnum IO уже доступно, за исключением GPUDirect Storage, к которому пока только открыт ранний доступ. Широкая доступность GPUDirect Storage запланирована на первое полугодие 2020 года.</p>
      <p>
        <b>Вы можете подписаться на наш <a href="https://t.me/ko_ua">Telegram-канал</a> для получения наиболее интересной информации</b>
      </p>
      <related>
        <h4>Читайте также</h4>
        <a href="https://ko.com.ua/hpe_predstavila_universalnuyu_kontejnernuyu_platformu_dlya_predpriyatij_130960"/>
        <a href="https://ko.com.ua/v_oblake_microsoft_azure_poyavilsya_novyj_gpu-uskorennyj_superkompyuter_nvidia_130950"/>
        <a href="https://ko.com.ua/predstavlena_referensnaya_platforma_dlya_sozdaniya_gpu-uskorennyh_arm-serverov_130947"/>
        <a href="https://ko.com.ua/kvartalnaya_vyruchka_nvidia_upala_na_5_130897"/>
        <a href="https://ko.com.ua/nvidia_ispravila_ryad_sereznyh_uyazvimostej_v_svoem_po_i_graficheskom_drajvere_130836"/>
      </related>
    </article>
  </body>
</html>