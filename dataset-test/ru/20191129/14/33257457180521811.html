<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <meta property="og:url" content="https://meduza.io/feature/2019/11/29/ty-govorish-nado-li-mne-a-mashina-slyshit-angely-diktatury"/>
    <meta property="og:site_name" content="Meduza"/>
    <meta property="article:published_time" content="2019-11-29T14:42:25+00:00"/>
    <meta property="og:title" content="Познакомьтесь с ученым Дмитрием Каневским. В детстве он потерял слух, а теперь разрабатывает в IBM и Google технологии, помогающие общаться — всем, кому это трудно"/>
    <meta property="og:description" content="В 2019 году корпорация Google показала несколько программ и технологий, которые должны помочь слабослышащим людям. В их создании и улучшении участвовал Дмитрий Каневский — эмигрировавший из СССР ученый, лишившийся слуха в раннем детстве. На мероприятии AI in Action, организованном Google в Цюрихе, Каневский рассказал о своих разработках и дал короткое интервью «Медузе» — с их же помощью."/>
  </head>
  <body>
    <article>
      <h1>Познакомьтесь с ученым Дмитрием Каневским. В детстве он потерял слух, а теперь разрабатывает в IBM и Google технологии, помогающие общаться — всем, кому это трудно</h1>
      <address><time datetime="2019-11-29T14:42:25+00:00">29 Nov 2019, 14:42</time> by <a rel="author">Meduza</a></address>
      <p>В 2019 году корпорация Google показала несколько программ и технологий, которые должны помочь слабослышащим людям. В их создании и улучшении участвовал Дмитрий Каневский — эмигрировавший из СССР ученый, лишившийся слуха в раннем детстве. На мероприятии AI in Action, организованном Google в Цюрихе, Каневский рассказал о своих разработках и дал короткое интервью «Медузе» — с их же помощью.</p>
      <hr/>
      <p>В руках Дмитрия Каневского — два телефона. Они помогают ему разговаривать с людьми — даже несмотря на то, что он сам ничего не слышит.</p>
      <p>На одном телефоне Каневский читает автоматическую расшифровку речи своих собеседников. На втором — уже собеседники Каневского могут читать расшифровку того, что он говорит: у исследователя — сильный славянский акцент, к тому же некоторые гласные звуки он произносит громче и выше, чем другие — так что его бывает непросто понять.</p>
      <p>Чтобы это сработало, на каждом телефоне установлена своя программа. На первом — Live Transcribe. Это бесплатное приложение под Android, которое Google выпустила в феврале 2019 года. Оно отправляет аудио с микрофона телефона на серверы компании, где происходит распознавание речи — и через пару секунд на экране телефона появляется текстовая расшифровка.</p>
      <figure>
        <iframe src="https://www.youtube.com/embed/OAdegPmkK-o" width="640" height="360" data-service="Youtube" scrolling="no"/>
        <figcaption>Презентация проекта Euphonia<cite>Google</cite></figcaption>
      </figure>
      <p>Live Transcribe хорошо расшифровывает разговор обычного человека, поскольку нейросеть в ее основе обучалась на «типичной» речи. Но когда приложение слышит человека с особенностями речи или с сильным акцентом, количество ошибок резко возрастает. Тут-то и помогает приложение Euphonia, установленное на втором телефоне Каневского (его Google <a href="https://www.wired.com/story/google-live-transcribe-sound-amplifier-for-android/#">представил</a> в мае 2019 года).</p>
      <p>Euphonia ученый обучал сам, поэтому оно намного лучше понимает его речь. Каневский начал с небольшого количества аудиоданных — порядка ста фраз, которые позволили «умной» колонке Google Home понимать его команды. Затем он стал записывать свои лекции и добавлять к ним точные текстовые расшифровки. В итоге Каневский записал для Euphonia 25 часов аудио, и теперь программа понимает уже почти все, что он говорит. В том числе те слова или фразы, которые непросто понять нетренированному человеческому уху.</p>
      <p>В <a href="https://ai.googleblog.com/2019/08/project-euphonias-personalized-speech.html">блоге</a> Google работу Euphonia сравнивают со стандартной моделью распознавания речи. Там, где Каневский говорил «Come right back please» («Вернись, пожалуйста»), стандартная модель слышала: «Cameras object» («Камеры, объект»). А когда он спрашивал: «Did I have anything to say about it?» («Надо ли мне было что-то сказать об этом?»), получалось «Dictatorship angels to think about it» («Ангелы диктатуры подумают об этом»).</p>
      <p>По словам ученого, Live Transcribe и Euphonia существенно изменили его жизнь, причем каждое приложение справляется со своей задачей. Так, Live Transcribe позволило ему общаться с внучками — раньше приходилось привлекать сына или жену в качестве посредников. «Они могут попросить меня сыграть в прятки или рассказать историю, — говорит Каневский. — Еще они любят смотреть, как приложение расшифровывает их слова, для них это становится формой игры».</p>
      <p>Euphonia помогает Каневскому выступать (в этом случае изображение с экрана телефона выводится на слайд). Каневский — математик, и в ближайшее время он планирует выступить с лекцией перед друзьями-математиками. Для этого ему пришлось обучить систему специфичным терминам; так что теперь он может сказать «алгебраическая геометрия» и «коммутативные лупы Муфанг» — и аудитория его поймет.</p>
      <p>Euphonia — исследовательский проект, который пока доступен только сотрудникам компании. Но Каневский надеется, что в будущем технологию смогут использовать и другие — в частности, люди с боковым амиотрофическим склерозом (БАС), испытывающие трудности в речи. По словам ученого, для тренировки акустической модели каждому человеку необязательно будет записывать 25 часов аудио — из-за схожих паттернов в речи можно совмещать записи многих голосов. «Мы надеемся, что если много людей запишут свои голоса, мы начнем их кластеризировать, — объясняет Каневский. — И когда придет новый человек, мы просто найдем подходящий кластер. Если ему и придется тренировать модель под себя, то совсем чуть-чуть».</p>
      <p>Конечно, нейросети, распознающие речь, были с Каневским не всегда. В интервью CNET Каневский <a href="https://www.cnet.com/news/deaf-ibm-researcher-scoffs-at-not-talking-on-the-phone/">рассказывал</a>, что в детском саду и в школе он занимался с детьми без нарушения слуха и научился хорошо читать по губам. Во время обучения в аспирантуре в МГУ в конце 1970-х он задумался об эмиграции в Израиль. За девять месяцев, которые он ждал разрешения на выезд, ученый придумал и собрал устройство, которое упрощало ему чтение по губам речи иностранцев. «Например, в иврите много шипящих звуков — „шаббат“, „шалом“, — объяснял он CNET. — Поэтому я разработал устройство, преобразующее высокие частоты в низкие, и в Израиле оно помогало мне общаться. Благодаря ему я начал понимать других людей и говорить на иврите и по-английски».</p>
      <p>В 1980-х Каневский переехал в США и начал работать в IBM над различными технологиями, помогающими глухим людям (у ученого больше 200 патентов). Так, в 1990-х он придумал подключать стенографистов по интернету: те слушали по телефону, что говорит Каневский и его собеседники, и тут же выводили на специальную веб-страницу расшифровку их фраз. Похожую систему Каневский <a href="https://www.cnet.com/news/deaf-ibm-researcher-scoffs-at-not-talking-on-the-phone/">применял</a>, когда давал телефонное интервью CNET в 2012 году — оно было приурочено к его приглашению на торжественную церемонию в Белом доме.</p>
      <p>С помощью стенографистов, подключенных по скайпу, ученый даже <a href="https://www.youtube.com/watch?v=R7VaGZU9Xx8">читал лекции</a>: студентам, которые хотели задать вопрос, нужно было говорить в планшет в руках Каневского — через несколько секунд он получал текстовую расшифровку. Но у этой системы есть серьезный изъян: услуги стенографистов стоят дорого. Из-за этого выбор мест работы Каневского был ограничен большими компаниями, вроде IBM и Google. «Если бы мы встретились больше года назад, наш разговор стоил бы Google несколько тысяч долларов, — рассказывает он „Медузе“. — Я бы нанял стенографиста и неделю практиковался с ним, чтобы он знал, о чем будет мое выступление. На это бы ушло много [оплачиваемых] часов».</p>
      <p>По словам ученого, когда он начал работать в сфере речевых технологий, то думал, что для исполнения его мечты — полноценной системы распознавания речи, которая поможет глухим людям общаться — потребуется примерно пять лет. На деле этот путь занял 25 лет. Расцвету технологий распознавания речи в последние годы способствовали два условия: компьютеры наконец стали достаточно мощными, чтобы на них могли эффективно работать нейросети; а в интернете появился сайт с сотнями тысяч видео, к которым люди загружали текстовые расшифровки, — ютьюб.</p>
      <p>Live Transcribe уже достаточно качественно распознает речь и даже указывает на посторонние звуки — например, лай собаки или аплодисменты; хотя с некоторыми обстоятельствами справляется с трудом — когда вокруг шумно, говорящий сидит далеко от микрофона или если одновременно говорят несколько человек.</p>
      <p>Euphonia же, по мнению ученого, должна развиться до системы, которая будет понимать всех людей с нестандартной речью. Он представляет себе это так: человек заходит на сайт, загружает туда образец своего голоса или просто находит подходящий под свой случай вариант, скачивает его к себе на телефон и начинает общаться с людьми и голосовыми помощниками.</p>
      <p>Работа Каневского и его коллег не ограничивается преобразованием речи в текст. В 2018 году они <a href="https://www.youtube.com/watch?v=PJULgyxA9wA">демонстрировали</a> прототип мини-проектора, который прикреплялся к груди ученого: таким образом Каневский мог увидеть расшифровку слов, которые произносил его собеседник, прямо у него на груди. Очки дополненной реальности, позволяющие выводить текст прямо перед глазами человека, позволят сделать общение с глухими людьми еще более натуральным: «Сейчас некоторые люди жалуются, что во время разговора я перестаю смотреть на них и смотрю на экран телефона».</p>
      <p>У Google также есть исследовательский проект <a href="https://ai.googleblog.com/2019/07/parrotron-new-research-into-improving.html">Parrotron</a>, который вообще не пытается «понять», что же сказал человек с нестандартной речью — нейросеть сразу «проговаривает» ту же фразу «стандартным» голосом.</p>
      <p>В ролике, демонстрирующем разработку, Каневский пытается задать вопрос голосовому ассистенту, но тот понимает его неправильно. Затем он говорит ту же команду в Parrotron, установленный на телефоне, и уже приложение повторяет ее «стандартным» голосом для «умной» колонки.</p>
      <figure>
        <iframe src="https://www.youtube.com/embed/KtKGWSpppz4" width="640" height="360" data-service="Youtube" scrolling="no"/>
        <figcaption>Демонстрация работы Parrotron<cite>Fadi Biadsy</cite></figcaption>
      </figure>
      <p>Каневский подчеркивает, что задача его команды не в том, чтобы слабослышащие люди полностью перешли на системы преобразования аудио в текст — они также работают и над автоматическим распознаванием жестового языка. Для слабовидящих и слепых людей Google выпустил приложение <a href="https://www.theverge.com/2019/3/13/18263426/google-lookout-ai-visually-impaired-blind-app-assistance">Lookout</a>: наводишь камеру на объект — и получаешь устное объяснение, что это такое. А для помощи слепоглухим людям в компании работают над преобразованием текста из Live Transcribe в шрифт Брайля.</p>
      <p>По словам Каневского, другим компаниям, желающим помочь людям с особенными потребностями, нужно помнить, что главный вызов, который стоит перед ними — не технологический. «Я думаю, главный вызов сейчас — это эмпатия. Мы недооцениваем, насколько это важно, — говорит ученый „Медузе“. — Вы не можете просто нанять разработчика и сказать: сейчас мы сделаем вот такое вот приложение. Важнейший вызов — пробуждать в людях эмпатию».</p>
      <blockquote>Хотите поддержать <a href="https://so-edinenie.org/">фонд «Со-единение»</a>, помогающий людям с одновременным нарушением слуха и зрения? Вы можете сделать это <a href="https://so-edinenie.org/blagotvoritelyam">здесь</a></blockquote>
      <related>
        <h4>другие материалы meduzacare</h4>
        <a href="https://meduza.io/cards/kak-nanyat-na-rabotu-cheloveka-s-invalidnostyu-eto-ochen-slozhno"/>
        <a href="https://meduza.io/feature/2019/11/20/v-rossii-zhivet-pochti-12-millionov-lyudey-s-invalidnostyu-chechnya-na-pervom-meste-po-chislu-novyh-invalidnostey"/>
        <a href="https://meduza.io/feature/2019/11/28/nas-uchat-terpet-byt-molchalivymi-ustupchivymi-i-pokladistymi"/>
      </related>
      <footer>
        <b>Султан Сулейманов</b>
      </footer>
    </article>
  </body>
</html>