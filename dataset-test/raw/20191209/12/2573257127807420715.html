<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <meta property="og:url" content="https://www.tecnoandroid.it/2019/12/09/intelligenza-artificiale-distruggera-umanita-come-terminator-637568"/>
    <meta property="og:site_name" content="tecnoandroid"/>
    <meta property="article:published_time" content="2019-12-09T12:30:11+00:00"/>
    <meta property="og:title" content="L’intelligenza artificiale un giorno distruggerà l’uomo come Terminator?"/>
    <meta property="og:description" content="Se vogliamo sopravvivere dobbiamo controllare l'evoluzione dell'intelligenza artificiale o, almeno, cercare di non lasciarcela sfuggire di mano."/>
  </head>
  <body>
    <article>
      <h1>L’intelligenza artificiale un giorno distruggerà l’uomo come Terminator?</h1>
      <h2>Se vogliamo sopravvivere dobbiamo controllare l'evoluzione dell'intelligenza artificiale o, almeno, cercare di non lasciarcela sfuggire di mano.</h2>
      <address><time datetime="2019-12-09T12:30:11+00:00">09 Dec 2019, 12:30</time> by <a rel="author">Flavio Mezzanotte</a></address>
      <figure>
        <img src="https://t4m7p5j6.stackpathcdn.com/wp-content/uploads/2019/12/intelligenza-artificiale-killer-terminator-700x400.jpg"/>
      </figure>
      <p><b>L’intelligenza artificiale</b> è in grado di apprendere e modificare i suoi comportamenti prendendo a modello anche dei cattivi esempi da noi trasmessi. E se una macchina può imparare nel modo sbagliato, allora può capitare che <b>diventi per noi un pericolo.</b></p>
      <p>Sull’argomento, i ricercatori <i>Laurent Orseau e Stuart Armstrong </i>hanno ideato un metodo per intervenire e <b>modificare le modalità di apprendimento dell’AI in modo che non impari cose sbagliate</b> (a livello etico).</p>
      <p>Gli schemi comportamentali sono afferenti al cosiddetto “<i>reinforcement learning</i>“: quando la AI impara correttamente le viene data una ricompensa, valutando autonomamente ogni sua possibile azione in tale relazione. Ma<b> l’intelligenza artificiale è anche in grado di apprendere in modo imprevedibile</b> come un cervello umano, e potrebbe scoprire delle scorciatoie per massimizzare le ricompense <b>deviando dal corretto modo di comportarsi. </b></p>
      <h3>L’intelligenza artificiale distruggerà l’uomo come Terminator?</h3>
      <p>È plausibile che <b>tra qualche decennio <a href="https://www.tecnoandroid.it/2019/12/01/alexa-lassistente-vocale-da-ora-in-poi-potra-esprimere-gioia-o-delusione-633186">le macchine riusciranno a surclassare la razza umana, </a></b>in un futuro dove uomini, robot e cyborg (esseri ibridi) convivranno con le relative tensioni sociali che ne seguono. L’uso di parti artificiali nel corpo umano è ormai di prassi comune, e <b>forse saremo noi un giorno a voler assomigliare un po’ di più a quelle macchine</b> che presto acquisiranno un’autocoscienza.<br/><b>Se vogliamo sopravvivere dobbiamo controllare questa evoluzione</b> o, almeno, cercare di non lasciarcela sfuggire di mano. Piuttosto dobbiamo cogliere l’opportunità di creare una nuova razza di essere senzienti che possa migliorare la nostra società, altrimenti un giorno <b>i robot potranno persino vedere gli umani come fastidiose scimmie involute</b>.<br/><b>Il problema è come interrompere il funzionamento di queste macchine</b> pensanti un giorno che ne avremo paura. Un’intelligenza artificiale che sia bloccabile in tutta sicurezza è qualcosa che è ancora sotto il nostro controllo (giochiamo a fare Dio da sempre d’altronde). M<b>a se un robot può essere progettato con un pulsante per interromperlo</b>, il rischio è che l’intelligenza artificiale possa resistere ai tentativi di spegnimento umani.</p>
    </article>
  </body>
</html>