<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <meta property="og:url" content="https://www.nextinpact.com/brief/mozilla-deepspeech-0-6---de-vastes-gains-de-performances-10594.htm"/>
    <meta property="og:site_name" content="Next INpact"/>
    <meta property="article:published_time" content="2019-12-09T10:05:08+00:00"/>
    <meta property="og:title" content="Mozilla DeepSpeech 0.6 : de vastes gains de performances"/>
    <meta property="og:description" content="DeepSpeech est un ensemble de moteurs de type speech-to-text et text-to-speech, permettant donc la reconnaissance ou la synthèse vocale. La nouvelle mouture, sortie en fin de semaine dernière, apporte des gains très significatifs de performances."/>
  </head>
  <body>
    <article>
      <h1>
        <a href="https://www.nextinpact.com/brief/mozilla-deepspeech-0-6---de-vastes-gains-de-performances-10594.htm">Mozilla DeepSpeech 0.6 : de vastes gains de performances</a>
      </h1>
      <address>
        <time datetime="2019-12-09T10:05:08+00:00">09 Dec 2019, 10:05</time>
      </address>
      <p>DeepSpeech est un ensemble de moteurs de type speech-to-text et text-to-speech, permettant donc la reconnaissance ou la synthèse vocale. <a href="https://hacks.mozilla.org/2019/12/deepspeech-0-6-mozillas-speech-to-text-engine/">La nouvelle mouture</a>, sortie en fin de semaine dernière, apporte des gains très significatifs de performances.</p>
      <p>L’un des plus gros changements est le passage à TensorFlow Lite, pour rappel une version réduite de TensorFlow dédiée aux appareils embarqués et mobiles. Cette transition et les optimisations apportées offrent des gains majeurs :</p>
      <ul>
        <li>Le paquet DeepSpeech est passe de 98 à 3,7 Mo</li>
        <li>Le modèle de traitement de l’anglais passe de 188 à 47 Mo</li>
        <li>La consommation mémoire est divisée par 22</li>
        <li>Le temps de démarrage est divisé par 500</li>
      </ul>
      <p>Les performances du modèle sont telles que Mozilla n’hésite plus à dire qu’il fonctionne « <i>plus vite qu’en temps réel</i> », en ne se servant que d’un seul cœur sur un Raspberry Pi 4. Le taux d’erreur en reconnaissance vocale est actuellement de 7,5 %.</p>
      <p>Les deux principaux sous-systèmes sont maintenant capables de streaming, annulant le besoin d’introduire des algorithmes de détection des silences.  Les transcriptions sont fournies en moyenne 260 ms après la fin de l’audio, 73 % plus rapidement qu’avant l’introduction du streaming.</p>
      <p>Le passage à TensorFlow 1.14 fournit également son lot d’améliorations, par exemple une division par 2 (au maximum) du temps d’entrainement des modèles. Ces derniers peuvent être pleinement entrainés et déployés à des taux d’échantillonnage différents (8 kHz pour les données téléphoniques par exemple), le décodeur exposant des métadonnées pour chaque caractère dans la transcription.</p>
      <p>DeepSpeech possède en outre ses propres paquets pour Windows, via .NET, Python, JavaScript ou C. Pour le premier, le paquet est disponible depuis la galerie NuGet, directement depuis Visual Studio. DeepSpeech reste compatible avec les plateformes précédentes, Android, Linux et macOS.</p>
      <ul>
        <li><a href="https://github.com/mozilla/DeepSpeech/releases/v0.6.0">Télécharger DeepSpeech 0.6</a> (GitHub)</li>
      </ul>
    </article>
  </body>
</html>