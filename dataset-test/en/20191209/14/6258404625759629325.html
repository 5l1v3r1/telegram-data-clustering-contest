<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <meta property="og:url" content="https://hothardware.com/news/nvidia-machine-learning-transform-2d-images-3d-models"/>
    <meta property="og:site_name" content="HotHardware"/>
    <meta property="article:published_time" content="2019-12-09T14:15:00+00:00"/>
    <meta property="og:title" content="NVIDIA Is Using Machine Learning To Transform 2D Images Into 3D Models"/>
    <meta property="og:description" content="Researchers at NVIDIA have come up with a clever machine learning technique for taking 2D images and fleshing them out into 3D models."/>
  </head>
  <body>
    <article>
      <h1>NVIDIA Is Using Machine Learning To Transform 2D Images Into 3D Models</h1>
      <address><time datetime="2019-12-09T14:15:00+00:00">09 Dec 2019, 14:15</time> by <a rel="author" href="https://hothardware.com/author/Paul-Lilly" target="_blank">Paul Lilly</a></address>
      <figure>
        <img src="https://images.hothardware.com/contentimages/newsitem/50105/content/small_nvidia_3d_modeling.jpg"/>
      </figure>
      <p>Researchers at NVIDIA have come up with a clever <a href="https://hothardware.com/news/nvidia-gaugan-machine-learning-drawings-photorealistic-landscapes">machine learning</a> technique for taking 2D images and fleshing them out into 3D models. Normally this happens in reverse—these days, it's not all that difficult to take a 3D model and flatten it into a 2D image. But to create a 3D model without feeding a system 3D data is far more challenging.<br/><br/>"In traditional computer graphics, a pipeline renders a 3D model to a 2D screen. But there’s information to be gained from doing the opposite—a model that could infer a 3D object from a 2D image would be able to perform better object tracking, for example.," NVIDIA explains.<br/><br/>What the researchers came up with is a rendering framework called DIB-R, which stands for differentiable interpolation-based renderer. The goal was to design a framework that could accomplish this task while integrating seamlessly with machine learning techniques.<br/><br/>"The result, DIB-R, produces high-fidelity rendering by using an encoder-decoder architecture, a type of neural network that transforms input into a feature map or vector that is used to predict specific information such as shape, color, texture and lighting of an image," NVIDIA says.<br/><br/>According to <a href="https://hothardware.com/tags/nvidia">NVIDIA</a>, this type of thing could be especially helpful in <a href="https://hothardware.com/news/nvidia-opens-ai-robotics-research-lab-seattle-human-robot-interactions">robotics</a>. By processing 2D images into 3D models, an autonomous robot would be in a better position to interact with its environment more safely and efficiently, as it could "sense and understand it surroundings" using this technology.<br/><br/>NVIDIA says it takes two days to train this kind of model on a single <a href="https://hothardware.com/news/nvidia-debuts-tesla-v100-volta-gpu-dgx-1-at-gdc-2017">Tesla V100 Tensor Core GPU</a>, versus several weeks to train the same kind of thing without its GPUs. What that ultimately translates to is being able to produce a 3D object from a 2D image in less than 100 milliseconds.<br/><br/>Researchers at NVIDIA trained their model on a bunch of datasets, including a set collection of bird images. Once trained, a system could look at a 2D image of a bird and a produce a 3D model with the right shape and texture.<br/><br/>"This is essentially the first time ever that you can take just about any 2D image and predict relevant 3D properties," says Jun Gao, one of a team of researchers who collaborated on DIB-R.<br/><br/>Beyond robotics, NVIDIA also sees this as being handy in transforming 2D images of dinosaurs and other extinct animals, into lifelike 3D images in quick fashion (under a second).</p>
    </article>
  </body>
</html>