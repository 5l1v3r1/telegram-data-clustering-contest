<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <meta property="og:url" content="https://www.ksta.de/ratgeber/verbraucher/viele-vorteile-und-doch-grosse-probleme-kann-ki-in-zukunft-den-richter-ersetzen--33506410"/>
    <meta property="og:site_name" content="Kölner Stadt-Anzeiger"/>
    <meta property="article:published_time" content="2019-11-22T17:00:05+00:00"/>
    <meta property="og:title" content="Kann KI in Zukunft den Richter ersetzen?"/>
    <meta property="og:description" content="Künstliche Intelligenz könnte helfen, doch es ist Vorsicht geboten."/>
  </head>
  <body>
    <article>
      <h6 class="kicker">Viele Vorteile und doch große Probleme</h6>
      <h1>Kann KI in Zukunft den Richter ersetzen?</h1>
      <address><time datetime="2019-11-22T17:00:05+00:00">22 Nov 2019, 17:00</time> by <a rel="author">Frauke Rostalski</a></address>
      <ul>
        <li>In unserer neuen Serie „Recht und Ordnung“ wollen wir uns mit juristischen Themen aller Art befassen – und vor allem Ihnen mehr Durchblick im Paragrafen-Dschungel verschaffen.</li>
        <li>Heute befasst sich die Kölner Strafrechts-Professorin Frauke Rostalski mit der Frage, ob Künstliche Intelligenz in Zukunft Menschen vor Gericht ersetzen kann.</li>
        <li>Obwohl eine Maschine nie müde wird und auch Kosten gespart werden könnten – einen entscheidenden Nachteil gibt es bei KI.</li>
      </ul>
      <p>Die Digitalisierung durchdringt inzwischen nahezu sämtliche Lebensbereiche und macht auch vor dem Recht nicht halt. In den USA etwa werden algorithmenbasierte Systeme schon seit Längerem sowohl in der Polizeiarbeit als auch bei der Rechtsanwendung eingesetzt.</p>
      <p>Traurige Berühmtheit erlangte die Software „Compas“ (Correctional Offender Management Profiling for Alternative Sanctions), die das Rückfallrisiko verurteilter Straftäter berechnen sollte. Konkret sah das Programm vor, dem Richter bei der Beurteilung der Frage zu helfen, ob ein Häftling eine günstige Bewährungsentscheidung erhalten sollte. Erst nach Jahren fiel auf, dass die Software Afroamerikaner systematisch benachteiligte, ihnen nämlich fälschlicherweise beinahe doppelt so häufig eine die Bewährung ausschließende Rückfallgefahr bescheinigte als anderen.</p>
      <hr/>
      <h4>Zur Person</h4>
      <figure>
        <img src="https://www.ksta.de/image/33461236/3x4/300/400/f3b6cc81f4b73469bb25e0dac00aa036/wY/plus-foto-rostaksli.jpg"/>
      </figure>
      <p>Frauke Rostalski, geboren 1985, ist geschäftsführende Direktorin des Instituts für Strafrecht und Strafprozessrecht der Universität zu Köln. Im Januar 2018 wurde sie dort auf den Lehrstuhl für Strafrecht, Strafprozessrecht, Rechtsphilosophie und Rechtsvergleichung berufen. Rostalski studierte Rechtswissenschaften an der Philipps-Universität Marburg und promovierte dort von 2009 bis 2011. Im Anschluss an ihre zweite juristische Staatsprüfung 2013 verbrachte sie Forschungsaufenthalte an der Nanjing Universität (China) und der Seoul Universität (Korea). 2017 promovierte sie auch im Fach Philosophie an der Friedrich-Schiller-Universität Jena. (jf)</p>
      <hr/>
      <p>Compas ist ein Beispiel dafür, dass die Arbeit von Rechtsanwendern durch algorithmenbasierte Systeme nicht zwingend verbessert wird. Im Gegenteil: Die Software zeigt, welche Gefahren in der zu unkritischen Einbeziehung solcher Programme in die Arbeit von Juristen schlummern können. So werden in der Software angelegte Fehler unter Umständen erst viel zu spät entdeckt – mit bereits schwerwiegenden Folgen für eine Vielzahl von Menschen.</p>
      <p>Aber sollten wir Algorithmen aus diesem Grund in Gänze und für immer von der Richterbank verdrängen? Was wäre, wenn es künftig Softwareprogramme gäbe, die sicher fehlerfrei sind und die Arbeit des Juristen ebenso gut erledigen könnten wie der Mensch? Für den Einsatz von Algorithmen in der Rechtsanwendung spricht zumindest der hohe Effizienzgewinn, der hiermit einherginge: Anders als der Mensch wird die Maschine nicht müde, sie braucht keinen Urlaub und keine Mittagspausen.</p>
      <p>Ließen sich auf diese Weise menschliche Ressourcen einsparen, könnten auch Gerichtskosten reduziert werden. In der Folge hätten deutlich mehr Menschen Zugang zum Recht als bislang. Und: Anders als der Mensch, lässt sich eine Software weder durch einen subjektiv guten oder schlechten Eindruck vom Angeklagten in Strafsachen oder von den Parteien im Zivilverfahren beeinflussen. Das hierin liegende, hohe Maß an Objektivität, verspricht für sich genommen einen Zugewinn an Gerechtigkeit.</p>
      <hr/>
      <h4>Vortrag</h4>
      <p>Zum Thema Künstliche Intelligenz in der Arbeitswelt und im Arbeitsrecht diskutiert unsere Kolumnistin mit weiteren Experten in der Reihe „Recht in Köln“. „Wenn der Kollege Computer mitreden will“. Dienstag, 26. November, 17 Uhr, Landesarbeitsgericht, Blumenthalstraße 33, 50670 Köln. Der Eintritt ist frei (jf) Anmeldung unter Telefon 0221/7740-347 oder per E-Mail: rechtinkoeln@lag-koeln.nrw.de (jf)</p>
      <hr/>
      <p>Dennoch sollten wir vorsichtig sein mit einer Delegation wichtiger menschlicher Kompetenzen an technische Assistenten. Das Recht hat eine bedeutsame Funktion für die Gemeinschaft.</p>
      <p>Nur wenn der Einzelne versteht, warum ein ihn betreffendes Urteil so oder anders ausgefallen ist, kann damit gerechnet werden, dass Rechtsfrieden einkehrt. Ich habe zumindest starke Zweifel, dass eine solche Vermittlung durch eine Computersoftware gelingen kann. Und zuletzt: Urteile können auch falsch sein – etwa weil uns Erkenntnisse fehlen, die wir benötigt hätten, um den Sachverhalt zutreffend zu bewerten.</p>
      <hr/>
      <h4>Zu unserer Serie</h4>
      <p>
        <b>Haben auch Sie eine Frage an unsere Experten? Schreiben Sie per Mail an:</b>
      </p>
      <p>recht-und-ordnung@dumont.de<br/>oder per Post an:<br/>„Kölner Stadt-Anzeiger“<br/>z.Hd. Joachim Frank<br/>Stichwort „Recht und Ordnung“<br/>Neven DuMont Haus, 50590 Köln.</p>
      <hr/>
      <p>In jeder rechtlichen Entscheidung steckt also zugleich das Risiko des Fehlers. Dieses Risiko kann aber nur ein Mensch tragen – keine Maschine, die für ihre technisch produzierten Ergebnisse keine Verantwortung trägt. Es spricht also einiges dafür, die Rechtsanwendung auch künftig nicht mit Kaffee kochen zu verwechseln. Selbst wenn wir Urteile per Knopfdruck herbeiführen könnten, sollten wir uns sehr gut überlegen, ob wir das wirklich wollen.</p>
      <related>
        <h4>Das könnte Sie auch interessieren</h4>
        <a href="https://www.ksta.de/ratgeber/verbraucher/plaedoyer-fuer-ein-liberales-strafrechtsverstaendnis--taten-oder-taeter-bestrafen--33461030"/>
        <a href="https://www.ksta.de/ratgeber/verbraucher/paragraph-219a-warum-ist-werbung-fuer-abtreibungen-strafbar--33227062"/>
        <a href="https://www.ksta.de/ratgeber/verbraucher/aussage-gegen-aussage-zaehlt-die-aussage-eines-polizisten-vor-gericht-mehr---33355228"/>
      </related>
    </article>
  </body>
</html>