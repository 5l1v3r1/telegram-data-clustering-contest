<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <meta property="og:url" content="https://www.heise.de/newsticker/meldung/Initiative-D21-Tauziehen-um-gesetzliche-Vorschriften-fuer-Kuenstliche-Intelligenz-4593264.html"/>
    <meta property="og:site_name" content="heise online"/>
    <meta property="article:published_time" content="2019-11-21T07:36:00+00:00"/>
    <meta property="og:title" content="Initiative D21: Tauziehen um gesetzliche Vorschriften für Künstliche Intelligenz"/>
    <meta property="og:description" content="Die Initiative D21 hält in ihren ethischen Leitlinien für algorithmische Systeme nichts von neuen gesetzlichen Regeln für die Technik."/>
  </head>
  <body>
    <article>
      <h1>Initiative D21: Tauziehen um gesetzliche Vorschriften für Künstliche Intelligenz</h1>
      <h2>Die Initiative D21 hält in ihren ethischen Leitlinien für algorithmische Systeme nichts von neuen gesetzlichen Regeln für die Technik.</h2>
      <address><time datetime="2019-11-21T07:36:00+00:00">21 Nov 2019, 07:36</time> by <a rel="author">Stefan Krempl</a></address>
      <p>"Neue gesetzliche Regelungen für algorithmische Systeme sind nicht zwingend erforderlich", schreibt die Initiative D21 in neun Leitlinien zum ethischen Umgang mit der für Künstliche Intelligenz (KI) grundlegenden Technik. Es sei bereits unzulässig, Menschen etwa aufgrund der ethnischen Herkunft, des Geschlechts, der Religion oder Weltanschauung, einer Behinderung, des Alters oder der sexuellen Identität zu benachteiligen, heißt es in dem am Mittwoch veröffentlichten Papier. Daher reiche es, das bestehende Recht anzuwenden.</p>
      <p>Die Arbeitsgruppe "Algorithmen-Monitoring" der öffentlich-privaten Digitalisierungspartnerschaft kommt damit zu einem anderen Ergebnis als etwa die Datenethik-Kommission (DEK) der Bundesregierung. Letztere rät dazu, <a href="https://www.heise.de/meldung/Datenethik-Kommission-Verbot-von-De-Anonymisierung-und-Profilbildung-4566788.html">Algorithmen in fünf Risikostufen einzuteilen</a> und rundherum eine europäische Verordnung zu verabschieden.</p>
      <h3>Überregulierung vermeiden</h3>
      <p>"Wir wollen keine Überregulierung, keine Innovation hemmen", erläuterte die Wiener Zivilrechtlerin Christiane Wendehorst, Co-Vorsitzende der DEK am Mittwoch <a href="https://initiatived21.de/publikationen/denkimpulse-zur-digitalen-ethik">bei der Präsentation des D21-Selbstregulierungsrahmens in Berlin</a>. Es sei aber Konsens in dem Gremium gewesen, "dass Ethik auch Verbindlichkeit bedeutet". Man könne den Bürgern nur die Garantie geben, dass die allerorten aus dem Boden schießenden Leitlinien für den Einsatz von Programmroutinen auch eingehalten werden, "wenn man sie rechtlich absichert".</p>
      <p>Bei der umrissenen Gesetzgebung liege jetzt aber "der Teufel im Detail", räumte Wendehorst ein. Ihr jucke es hin und wieder in den Fingern, im eigenen Stübchen eine einschlägige Initiative auszuformulieren. Dabei habe sie gemerkt, "wie schwierig das ist", ließ Wendehorst durchblicken. Es handle sich aber nicht um eine unlösbare Aufgabe. Dass verschiedene Organisationen mit Richtschnüren die Debatte belebten, schade nicht. Meist bewegten sich diese aber "auf oberster Abstraktionsebene", auf der alle recht einfach einen Konsens finden könnten. Nun gehe es darum, mit handhabbaren Vorschriften konkreter zu werden.</p>
      <h3>Handlungsempfehlungen</h3>
      <figure>
        <img src="https://www.heise.de/imgs/18/2/7/9/3/0/8/1/Leitlinien-1c1ace57e7db2537.jpeg"/>
        <figcaption>Die Leitlinien der UAG Algorithmen-Monitoring.<cite>(Bild: Stefan Krempl)</cite></figcaption>
      </figure>
      <p>Von den Mühen der Ebenen berichtete Anke Domscheit-Berg, Mitglied der Enquete-Kommission des Bundestags für KI. "Wir haben auch über Risikoklassen geredet", die Mehrheit habe sich hier aber nicht auf ein Modell festlegen wollen, erklärte die Linke. Ihrer Ansicht nach müssten etwa Killer-Roboter umgehend geächtet werden. Die große Koalition wolle hier jedoch darauf warten, was die laufenden Gespräche in Genf über ein einschlägiges Protokoll ergäben. Die Linksfraktion werde daher vermutlich ein Sondervotum zum Einsatz von KI in den Bereichen Inneres und Verteidigung abgeben, wenn der Abschlussbericht des Gremiums in etwa einem Jahr veröffentlicht werde.</p>
      <p>Prinzipiell plädiert auch die Abgeordnete dafür, von den "Meta-Handlungsempfehlungen" und Sektorenanweisungen für algorithmische Systeme "zu einer verbindlichen Umsetzung" zu kommen. Sie begrüßte daher die <a href="https://www.heise.de/meldung/Datenstrategie-Regierung-sucht-sichere-Methoden-zum-Teilen-und-Anonymisieren-4589710.html">in den Eckpunkten für eine Datenstrategie der Bundesregierung erkennbare Absicht</a>, Gesetze in diesem Bereich auszuarbeiten. Es müsse etwa klar sein, dass eine für die Resozialisierung von Gefangenen entwickelte KI nicht einfach Richtern in die Hand gedrückt werden dürfe, damit diese damit Verdächtige beurteilten. Risikoklassen dürften nicht einfach gewechselt werden.</p>
      <h3>Regulierung auf EU-Ebene</h3>
      <p>Sie habe "lieber eine Regulierung, als wenn ich im rechtsfreien Raum bin", zeigte sich auch Iris Plöger aus der Hauptgeschäftsführung des Bundesverbands der deutschen Industrie (BDI) nicht ganz abgeneigt gegenüber gesetzgeberischen Schritten. Diese müssten aber auf europäischer Ebene im Sinne des digitalen Binnenmarkts erfolgen, sprach sich das Mitglied der <a href="https://www.heise.de/meldung/EU-Experten-KI-nicht-fuer-Ueberwachung-und-Scoring-von-Massen-einsetzen-4456008.html">hochrangigen Expertengruppe der EU-Kommission für KI</a> gegen nationale Alleingänge aus.</p>
      <p>"Zum Schrecken aller" habe die gewählte Präsidentin der Brüsseler Regierungsinstanz, Ursula von der Leyen (CDU), aber angekündigt, <a href="https://www.heise.de/meldung/Klima-und-KI-Gesetz-bis-Herbst-von-der-Leyen-sieht-grosse-Aufgaben-als-EU-Kommissionspraesidentin-4472826.html">schon binnen 100 Tagen ethische KI-Vorgaben auf den Weg bringen zu wollen</a>, warnte Plöger vor einem Schnellschuss. Es gelte etwa zu überlegen, ob für Bereiche wie die Gesundheitsversorgung oder Mobilität andere Vorgaben nötig seien als für die Industrie allgemein. Dort habe sie "weniger Bedenken", da viele Systeme bereits liefen, "ohne dass irgendein Mensch Schaden nimmt".</p>
      <p>D21-Geschäftsführerin Lena-Sophie Müller verteidigte den von dem Netzwerk gefundenen Ansatz. Es ergebe etwa keinen Sinn, eine neue juristische "E-Person" für eine KI oder einen Roboter zu schaffen, erläuterte sie. Bei solchen Vorschlägen handle es sich um eine "Nebelkerze". Es sei aber genau im Sinne der Initiative, den Regulierungsdiskurs auf eine höhere Ebene heben.</p>
      <p>Mit den Leitlinien wirbt D21 auch dafür, in die Technik gelangte Vorurteile besser zu erkennen. Es gebe "kein algorithmisches System ohne menschliche Wahrnehmungen und Entscheidungen", erläuterte Irina Eckardt aus der einschlägigen Arbeitsgruppe. Der soziale, kulturhistorische und ökonomische Hintergrund präge generell persönliche Entscheidungen. Dieser Faktor werde unbewusst in jede Entwicklungsphase der Technik mit eingebracht.</p>
      <p>Bisher verborgene subjektive Wertungen in analogen Verfahren könnten durch das Umsetzen in algorithmischen Strukturen aber auch sichtbarer werden, heißt es in dem Papier. Dies helfe, erstere auf den Prüfstand zu stellen. Nötig seien auf jeden Fall "klare und verbindliche Richtlinien" zum Umgang mit Vorurteilen.</p>
      <h3>Transparente KI-Systeme</h3>
      <p>"Durch die Komplexität algorithmischer Systeme können Fehlurteile, Fehlfunktionen und Bias oftmals nur schwer oder eingeschränkt erkannt werden", haben die Verfasser erkannt. Transparenz sei deswegen "eine notwendige Grundlage" für deren Prüfbarkeit. Daher sollten die eingegebenen Daten, die verwendeten Methoden und die präsentierten Ergebnisse der Verfahren gegenüber Kontrollinstanzen offengelegt werden.</p>
      <figure>
        <img src="https://www.heise.de/imgs/18/2/7/9/3/0/8/1/Leitlinien-1c1ace57e7db2537.jpeg"/>
        <figcaption>Die Leitlinien der UAG Algorithmen-Monitoring. <br/>(Bild: Stefan Krempl)</figcaption>
      </figure>
      <p>"Algorithmische Systeme müssen von Anfang an so gestaltet werden, dass Prozesse im Nachhinein nachvollziehbar sind", schließt sich ein weiterer Punkt an. Zu viele veröffentlichte Informationen könnten die Beteiligten aber überfordern. Daher müssten "kontextbezogene Darstellungen" der verwendeten Methoden "mit Bezug auf unterschiedliche Nutzergruppen" ausgearbeitet werden.</p>
      <p>Generell sollte der Einsatz von Algorithmen dem Papier nach ethischen Grundsätzen unterliegen, "deren Einhaltung transparent und nachvollziehbar" ist. Dafür seien Mindeststandards nötig, die einschlägige Systeme auch vergleichbarer machten. Für unabdinglich hält es die Gruppe auch, dass die Technik einen "positiven Nutzen für die Gesellschaft erzeugen" und dem Gemeinwohl dienen müsse. Ähnliche <a href="https://www.heise.de/meldung/Algo-Rules-Ethische-Standards-sollen-im-Programmcode-verankert-werden-4328526.html">"Algo.Rules" hatten zuvor etwa bereits die Bertelsmann-Stiftung und die Denkfabrik iRights.Lab vorgelegt</a>. (<a href="mailto:olb@heise.de">olb</a>)</p>
    </article>
  </body>
</html>