<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <meta property="og:url" content="https://www.engadget.com/2019/11/12/intel-nervana-chips-for-ai-in-cloud/"/>
    <meta property="og:site_name" content="Engadget"/>
    <meta property="article:published_time" content="2019-11-12T21:44:00+00:00"/>
    <meta property="og:title" content="Intel unveils its first chips built for AI in the cloud"/>
    <meta property="og:description" content="There's also a next-gen computer vision chip."/>
  </head>
  <body>
    <article>
      <h1>Intel unveils its first chips built for AI in the cloud</h1>
      <h2>There's also a next-gen computer vision chip.</h2>
      <address><time datetime="2019-11-12T21:44:00+00:00">12 Nov 2019, 21:44</time> by <a rel="author" href="http://www.facebook.com/jonathanf" target="_blank">Jon Fingas</a></address>
      <p>Intel is no stranger to <a href="https://www.engadget.com/2019/01/07/intel-nervana-processor-for-inference/">AI-oriented chips</a>, but now it's turning its attention to those chips that might be thousands of miles away. The tech firm has <a href="https://newsroom.intel.com/news/intel-speeds-ai-development-deployment-performance-new-class-ai-hardware-cloud-edge/#gs.fnu7hq">introduced</a> two new Nervana Neural Network Processors, the NNP-T1000 (below) and NNP-I1000 (above), that are Intel's first ASICs designed explicitly for AI in the cloud. The NNT-T chip is meant for training AIs in a 'balanced' design that can scale from small computer clusters through to supercomputers, while the NNP-I model handles "intense" inference tasks.</p>
      <p>The chipmaker also unveiled a next-gen <a href="https://www.engadget.com/2019/01/23/intel-realsense-tracking-camera-t265/">Movidius</a> Vision Processing Unit whose updated computer vision architecture promises over 10 times the inference performance while reportedly managing efficiency six times better than rivals. Those claims have yet to pan out in the real world, but it's safe to presume that anyone relying on Intel tech for visual AI work will want to give this a look.</p>
      <p>You'll have to be patient for the Movidius chip when it won't ship until sometime in the first half of 2020. This could nonetheless represent a big leap for AI performance, at least among companies that aren't relying on rivals <a href="https://www.engadget.com/2018/12/12/nvidia-jetson-agx-xavier-robot-processor-available/">like NVIDIA</a>. Intel warned that bleeding-edge uses of AI could require performance to double every 3.5 months -- that's not going to happen if companies simply rely on conventional CPUs. And when internet giants like Facebook and Baidu lean heavily on Intel for AI, you might see practical benefits like faster site loads or <a href="https://www.engadget.com/2019-10-26-facebook-hides-people-from-facial-recognition.html">more advanced AI features</a>.</p>
      <figure>
        <img src="https://o.aolcdn.com/images/dims?crop=1600%2C1401%2C0%2C0&amp;quality=85&amp;format=jpg&amp;resize=1600%2C1401&amp;image_uri=https%3A%2F%2Fs.yimg.com%2Fos%2Fcreatr-uploaded-images%2F2019-11%2Fe028ea00-05a2-11ea-b1fb-f005ee7564bd&amp;client=a1acac3e1b3290917d92&amp;signature=dd947e72ff2ac5a1caae1587e765aed232e5f5a8"/>
      </figure>
      <footer>Source: <a href="https://newsroom.intel.com/news/intel-speeds-ai-development-deployment-performance-new-class-ai-hardware-cloud-edge/">Intel</a></footer>
    </article>
  </body>
</html>