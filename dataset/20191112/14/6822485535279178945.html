<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <meta property="og:url" content="https://www.alef.ir/news/3980821107.html"/>
    <meta property="og:site_name" content="جامعه خبری تحلیلی الف"/>
    <meta property="article:published_time" content="2019-11-12T14:03:00+00:00"/>
    <meta property="og:title" content="تسخیر میدان نبرد با هوش مصنوعی"/>
    <meta property="og:description" content="به گزارش خبرگزاری علم و فناوری؛ تاریخ حیات بشری سرشار از دوگانگی‌های بسیاری بوده که شاید جنگ و صلح را بتوان مهم ترین نمود و نتیجه همه آن ها محسوب کرد. تاریخ انسان، تاریخ جنگ و صلح و در واقع جنگ و صلح سازنده تاریخ انسانی بوده است. اگر این پندار صحیح باشد، تغییر در ابزار و ماهیت جنگ و صلح، تاریخ های متمایزی را رقم زده که برای درک و شناخت آن ها ناگزیر از شناخت ابزار و ماهیت جنگ ها و دگرگونی های آن‌ها هستیم."/>
  </head>
  <body>
    <article>
      <h1>تسخیر میدان نبرد با هوش مصنوعی</h1>
      <address>
        <time datetime="2019-11-12T14:03:00+00:00">12 Nov 2019, 14:03</time>
      </address>
      <p>امروزه کاربردهای مختلف هوش مصنوعی در ابعاد مختلف زندگی، بخصوص در مباحث نظامی، باعث مطرح شدن مسائل مختلف اخلاقی در باب استفاده از ربات‌ها در جنگ شده است.</p>
      <p>به گزارش خبرگزاری علم و فناوری؛ تاریخ حیات بشری سرشار از دوگانگی‌های بسیاری بوده که شاید جنگ و صلح را بتوان مهم ترین نمود و نتیجه همه آن ها محسوب کرد. تاریخ انسان، تاریخ جنگ و صلح و در واقع جنگ و صلح سازنده تاریخ انسانی بوده است. اگر این پندار صحیح باشد، تغییر در ابزار و ماهیت جنگ و صلح، تاریخ های متمایزی را رقم زده که برای درک و شناخت آن ها ناگزیر از شناخت ابزار و ماهیت جنگ ها و دگرگونی های آن‌ها هستیم.</p>
      <p>به نقل از پژوهش دکتر اصغر مشبکی، کاربردهای نوین هوش مصنوعی در خلال جنگ جهانی دوم و توسط نوربرت وینر یکی از دانشمندان دانشگاه فنی ماساچوست آغاز شد. وی با استفاده از مفهوم بازخورد، روشی برای ساخت توپ ضد هوایی با هدایت راداری ابداع نمود. کار اینگونه بود که دستگاه با دریافت اطلاعات، بازخورد از رادار، همواره موقعیت خود را تنظیم می کرد.</p>
      <p>الگوريتم‌هاي هوش مصنوعي با تكيه بر فناوري‌هاي كليدي مانند ميكروالكترونيك، نانو فناوري، سنسورها، محاسبات و ارتباطات درحال پيش بردن جوامع كنوني به سمت سيستم‌هايي هستند كه نقش عامل انساني كمرنگ‌تر شود. رايانه‌اي شدن سيستم‌ها يكي از شاخص‌هاي نشان دهنده افزايش سهم عنصر دانش در جنگ است. امروزه جنگ واقعاً از تمام جهات خودكار شده و مستلزم اين توانمندي است كه مقادير زيادي از داده‌ها در شكل‌هاي گوناگون مورد تجزيه و تحليل قرار گيرد.</p>
      <p>نسل جدید تسلیحات نظامی و روبات‌ها، از جنگ‌افزارهای ثابت در نیروی دفاعی کشورهاست. در عصر حاضر، کشورهای چین، روسیه، انگلستان و ایالات متحده به همراه پنجاه کشور دیگر به دنبال تقویت زرادخانه روباتیک خود، ازجمله روبات‌های نظامی مرگبار هستند و در این میان، کشور چین با رونمایی از 27 مدل مختلف روبات‌های مسلح تا سال 2012 میلادی، مقام اول را به خود اختصاص داده است.</p>
      <p>این حجم استفاده از روبات‌های نظامی، متخصصین علم روباتیک را بر آن داشته است تا با تکیه بر معیارهای مختلف، تعریفی مناسب برای این دسته از تسلیحات نوین ترتیب دهند. روبات ماشینی است که از طریق کنترل از راه دور یا بر اساس الگوهای ازپیش برنامه‌ریزی‌شده، دسته‌ای از وظایف با پیچیدگی‌های خاص را انجام می‌دهد و همچنین نسبت به انسان از درجات مختلف استقلال برخوردار است.</p>
      <p>در دنیای امروز، اما برخی شرکت‌های صنعتی که در حوزه فناوری کار می‌کنند در تلاش هستند به کمک هوش مصنوعی و یادگیری ماشین روبات‌های سرباز تولید کرده و روانه میدان جنگ کنند. ظاهرا جنگ آینده جنگ روبات‌ها خواهد بود.</p>
      <figure>
        <video src="http://media.stnews.ir/ckEditor/2214.mp4"/>
      </figure>
      <p>
        <b>مشکل استفاده از روبات‌ها در جنگ چیست؟</b>
      </p>
      <p>بهره‌گیری از روبات‌های نظامی در ارتش بعضی از کشورها به امری طبیعی و حتی لازم تبدیل شده است، درحالیکه برخی دیگر، تنها قربانی استفاده از آن هستند. باید گفت که روبات با هر میزان از استقلال، خطراتی به همراه خواهد داشت و بدین ترتیب، نیازمند نظارت نهایی انسان است.</p>
      <p>با استناد به نتایج پژوهش رضا اسلامی، استادیار دانشکده حقوق دانشگاه شهید بهشتی و نرگس انصاری که در سال 1395 انجام شد، باید گفت روبات نظامی به هنگام تطبیق با اصول کلیدی حقوق بشردوستانه بین‌المللی با مشکلاتی روبه‌روست که در ادامه به آن‌ها پرداخته می‌شود.</p>
      <p>تفکیک میان اهداف نظامی و غیرنظامی از پایه‌ای‌ترین قواعدی است که باید به هنگام درگیری رعایت شود. حتی اگر سامانه به گونه‌ای برنامه‌ریزی شود که فرد نظامی را، با توجه به نشانه‌های مشخص‌کننده، شناسایی کند، به علت عدم تعریف «غیرنظامی» در حقوق بشردوستانه، مشخص نیست که چه برنامه‌ای باید در نرم‌افزار روبات قرار بگیرد.</p>
      <p>شکی نیست وقتی که نتوان نظامی را از غیرنظامی تفکیک کرد، اصل تناسب را هم نمی‌توان به شایستگی اجرا کرد. بخش اساسی در این اصل، سنجش میزان تلفات جانبی و مزیت نظامی است. آن هنگام که معلوم نباشد که آیا روبات می‌تواند مرحله نخست را انجام دهد، یعنی تلفات غیرنظامیان را تعیین کند یا نه، اصلاً نمی‌توان به مرحله دوم یعنی سنجش مزیت نظامی ورود پیدا کرد. حتی اگر با استناد به برخی برنامه‌های موجود در روبات، از بخش نخست چشم‌پوشی شود، چگونه می‌توان از روبات انتظار داشت تا به سنجش مزیت نظامی و انجام فرایند تناسب، که فراتر از داده‌های کمی بوده و کاملاً ذهنی و کیفی است، بپردازد.</p>
      <figure>
        <img src="http://media.stnews.ir/ckEditor/3(221).jpg"/>
      </figure>
      <p>دکتر سید کمال الدین موسوی استاد جامعه شناسی جنگ و مدرس دانشگاه با اشاره به یکی از قدیمی‌ترین اهداف اساسی قواعد امری و عرفی حقوق بشردوستانه یعنی اصل تفکیک و مصونیت غیرنظامیان، گفت: این اصل باید در مخاصمه مسلحانه (ملی یا بین المللی) اعمال شود، زیرا این اصل در واقع تنظیم کننده نحوه استفاده از تسلیحات در درگیری های مسلحانه است.</p>
      <p>همچنین در پژوهش اسلامی و انصاری آمده است که مسئله دیگر آنکه هنوز سامانه نرم‌افزاری روبات قادر نیست وضعیت‌هایی مانند فرد خارج از کارزار یا حالتی مانند تسلیم شدن را تشخیص دهد. در این بین، اعطای امان، زیر سؤال خواهد رفت. اگر روبات به گونه‌ای برنامه‌ریزی شود که فرد X باید کشته شود و آن فرد، زخمی شده و تقاضای اسیرشدن به جای کشته شدن را کند، آیا روبات، توان دستگیری فرد به جای قتل او را خواهد داشت؟</p>
      <p>در صورت استفاده از روبات در میدان جنگ و نقض قواعد حقوق بشردوستانه، تعیین شخص مسئول، مشکل است. عامل، فرمانده، تولیدکننده یا برنامه‌ریز در مقام اتهام قرار خواهند گرفت که با این حال، هیچکدام به طور جدی مسئول اصلی نخواهند بود. عدم پاسخگویی و شفافیت، مهم‌ترین دغدغه پیش روی تسلیحات روباتیک با هر درجه از استقلال خواهد بود.</p>
      <p>دکتر موسوی با اشاره به عدم تعریف دقیق غیرنظامیانی که حمایت قانونی خود را از دست می‌دهند با وجود هوش مصنوعی، اظهار داشت: این مسئله باعث می شود سرباز هنگام مواجهه با این اهداف، دچار شک و عدم قطعیت شود. حال انسان به واسطه قدرت تفکر، تجزیه و تحلیل و همچنین حس شفقت متناسب با وضعیت، تصمیم به شلیک یا عدم شلیک می‌گیرد.</p>
      <p>با عنایت به مباحث مطرح شده در پژوهش اسلامی و انصاری و نظرات دکتر موسوی، می‌توان گفت روبات‌های نظامی در مواجهه با حقوق بشردوستانة کنونی با خلأ روبه‌رو هستند. گرچه موافقان با استدلالات خود، سعی در سازگار نشان دادن این نوع تسلیحات با قواعد موجود داشته‌اند، این موارد نتوانسته به چالش‌های جدی و مشخص در این حوزه پاسخ دهد. به عبارت دیگر، اگر دولت‌ها خواستار بهره‌گیری از روبات‌های نظامی هستند، با توجه به مشکلات عدیده مذکور، باید به فکر تنظیم شکل جدیدی از حقوق جنگ باشند یا اینکه به هنگام طراحی روبات‌ها، خط قرمز حقوق بشردوستانه موجود را در تمام زمینه‌ها رعایت کنند که در این صورت، بهره‌گیری از روبات نظامیِ کاملاً خودمختار، این خط قرمز را زیر سؤال خواهد برد.</p>
    </article>
  </body>
</html>