<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <meta property="og:url" content="https://www.calcalist.co.il/conference/articles/0,7340,L-3774457,00.html"/>
    <meta property="og:site_name" content="כלכליסט - www.calcalist.co.il"/>
    <meta property="article:published_time" content="2019-11-25T00:00:00+00:00"/>
    <meta property="og:title" content="נמרוד קוזלובסקי: &quot;הרגולציה בעתיד תאפשר ללקוחות להבין כיצד הבנקים דרגו את האשראי שלו&quot;"/>
    <meta property="og:description" content="ד&quot;ר קוזלובסקי מאוניברסיטת ת&quot;א, אמר בוועידת Mind the Tech TLV של כלכליסט ובנק לאומי, כי &quot;באירופה אזרח יהיה זכאי לדעת את הלוגיקה של כל מערכת ועד לרמה שהוא יוכל לקבל תשובה למה הוא לא זומן לראיון&quot;"/>
  </head>
  <body>
    <article>
      <h1>נמרוד קוזלובסקי: "הרגולציה בעתיד תאפשר ללקוחות להבין כיצד הבנקים דרגו את האשראי שלו"</h1>
      <h2>ד"ר קוזלובסקי מאוניברסיטת ת"א, אמר בוועידת Mind the Tech TLV של כלכליסט ובנק לאומי, כי "באירופה אזרח יהיה זכאי לדעת את הלוגיקה של כל מערכת ועד לרמה שהוא יוכל לקבל תשובה למה הוא לא זומן לראיון"</h2>
      <address><time datetime="2019-11-25T00:00:00+00:00">25 Nov 2019</time> by <a rel="author">ליאור גוטמן</a></address>
      <p>"המחוקק האמריקאי אומר בפעם הראשונה שהוא טעה כשנתן לחברות מסחריות להחליט כיצד לדרג בני אדם, מי ישאר בכלא או מי יקבל אשראי. שיטת הדירוג הישנה עם האלגוריתמים הוותיקים נעצרה, ומהיום כל פרויקט בינה מלאכותית יהיה חייב בהערכה של מקור המידע לרבות תשובה על השאלה האם התוצאות של השיטה גוררות הטיה באופן קבוע" - כך אמר ד"ר נמרוד קוזלובסקי מאוניברסיטת תל אביב בוועידת Mind the Tech TLV של כלכליסט ובנק לאומי.</p>
      <p>קוזלובסקי הציג שלושה מקרים שבהם מאגרי המידע גרמו להטיה לכאורה של תהליך קבלת ההחלטות ועד לרמת השליטה בגורלם של אנשים.</p>
      <p>"בארה"ב גרים רק 5% מאוכלוסיית העולם אבל אחוז האסירים שם, ביחס למספר התושבים, הוא אחד הגבוהים שיש. המציאות הזו הובילה מומחים לבחון מעצרי בית במקום מאסר, ואז הוצע לקחת מערכת בינה מלאכותית שתבחן כל אסיר ביחס לחברים שלו, מוצא והתנהגות, מה שיוביל לדרוג האפשרות שהוא יחזור לפשיעה. הציון שהתקבל קבע מי יזכה למעצר בית ומי ישאר בכלא, אבל כשהחליטו לחקור את התוצאות מצאו שמאגרי המידע לא היו עדכניים או מדויקים, מה שהשפיע על הציון של כל אסיר".</p>
      <figure>
        <img src="https://images1.calcalist.co.il/PicServer3/2019/11/25/949899/1NL.jpg"/>
        <figcaption>ד"ר נמרוד קוזלובסקי, HFN אוניברסיטת ת"א <br/>צילום: יריב כץ</figcaption>
      </figure>
      <p>קוזלובסקי סיפר שהמערכת השנייה שמצאה בעיות היא מערכת הרווחה האמריקאית. "יש 7.5מיליון ילדים שמדוּוחים כילדים בסיכון, עם חשש שאם ישארו במשפחה ייגרם להם נזק. עברו על הסטטייסטיקה וגילו יותר מ-2 מיליון שיחות למוקדי חירום, שם התקבלה החלטה האם שולחים עובדים סוציאלים לבחון מצב של ילד, וגם שם התקבלה החלטה לאמץ בינה מלאכותית עם שורת אלגוריתמים שמנסים ללמוד או לחזות מתי ילד בסיכון. הבחינה של השיטה עוררה המון רעש כי התברר שבחלק מהמקרים ההחלטה לגבי ילד התקבלה בטעות כיוון שהמידע שהוזן למערכת בחנה סיכון של ילד הסתמכה על הנחות בני עשרות שנים". המערכת השלישית, לדברי קוזלובסקי, היתה היכולת לקבל קרדיט מבנק ההשקעות גולדמן זאקס, שם התגלה שגברים מקבלים דירוגי אשראי טובים מכאלה שקיבלו נשים, כאשר אחת הסיבות היתה הסתמכות על סיכוי כיסויי ההלוואות. נשים  זכו לדירוג שונה, גם בשל התבססות על מקצועות "נשיים" ישנים שהיו נפוצים לפני עשרות שנים. המסקנה של קוסלובסקי היא שבעתיד הרגולטור יחייב להציג פומבית מידע, כך שאם מישהו ירצה לתבוע על כל שחרצו את גורלו על בסיס אלגוריתם שגוי, הוא יוכל לעשות את זה. "באירופה זה קצת שונה עם כוונה דומה - יעניקו לאנשים את הזכות לדעת שקיבלו החלטה, כך שהאזרח יהיה זכאי לדעת את הלוגיקה של כל מערכת ועד לרמה שהוא יוכל לקבל תשובה למה הוא לא זומן לראיון", סיכם.</p>
    </article>
  </body>
</html>