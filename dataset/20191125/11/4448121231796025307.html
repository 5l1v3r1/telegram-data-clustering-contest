<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <meta property="og:url" content="https://www.focus.de/digital/dldaily/gastbeitrag-kasparov-ki-vergisst-nie-also-muessen-wir-ihr-beibringen-wie-man-vergibt_id_11386569.html"/>
    <meta property="og:site_name" content="FOCUS Online"/>
    <meta property="article:published_time" content="2019-11-25T11:54:00+00:00"/>
    <meta property="og:title" content="Gastbeitrag: Kasparov: KI vergisst nie – also müssen wir ihr beibringen, wie man vergibt"/>
    <meta property="og:description" content="In seiner FOCUS-Online-Kolumne setzt sich Schachlegende Garry Kasparov mit den Chancen und Gefahren der Künstlichen Intelligenz auseinander. Fehler und Verbrechen würden durch die neue Technologie für immer gespeichert und erinnert, schreibt er. Um ungeahnte Konsequenzen zu verhindern, müsse sich die Gesellschaft schon jetzt darüber klar werden."/>
  </head>
  <body>
    <article>
      <h1>Gastbeitrag: Kasparov: KI vergisst nie – also müssen wir ihr beibringen, wie man vergibt</h1>
      <address><time datetime="2019-11-25T11:54:00+00:00">25 Nov 2019, 11:54</time> by <a rel="author">FOCUS Online</a></address>
      <p>In seiner FOCUS-Online-Kolumne setzt sich Schachlegende Garry Kasparov mit den Chancen und Gefahren der Künstlichen Intelligenz auseinander. Fehler und Verbrechen würden durch die neue Technologie für immer gespeichert und erinnert, schreibt er. Um ungeahnte Konsequenzen zu verhindern, müsse sich die Gesellschaft schon jetzt darüber klar werden.</p>
      <p>Wie Haruki Murakami in seinem Roman „Kafka am Strand“ schreibt, gibt es zu viele Dinge, an die wir jeden Tag denken müssen und zu viele neue Dinge, die wir lernen müssen: neue Stile, neue Informationen, neue Technologien und neue Terminologie.</p>
      <p>´Doch egal, wie viel Zeit vergeht, gibt es Dinge, die niemals in Vergessenheit geraten und Erinnerungen, die wir nicht abschütteln können. Sie bleiben wie ein Prüfstein für immer ein Teil von uns. Künstliche Intelligenz ist so ein Prüfstein: Sie hört mit, das lässt sich nicht vermeiden – dabei müssen wir vor allem die Privatsphäre von Kindern schützen.</p>
      <p>Laut einem im April dieses Jahres veröffentlichten <a href="https://about.ads.microsoft.com/en-us/blog/post/april-2019/new-report-tackles-tough-questions-on-voice-and-ai">Bericht von Microsoft</a> ist für Benutzer von digitalen Assistenten wie Amazons Alexa und Apples Siri weiterhin der Komfort wichtiger als potenzielle Bedenken bezüglich ihrer Privatsphäre.</p>
      <h3>Über den Autor</h3>
      <p>Garry Kasparov wurde 1985 der jüngste Schachweltmeister der Geschichte und galt 20 Jahre lang als weltbester Spieler. Das Potenzial von künstlicher Intelligenz wurde ihm erstmals während seiner berühmten Wettkämpfe gegen den Schachcomputer Deep Blue bewusst. Seitdem engagiert er sich als Fürsprecher für Zukunftstechnologien, jüngst in seiner Rolle als Sicherheitsbotschafter von Avast. In dieser Rolle erörtert er Herausforderungen rund um die Themen Cybersicherheit und digitale Zukunft. Er lebt mit seiner Familie in <a href="https://www.focus.de/orte/new-york/">New York</a> City.</p>
      <p>Achtzig Prozent der Befragten geben an, dass sie mit dem Nutzen dieser Geräte zufrieden sind; nur etwa die Hälfte davon (41 Prozent) äußern Bedenken bezüglich der von ihnen erfassten Daten. Dies ist ein Kompromiss, den jeder von uns im digitalen Zeitalter eingehen muss. Dabei gibt es keine richtigen oder falschen Antworten.</p>
      <h3>Ungerechte Bürde für Kinder</h3>
      <p>Es gibt allerdings fundierte und nicht fundierte Entscheidungen, und ich gehe davon aus, dass diese Befragten nicht gründlich darüber nachgedacht haben, wie die Daten, mit denen sie ihre virtuellen Assistenten füttern, verwendet werden können. Unsere Daten werden in Algorithmen eingepflegt, die Eigentümerkette wird durchbrochen und wir verlieren die Kontrolle – gerade für Kinder ist das eine ungerechte Bürde und ein potenzielles Sicherheitsrisiko.</p>
      <p>Selbst wenn Sie den datenerhebenden Firmen und den Algorithmen, die diese Daten analysieren und verwenden, vertrauen, gibt es Anlass zur Sorge, da Hacker Zugriff darauf erlangen könnten.</p>
      <p>Wir können zwar nachvollziehen, warum eine kriminelle Hackerbande unsere Kreditkartennummern und Informationen zu unserer Identität erhalten will, doch niemand weiß genau, welchen Schaden eine Ausschlachtung der KI-Analyse unserer Verhaltensmuster, unserer biometrischen Daten sowie anderer sensibler Informationen anrichten könnte.</p>
      <p>Staatliche Akteure könnten sich diese Informationen zu Nutze machen, um Geheimnisse zu stehlen, sich in Wahlen einzumischen oder Amtsträger zu manipulieren und zu erpressen. Repressive Staaten machen bereits von fortgeschrittenen Hacker-Tools Gebrauch und haben es dabei auf Dissidenten und andere Gruppierungen abgesehen.</p>
      <h3>KI-Maschinen werden mit Ihren Daten gefüttert</h3>
      <p>Es gibt gute Gründe, wieso man digitale Assistenten mit Vorsicht genießen sollte. Das vorliegende Geschäftsmodell ist abhängig von kontinuierlichen Verbesserungen in Bezug auf Genauigkeit und Intelligenz. Die erhaltenen Daten werden in den Lernalgorithmus der Maschine integriert, was der KI dabei hilft, Fehler aus der Vergangenheit nicht zu wiederholen und bessere Vorhersagen zu treffen. In einer wiederkehrenden Schleife nutzt der Verbraucher diese Technologie und stellt gleichzeitig kontinuierlich Material zu deren Verbesserung zur Verfügung.</p>
      <p>Zeitgleich zum oben erwähnten Bericht von Microsoft wurde enthüllt, dass sich Amazon-Mitarbeiter zu Analysezwecken die Sprachaufzeichnungen von Alexa anhören, um die Software zu trainieren und somit eine höhere Leistungsfähigkeit zu erzielen – ohne, dass der Alexa-Nutzer davon etwas weiß.</p>
      <p>Amazon betonte zwar, dass es sich bei den Aufnahmen nur um eine „sehr kleine Stichprobe“ handle, um das Verbrauchererlebnis verbessern zu können. Beunruhigend dabei ist jedoch, dass selbst Benutzer, die sich dagegen entscheiden, dass ihre Aufzeichnungen in das System zurückgeführt werden, immer noch diesem manuellen Prüfungsprozess unterzogen werden können. Auch <a href="https://www.pcwelt.de/news/Facebook-liess-Audio-Chats-der-Nutzer-transkribieren-10646752.html">Facebook </a>und <a href="https://www.appgefahren.de/apple-entschuldigt-sich-fuer-siri-aufnahmen-und-kuendigt-verbesserungen-an-259106.html">Apple </a>haben im Sommer dieses Jahres zugegeben, Messenger-Gespräche beziehungsweise Siri-Aufzeichnungen mit angehört zu haben, um den Dienst und die Sprachassistentin zu verbessern. Mit anderen Worten: Die Informationen, die Sie Ihrem digitalen Assistenten zur Verfügung stellen, landen nicht einfach nur in der Blackbox einer KI. Es kann gut sein, dass sie von anderen Menschen angehört werden und natürlich auch auf Sie zurückgeführt werden können.</p>
      <h3>Wir verlieren die Kontrolle über unsere Daten</h3>
      <p>Wir machen uns meist Sorgen darum, dass andere Menschen Zugriff auf unsere Daten erhalten könnten, doch wie steht es um die Algorithmen selbst? Dieses Problem ist nicht nur auf die Produktklasse der digitalen Assistenten beschränkt – es knüpft an deutlich weitreichendere Überlegungen zur KI an.</p>
      <p>Jene Informationen, die wir an intelligente Maschinen abtreten, können durchaus als diskrete Pakete eingespeist werden, doch sie sind im Nachhinein nicht weiter identifizierbar, sobald sie vom Netzwerk erfasst wurden. Es geht nicht mehr nur darum, Rechte und Vorschriften festzulegen, die Verbrauchern das Eigentumsrecht an ihren Daten zusichern. Heutzutage werden Informationen über uns fortwährend in komplexe Algorithmen eingepflegt, oftmals in solche, die nicht einmal mehr für die Programmierer, die sie entwickelt haben, transparent sind.</p>
      <p>Unsere individuellen Datenpunkte stärken diese Systeme und helfen sie zu erweitern, doch im Zuge dessen verlieren wir die Kontrolle über unsere Daten. Im Falle einer KI gibt es nicht die Möglichkeit, es sich anders zu überlegen und das Recht am digitalen Eigentum wieder einzufordern.</p>
      <p>Es sei an dieser Stelle angemerkt, dass es sich hierbei nicht nur um philosophische Überlegungen handelt. Sehen wir uns doch nur einmal die Verabschiedung der Datenschutz-Grundverordnung (DSGVO) durch die Europäische Union an: Wie setzen Regierungsbehörden beispielsweise das <a href="https://www.datenschutzbeauftragter-info.de/das-recht-auf-vergessenwerden-bzw-die-loeschungspflicht-nach-dsgvo/">„Recht auf Vergessenwerden“</a> um, falls die fraglichen Daten in die Lernprozesse einer KI eingeflossen sind?</p>
      <h3>Kinder sollten ihre Fehltritte für sich behalten dürfen</h3>
      <p>Darüber hinaus müssen wir auch die Folgen für die Generation, die mit dieser Technologie aufwächst, in Betracht ziehen. Sie wird vor Herausforderungen stehen, mit denen sich noch keine Generation zuvor auseinandersetzen musste. Beispielsweise finden sich von vielen Vertretern umfassende digitale Aufzeichnungen im Internet wieder, die ihr Leben von klein auf dokumentieren und die bei jedem <a href="https://www.focus.de/thema/bewerbung/">Vorstellungsgespräch</a>, jeder Kreditanfrage, ja sogar bei potenziellen Dates wieder an die Oberfläche kommen können.</p>
      <p>Digitale Assistenten werden Kinder oder Teenager über die dauerhaften Auswirkungen der von ihnen geteilten Daten nicht auf dieselbe geduldige Art und Weise aufklären, wie es ein Mensch tun könnte. Den Sprachassistenten sind diese Überlegungen bei der Aufzeichnung von Informationen gleichgültig. Die von ihnen gesammelten Informationen können dann in Algorithmen eingebunden werden, die erhebliche Nachwirkungen haben können.</p>
      <p>Ein Schüler, der in einer Videoaufzeichnung beim Spicken erwischt wurde, könnte von diesem Fehltritt bis ins Erwachsenenalter verfolgt und dafür immer wieder bestraft werden, was einen Teufelskreis von Misserfolgen und weiteren Fehltritten nach sich ziehen könnte. Es liegt nahe, dass wir eine Gesellschaft aufbauen möchten, in der Kinder genug Freiheit haben, Fehler zu begehen und aus ihnen zu lernen.</p>
      <p>Doch wir haben die optimalen Voraussetzungen für das genaue Gegenteil geschaffen, indem wir der KI so viel Macht übertragen haben: Wir haben eine Welt geschaffen, in der Fehler aus der Vergangenheit zu untilgbaren Einträgen in der Akte eines Menschen werden und die Chancen zur eigenen Weiterentwicklung erheblich einschränken.</p>
      <h3>Wir müssen unsere Grundwerte in den Mittelpunkt der Diskussion stellen</h3>
      <p>Daher müssen wir unbedingt eine Balance zwischen den unglaublichen Fähigkeiten dieser Technologien und deren Schattenseiten finden. Wir sollten KI-Systeme auch weiterhin verbessern, damit sie unseren Bedürfnissen gerecht werden. Mit ihrer kontinuierlich steigenden Intelligenz und Effizienz werden sie zu immer wertvolleren Partnern im Aufbau einer pulsierenden und wohlhabenden Gesellschaft.</p>
      <figure>
        <img src="https://p5.focus.de/img/fotos/origs10161113/2028215391-w630-h90-o-q72-p4/dld-header-app-996x143-min-alt.jpg"/>
        <figcaption>FOCUS Online / Shuang Liu</figcaption>
      </figure>
      <h3>DLDaily</h3>
      <p>Die Digitalisierung verändert Deutschland – zum Positiven, wenn wir es richtig anpacken. Auf der <a href="https://dld-conference.com/">Digitalkonferenz DLD</a>, die wie FOCUS Online zu Hubert Burda Media gehört, diskutieren Experten mehrmals im Jahr über diese Entwicklungen. Diesen Geist, diese Themen, möchte FOCUS Online seinen Lesern das ganze Jahr über bieten: mit <a href="https://www.focus.de/digital/dldaily/">DLDaily</a>. FOCUS Online spricht für DLDaily mit Menschen, die Konzepte für die digitale Zukunft haben: mit innovativen Politikern, visionären Denkern, kreativen Gründern. Wir erklären die neuen Technologien und zeigen, wie sie sich in Beruf und Privatleben nutzen lassen.</p>
      <p>Alle DLDaily-Artikel <a href="https://www.focus.de/digital/dldaily/">finden Sie hier</a>.</p>
      <p>Doch die oben geschilderten Probleme sind ernst und erfordern dringend unsere Aufmerksamkeit. Es ist unmöglich, die richtigen Lösungen zu finden, wenn wir es nicht schaffen, unsere Grundwerte in den Mittelpunkt der Diskussion zu stellen.</p>
      <p>Die Gesetzgebung muss die Verpflichtung zum Schutz der Privatsphäre des Einzelnen in einer für das digitale Zeitalter angemessenen Form wahren. Die unglaubliche Macht der KI besteht darin, dass sie Zusammenhänge in Daten findet, die vor dem menschlichen Verstand verborgen bleiben, was unweigerlich ungewollte Konsequenzen nach sich ziehen wird.</p>
      <p>Unter Berücksichtigung des technologischen Fortschritts müssen die Lösungen von heute viel globaler sein, um den Technologien, für die sie entworfen werden, gerecht zu werden. Gleichzeitig müssen sie diese Rechte schützen, ohne dabei dem weiteren technologischen Fortschritt den Weg zu versperren.</p>
      <p>Für mich als Familienvater ist meine Begeisterung dafür, dass meine Kinder in dieser revolutionären Zeit aufwachsen, viel größer als meine Angst davor. Doch um sicherzustellen, dass sie die Vorteile dieser leistungsfähigen digitalen Tools genießen können, müssen wir deren langfristige Folgen erkennen, insbesondere für diejenigen, die zu jung sind, um das Ausmaß zu begreifen.</p>
    </article>
  </body>
</html>