<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <meta property="og:url" content="https://money.bg/inovations/novi-tehnologii-novi-predizvikatelstva-diskriminatsiyata-v-izkustveniya-intelekt.html"/>
    <meta property="og:site_name" content="Money.bg"/>
    <meta property="article:published_time" content="2019-11-16T19:00:55+00:00"/>
    <meta property="og:title" content="Нови технологии, нови предизвикателства: Дискриминацията в изкуствения интелект"/>
    <meta property="og:description" content="Могат ли историческите предубеждения да се пренесат в новите технологии?"/>
  </head>
  <body>
    <article>
      <h1>Нови технологии, нови предизвикателства: Дискриминацията в изкуствения интелект</h1>
      <address>
        <time datetime="2019-11-16T19:00:55+00:00">16 Nov 2019, 19:00</time>
      </address>
      <p>Преди година Google съобщи за революционна технология за изкуствен интелект, наречена BERT. Технологията се използва в интернет търсачката на Google и се самообучава от дигитализирана информация в пространството. Източниците могат да бъдат всевъзможни - записи в Wikipedia, новинарски статии и стари книги. Според експерти това представлява голям проблем - изкуственият интелект на BERT може да се самообучава грешно и вместо да е абсолютно обективен, резултатът от продукта може да бъде точно обратен.</p>
      <p>Подобни предизвикателства правят технологията нож с две остриета. BERT и другите подобни продукти могат да внесат старите предубеждения в новите технологии, пишат специалистите от OODA Analyst.</p>
      <p>Един от основните проблеми на BERT е това, че технологията дискриминира жените. Когато говорим за програмиране например, изкуственият интелект е много по-вероятно да го свърже с мъжете, отколкото с жените.</p>
      <p>По-дълбок анализ показва, че когато технологията продължава да се разраства в нови домейни и продукти, започват да изкачат и нови неочаквани предубеждения.</p>
      <p>Компютърният учен Робърт Мънро подава 100 често използвани думи на BERT. В 99 от 100 случая BERT свързва думите с мъже. Думи като "пари", "къща" и "действие" се свързват с мъжете, докато само една дума се свързва с жените - "мама".</p>
      <p>Това е форма на историческа пристрастност към пола, която може да продължи да увековечава днешното общество чрез дори чрез изкуствения интелект чрез технологии като BERT, пишат авторите.</p>
      <p>Темата за пристрастията на изкуствения интелект вече се дебатира усилено. За да може сектора наистина да допринесе благоприятно за гражданите, предприятията и правителствата по света, специалистите от аналитичната компания обясняват, че тези и други въпроси трябва да бъдат смекчени.</p>
      <p>Анализаторите препоръчват развитието на технологията да се придържа към следните отправни точки:</p>
      <p>Сигурността на изкуствения интелект е от огромно значение, поради което екипът препоръчва изготвянето на стратегия. Това минава чрез четири стъпки, които предотвратяват някои проблеми, още преди те да се развият.</p>
      <ol>
        <li>Защита на ИИ инфраструктурата - технологиите за изкуствен интелект разчитат на стабилен набор от инфраструктурни компоненти за успешна работа, които предотвратяват неправомерни прониквания.</li>
        <li>Подсигуряване на алгоритмите - процес, който изследва техническата реализация на ИИ в контраст с желаната бизнес логика и резултати от ИИ внедряването. Това е подход със стрес тестове на алгоритмите, така че технологията да гарантира бъдещата си ефективност и самообучение чрез нови начини, при които алгоритмите не могат да бъдат манипулирани.</li>
        <li>Защита на данни при самообучение - един от най-важните проблеми при сигурността на ИИ е защитата на данните, използвани при обучението на алгоритмите. Това обаче трябва да бъде приоритет в самото начало на проектирането, така че да се гарантира използването на най-добрите практики за добра дигитална хигиена.</li>
        <li>Идентифициране и управление на външни зависимости и рискове - много платформи за ИИ разчитат на външни източници на данни, а съвременните технологии трябва да гарантират, че тези външни зависимости не създават рискове за бизнес и другите резултати.</li>
      </ol>
      <p>Според авторите изкуственият интелект може и трябва да прави грешки. Когато експертите изучават тези проблеми, те могат по-лесно да помогнат за тяхното преодоляване. Това би станало дори по-лесно, ако се разработи мащабно ръководство за вземане на решения, което да се използва генерално от технологиите за ИИ, особено при употребата от хората, където възникват най-много морални въпросителни.</p>
      <p>Бъдещето на ИИ е неписано, но със сигурност е едно от полетата, в които различните правителства и големите световни корпоративни гиганти ще се борят за надмощие. Според други пък голямата надпревара всъщност ще бъде кратка, защото създаването на добра технология ще има мигновена възвръщаемост, което ще откри успелите технологични компании. Такива резултати обаче не могат да бъдат постигнати, ако софтуерът е дискриминативен, независимо дали на полов, расов, религиозен или друг признак. Съществуващите безброй възможности оставят темата отворена.</p>
    </article>
  </body>
</html>