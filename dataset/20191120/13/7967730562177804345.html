<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <meta property="og:url" content="https://www.theage.com.au/business/companies/making-digital-giants-liable-for-online-posts-is-unworkable-20191120-p53ceg.html?ref=rss&amp;utm_medium=rss&amp;utm_source=rss_feed"/>
    <meta property="og:site_name" content="The Age"/>
    <meta property="article:published_time" content="2019-11-20T13:00:00+00:00"/>
    <meta property="og:title" content="Making digital giants liable for online posts is unworkable"/>
    <meta property="og:description" content="Forcing Facebook to be liable for defamatory posts on social media could undermine the business models of the tech titans, threaten grassroots activism and fail to fix the issues that news organisations face. "/>
  </head>
  <body>
    <article>
      <h1>Making digital giants liable for online posts is unworkable</h1>
      <address><time datetime="2019-11-20T13:00:00+00:00">20 Nov 2019, 13:00</time> by <a rel="author">Jennifer Duke</a></address>
      <p>Forcing Facebook to be liable for defamatory posts on social media could undermine the business models of the tech titans, threaten grassroots activism and fail to fix the issues that news organisations face.</p>
      <p>Attorney-General Christian Porter has added his voice to a growing chorus that social media websites need to be treated with a firmer hand by suggesting digital giants be more accountable for online posts.</p>
      <figure>
        <img src="https://static.ffx.io/images/$zoom_0.151%2C$multiply_2.1164%2C$ratio_1.5%2C$width_756%2C$x_0%2C$y_129/t_crop_custom/q_62%2Cf_auto/316fbffbaffeaf22b1c47c98b0c1ec3272e29a0e"/>
        <figcaption>Making Facebook and other digital giants liable for defamatory comments could have unintended consequences.<cite>Shutterstock</cite></figcaption>
      </figure>
      <p>It is not controversial to suggest, as Porter has, that the legal environment for traditional media companies is unfair and the playing field needs to be levelled. But the biggest issue with defamation laws isn't that they are too narrowly focused but that they are too onerous for public interest journalism.</p>
      <p>There are already certain forms of content that society has collectively agreed are unacceptable, such as child exploitation and violent terrorist material. In most cases, what falls into these categories is relatively clear-cut and the government has imposed new rules about abhorrent content since the <a href="https://www.theage.com.au/link/follow-20170101-p529a2.html">Christchurch attacks.</a></p>
      <p>But making Facebook, Google, Twitter and the other online giants liable for posts in this way is unworkable because what is actually "defamatory" is not always clear and negative comments can at the same time be offensive, important and true. There is not yet a way to manage this level of nuance through artificial intelligence at scale.</p>
      <p>Porter acknowledges there would be difficulties, saying "you have to, of course, take into account, reasonable, sensible measures for how you do that ... because of the volume of what goes on in Twitter and Facebook is much larger than the volume from a standard newspaper".</p>
      <p>It's not just the volume of content that is so different. For most people a comment on Facebook does not hold the same weight as an article in a trusted news title. It's right to treat the two differently.</p>
      <p>Like it or not, at the heart of how social media websites function is unedited user-generated content. It is the reason 60 per cent of Australians flock to Facebook every month, with many posting many times a day.</p>
      <p>It is also why grassroots activist groups flourish on social media. Acting too quickly to force digital giants to sanitise comments could have unintended consequences, such as making these companies so risk-averse that important movements such as #MeToo are ranked lower or stopped in their tracks in Australia.</p>
      <related>
        <a href="https://www.theage.com.au/link/follow-20170101-p53cch.html"/>
      </related>
      <p>Porter's concerns about the <a href="https://www.theage.com.au/link/follow-20170101-p520rf.html">NSW Supreme Court decision</a> that means media companies are liable for defamatory comments made by users on their public Facebook pages are also legitimate. But better tools for moderation and faster responses to direct complaints to the social media websites through official channels are much simpler initiatives.</p>
      <p>Those choosing to use social media also shouldn't be able to outsource their personal accountability.</p>
      <p>As recommended by the competition and consumer watchdog’s digital-platform review’s final report to the government, an ombudsman for complaints about the tech giants could also help in situations when there is disagreement.</p>
      <p>By all means encourage the digital giants to respond more quickly and provide adequate tools for publishers, but making defamation an issue for even more companies threatens to further complicate an area that is already fraught.</p>
    </article>
  </body>
</html>