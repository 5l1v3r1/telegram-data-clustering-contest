<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <meta property="og:url" content="https://www.gizmodo.com.au/2019/11/instead-of-showing-leadership-twitter-pays-lip-service-to-the-dangers-of-deep-fakes/"/>
    <meta property="og:site_name" content="Gizmodo AU"/>
    <meta property="article:published_time" content="2019-11-20T14:31:25+00:00"/>
    <meta property="og:title" content="Instead Of Showing Leadership, Twitter Pays Lip Service To The Dangers Of Deep Fakes"/>
    <meta property="og:description" content="Fake videos and doctored photographs, often based on events such as the Moon landing and supposed UFO appearances, have been the subject of fascination for decades...."/>
  </head>
  <body>
    <article>
      <h1>Instead Of Showing Leadership, Twitter Pays Lip Service To The Dangers Of Deep Fakes</h1>
      <address><time datetime="2019-11-20T14:31:25+00:00">20 Nov 2019, 14:31</time> by <a rel="author">David Cook</a></address>
      <figure>
        <img src="https://edge.alluremedia.com.au/m/g/2019/11/deepfakezuck.jpg"/>
        <figcaption>Image: Getty Images</figcaption>
      </figure>
      <p>Fake videos and doctored photographs, often based on events such as the <a href="https://www.space.com/apollo-11-moon-landing-hoax-believers.html">Moon landing</a> and supposed UFO appearances, have been the subject of fascination for decades.</p>
      <p>Such imagery is often <a href="https://www.forbes.com/sites/chenxiwang/2019/11/01/deepfakes-revenge-porn-and-the-impact-on-women/#4f721c5e1f53">deep fake content</a>, called so because it uses deep learning associated with neural networks and digital image processing.</p>
      <p>Last week, Twitter <a href="https://www.reuters.com/article/us-twitter-deepfakes/twitter-wants-your-feedback-on-its-deepfake-policy-plans-idUSKBN1XL2C6">revealed</a> plans to introduce a <a href="https://blog.twitter.com/en_us/topics/company/2019/synthetic_manipulated_media_policy_feedback.html">new policy</a> governing deep fake videos on its platform.</p>
      <p>The company proposed it would warn users about deep fake content by flagging tweets with “synthetic or manipulated media”. Twitter says media may be removed in cases where it could lead to serious harm, but has stopped short of enforcing a strict removal stance. Users have until November 27 to provide feedback.</p>
      <p>In adopting this warning-only approach towards deep fakes, the social media giant has shown poor judgement.</p>
      <related>
        <a href="https://www.gizmodo.com.au/2019/08/what-are-deepfakes"/>
      </related>
      <h3>Why deep fakes are dangerous</h3>
      <p>With advances in computer science, deep fakes are becoming an increasingly powerful tool to deceive people using social media.</p>
      <p>Deep fake clips of celebrities and politicians are realistic enough to trick users into making financial, political and personal decisions based on the fake testimony of others.</p>
      <figure>
        <iframe src="https://www.youtube.com/embed/VWrhRBb-1Ig" width="640" height="360" data-service="Youtube" scrolling="no"/>
      </figure>
      <p>Whether it’s a David Koch <a href="https://www.dailymail.co.uk/tvshowbiz/article-6204111/David-Koch-unwillingly-face-erectile-dysfunction-advertising-scam.html">erectile dysfunction cream</a> scam, an announcement by Donald Trump that <a href="https://shots.net/news/view/has-donald-trump-eradicated-aids">AIDs has been eradicated</a>, or a fake interview with Andrew Forrest leading to a <a href="https://www.commerce.wa.gov.au/announcements/scammers-use-fake-twiggy-forrest-investment-fleece-woman-out-670000">finance scam</a>, deep fakes present a serious risk to our ability to trust what we view online.</p>
      <p>Social media companies have so far taken a sloppy approach to this threat. They have even promoted the use of photo algorithms letting users experiment with animated face masks, and provided tutorials on how to use editing programs.</p>
      <p>Deep fake production is the <a href="https://www.sciencealert.com/deepfake-ai-algorithms-can-now-take-text-and-turn-it-into-words-spoken-in-a-video">professional version</a> of this practice. At its worst, it can even <a href="https://intelligence.house.gov/news/documentsingle.aspx?DocumentID=657">threaten democracy</a>.</p>
      <p>Twitter’s latest draft policy on deep fakes sets a dangerous precedent. It allows social media platforms to handball away their responsibility to protect customers from manipulated videos and imagery.</p>
      <h3>Twitter should be just as accountable as television</h3>
      <p>It’s time social media giants such as Twitter started seeing themselves as the 21st century version of free-to-air television. With TV, there are clear guidelines about what cannot be broadcast.</p>
      <p>Since 1992, Australians have been protected by the <a href="https://www.legislation.gov.au/Details/C2018C00060"><i>1992 Broadcasting Services Act</i></a>, ensuring what is shows in “fair and accurate coverage”. The act <a href="http://www5.austlii.edu.au/au/legis/cth/consol_act/cca1995115/sch1.html">protects</a> viewers in regards to the origin and authenticity of television content.</p>
      <p>The same principles should apply to social media. Americans now spend <a href="https://www.socialmediatoday.com/news/people-are-now-spending-more-time-on-smartphones-than-they-are-watching-tv/556405/">more time on social media</a> than they do watching television, and Australia isn’t far behind.</p>
      <p>By suggesting they only need to flag tweets with deep fake content, Twitter’s proposed policy downplays the seriousness of the threat.</p>
      <h3>Sending the wrong message</h3>
      <p>Twitter’s draft policy is dangerous on two fronts.</p>
      <p>Firstly, it suggests the company is somehow doing its part in protecting its users. In reality, Twitter’s decision is akin to watching a child struggle to swim in heavy surf, while nearby authorities wave a sign saying: “some waves may be hard to judge” - instead of actually helping.</p>
      <p><a href="https://www.theguardian.com/technology/2019/jun/23/what-do-we-do-about-deepfake-video-ai-facebook">Senior citizens</a> and inexperienced social media users are particularly vulnerable to deep fakes. This is because they’re predisposed to <a href="https://ro.ecu.edu.au/ecuworkspost2013/5709/">trust online content</a> that looks authentic.</p>
      <p>The second reason Twitter’s proposition is dangerous is because social media trolls and <a href="https://ro.ecu.edu.au/ecuworkspost2013/665/">sock puppet armies</a> enjoy surprising online audiences. Sock puppets are specialists in deceiving users into believing they’re a single fake person (or multiple fake perople) by means of false posts and online identities.</p>
      <p>Basically, content that has been signposted as deep fake will be exploited by people wanting to amplify its spread. It’s unrealistic to suppose this won’t happen.</p>
      <p>If Twitter flags posts that are fake, yet leaves them up, the likely outcome will be a popularity surge in this content. As per social media algorithms, this means a greater number of fake videos and images will be “<a href="https://business.twitter.com/en/help/overview/what-are-promoted-tweets.html">promoted</a>” rather than retracted.</p>
      <p>Twitter has an opportunity to take a leadership role in preventing the spread of deep fake content, by identifying and removing deep fakes from its platform. All major social media platforms have the responsibility to present a unified approach to the prevention and removal of manipulated and fake imagery.</p>
      <p>The circulation of a <a href="https://fortune.com/2019/06/12/deepfake-mark-zuckerberg/">Nancy Pelosi deep fake</a> video earlier this year revealed social media’s inconsistency in the handling of deceitful imagery. YouTube removed the clip from its platform, Facebook flagged it as false, and Twitter let it remain.</p>
      <p>Twitter is in the business of helping users repost links and content as many times as possible. It creates profit by generating repeated referrals, commentary, and the acceptance of its content through <a href="https://fourweekmba.com/how-does-twitter-make-money/">promoted trends</a>.</p>
      <p>If deep fakes aren’t removed from Twitter, their growth will be exponential.</p>
      <h3>A looming threat</h3>
      <p><a href="https://www.schneier.com/blog/archives/2018/10/detecting_fake_.html">Early versions</a> of such spurious content were relatively easy to spot. People in the first deep fake clips appeared unrealistic. Their eyes would’t blink and their facial gestures wouldn’t sync with the words being spoken.</p>
      <p>There are also examples of harmless image manipulation. These include web apps on <a href="https://www.pocket-lint.com/apps/news/facebook/139756-facebook-messenger-here-s-how-to-use-those-new-snapchat-like-lenses">Snapchat and Facebook</a> that let users alter their photos (usually selfies) to add backgrounds, or resemble characters such as cute animals.</p>
      <p>However, this new generation of altered imagery is often hard to distinguish from reality. And as criminals and pranksters improve their production of deep fakes, the other side of this double-edged sword could swing at any time.</p>
      <p><a href="https://theconversation.com/profiles/david-cook-123691">David Cook</a>, Lecturer, Computer and Security Science,Edith Cowan University, <i><a href="http://theconversation.com/institutions/edith-cowan-university-720">Edith Cowan University</a></i></p>
      <p>This article is republished from <a href="http://theconversation.com/">The Conversation</a> under a Creative Commons license. Read the <a href="https://theconversation.com/instead-of-showing-leadership-twitter-pays-lip-service-to-the-dangers-of-deep-fakes-127027">original article</a>.</p>
    </article>
  </body>
</html>