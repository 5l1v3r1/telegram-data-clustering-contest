<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <meta property="og:url" content="https://dev.by/news/openai-vypustila-polnuyu-versiyu-modeli-dlya-generacii-strashno-pravdopodobnykh-feikov"/>
    <meta property="og:site_name" content="dev.by"/>
    <meta property="article:published_time" content="2019-11-11T12:10:00+00:00"/>
    <meta property="og:title" content="OpenAI выпустила полную версию модели для генерации «страшно правдоподобных» фейков"/>
    <meta property="og:description" content="OpenAI не нашла свидетельств злоупотребления моделью для генерирования текстов GPT-2, поэтому опубликовала полную её версию — частично она была выпущена ранее в этом году, сообщает Engadget."/>
  </head>
  <body>
    <article>
      <h1>OpenAI выпустила полную версию модели для генерации «страшно правдоподобных» фейков</h1>
      <address><time datetime="2019-11-11T12:10:00+00:00">11 Nov 2019, 12:10</time> by <a rel="author">Александра Кукуть</a></address>
      <p>OpenAI не нашла свидетельств злоупотребления моделью для генерирования текстов GPT-2, поэтому <a href="https://openai.com/blog/gpt-2-1-5b-release/">опубликовала</a> полную её версию — частично она была <a href="https://dev.by/news/openai-vypustila-uluchshennuyu-versiyu-algoritma-dlya-generacii-novostei">выпущена</a> ранее в этом году, <a href="https://www.engadget.com/2019/11/07/openai-published-ai-gpt-fake-news/">сообщает</a> Engadget.</p>
      <p>В феврале OpenAI <a href="https://dev.by/news/openai-sozdala-slishkom-khoroshii-algoritm-generacii-tekstov-i-ne-budet-delitsya-im">анонсировала</a> алгоритм, который умеет синтезировать фейковые новости на основе небольших исходных фрагментов настолько качественно, что их якобы не отличить от написанных человеком. Тогда разработчики <a href="https://dev.by/news/openai-vypustila-uluchshennuyu-versiyu-algoritma-dlya-generacii-novostei">решили выпустить</a> лишь ограниченную версию модели из страха, что её могут использовать в недобрых целях, например для массового распространения спама или дезинформации. Но так как в жизни опасения (пока) не подтвердились, OpenAI опубликовала алгоритм на 1,5 млрд параметров целиком.</p>
      <p>Модель, обученная на 8 млн веб-страниц, предназначена для ответов на вопросы, а также резюмирования и перевода текстов. Она должна помочь исследователям в области искусственного интеллекта создавать более качественные технологии распознавания фейков и синтеза текстов.</p>
      <p>Исходный код доступен <a href="https://github.com/openai/gpt-2-output-dataset">на GitHub</a>, опробовать алгоритм можно <a href="https://talktotransformer.com/">здесь</a>.</p>
      <hr/>
      <hr/>
      <h3>​<a href="https://jobs.dev.by/?utm_source=dev.by.ads&amp;utm_medium=link&amp;utm_campaign=bottom_openai_vypustila_polnuyu_versiyu_modeli_dlya_generacii_strashno_pravdopodobnykh_feikov&amp;utm_content=jobs_dev_by_mainpage">Работа в ИТ</a> в Беларуси​.​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​</h3>
      <p>1. <a href="https://jobs.dev.by/wishes?utm_source=dev.by.ads&amp;utm_medium=link&amp;utm_campaign=bottom_openai_vypustila_polnuyu_versiyu_modeli_dlya_generacii_strashno_pravdopodobnykh_feikov&amp;utm_content=jobs_dev_by_wishes">Заполните</a> анонимную форму — 5 минут.<br/>2. Укажите зарплатные (и другие) ожидания.<br/>3. Выберите желаемую индустрию или область деятельности.<br/>4. Получайте релевантные предложения​​.​​​​​​​​​​​​ ​</p>
      <hr/>
      <footer>Источник: <a href="https://www.engadget.com/2019/11/07/openai-published-ai-gpt-fake-news/">Engadget</a></footer>
    </article>
  </body>
</html>