<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <meta property="og:url" content="https://www.gizmodo.co.uk/2019/11/henry-kissinger-warns-that-ai-will-fundamentally-alter-human-consciousness/?utm_source=feedburner&amp;utm_medium=feed&amp;utm_campaign=Feed%3A+uk%2Fgizmodo+%28Gizmodo+UK%29&amp;hl=en"/>
    <meta property="og:site_name" content="Gizmodo UK"/>
    <meta property="article:published_time" content="2019-11-07T21:00:15+00:00"/>
    <meta property="og:title" content="Henry Kissinger Warns That AI Will Fundamentally Alter Human Consciousness"/>
    <meta property="og:description" content="Speaking in Washington, DC on Tuesday, former US secretary of state Henry Kissinger said he’s convinced of AI’s potential to fundamentally alter human consciousness – including changes in our self-perception and strategic decision-making. He also slammed AI developers for insufficiently thinking through the implications of their creations."/>
  </head>
  <body>
    <article>
      <h1>Henry Kissinger Warns That AI Will Fundamentally Alter Human Consciousness</h1>
      <address><time datetime="2019-11-07T21:00:15+00:00">07 Nov 2019, 21:00</time> by <a rel="author">George Dvorsky</a></address>
      <p>Speaking in Washington, DC on Tuesday, former US secretary of state Henry Kissinger said he’s convinced of AI’s potential to fundamentally alter human consciousness – including changes in our self-perception and strategic decision-making. He also slammed AI developers for insufficiently thinking through the implications of their creations.</p>
      <p>Kissinger, now 96, was speaking at the “<a href="https://www.nscai.gov/conference?utm_medium=email&amp;utm_source=FYI&amp;dm_i=1ZJN,6KJIK,SJB7KV,Q4PRE,1">Strength Through Innovation</a>” conference run by the US National Security Commission on Artificial Intelligence, which was set up by Congress to evaluate the future of AI in the US with regard to national security.</p>
      <p>Kissinger, who served under President Richard Nixon during the Vietnam War, is a <a href="https://www.thecrimson.com/article/2017/1/31/galant-welcoming-war-crimes/">controversial figure</a> who many argue is an unconvicted <a href="https://www.globalresearch.ca/crimes-against-humanity-why-is-henry-kissinger-walking-around-free/5358322">war criminal</a>. That he’s speaking at conferences and not locked in a cold jail cell is understandably offensive to some observers.</p>
      <aside>
        <i>“I’ve become convinced that AI and the surrounding disciplines are going to bring a change in human consciousness, like the Enlightenment.”</i>
      </aside>
      <p>Moderator Nadia Schadlow, who in 2018 served in the Trump administration as the Assistant to the President and as Deputy National Security Advisor for Strategy, asked Kissinger about his take on militarised artificial intelligence and how it might affect global security and strategic decision-making.</p>
      <p>“I don’t look at it as a technical person,” said Kissinger. “I am concerned with the historical, philosophical, strategic aspect of it, and I’ve become convinced that AI and the surrounding disciplines are going to bring a change in human consciousness, like the Enlightenment,” he said, adding: “That’s why I’m here.” His invocation of the 18th-century European Enlightenment was a reference to the paradigmatic intellectual shift that occurred during this important historical period, wherein science, rationalism, and humanism largely replaced religious and faith-based thinking.</p>
      <p>Though Kissinger didn’t elaborate on this point, he may have been referring to a kind of philosophical or <a href="https://www.gizmodo.co.uk/2018/12/how-we-can-prepare-now-for-catastrophically-dangerous-ai-and-why-we-cant-wait/">existential shift in our thinking</a> once AI reaches a sufficiently advanced level of sophistication – a development that will irrevocably alter the way we engage with ourselves and our machines, not necessarily for the better.</p>
      <figure>
        <img src="https://i.kinja-img.com/gawker-media/image/upload/xrrod1axm4tpofqmv5hw.png"/>
      </figure>
      <p>
        <i>Kissinger with moderator Nadia Schadlow. (Image: DVIDS)</i>
      </p>
      <p>Kissinger said he’s not “arguing against AI” and that it’s something that might even “save us,” without elaborating on the details.</p>
      <p>He said he recently spoke to university students about the perils of AI and that he told them, ‘You work on the applications, I work on the implications.’” He said computer scientists aren’t doing enough to figure out what it will mean “if mankind is surrounded by automatic actions” that cannot be explained or fully understood by humans, a conundrum AI researchers refer to as the black box problem.</p>
      <p>Artificial intelligence, he said, “is bound to change the nature of strategy and warfare,” but many stakeholders and decision-makers are still treating it as a “new technical departure.” They haven’t yet understood that AI “must bring a change in the philosophical perception of the world,” and that it will “fundamentally affect human perceptions.”</p>
      <p>A primary concern of Kissinger's was how militarised AI might cause diplomacy to break down. The secret, ephemeral nature of AI means it’s not something state actors can simply “put on the table” as an obvious threat, unlike conventional weapons, said Kissinger. In the strategic field, “we are moving into an area where you can imagine an extraordinary capability” and the “enemy may not know where the threat came from for a while.”</p>
      <p>This confusion could cause undue chaos on a battlefield, or a country could mistake the source of an attack. Even scarier, a <a href="https://www.gizmodo.co.uk/2018/04/ai-could-dramatically-increase-risk-of-nuclear-war-by-2040-says-new-report/">2018 report</a> from the RAND Corporation warned that AI could eventually heighten the risk of nuclear war. This means we’ll also have to “rethink the element of arms control” and “rethink even how the concept of arms control” might apply to this future world, said Kissinger.</p>
      <p>Kissinger said he’s “sort of obsessed” with the work being done by Google’s DeepMind, and the development of <a href="https://www.gizmodo.co.uk/2016/03/lee-sedol-loses-final-go-match-making-it-a-4-1-victory-for-googles-ai/">AlphaGo</a> and <a href="https://www.gizmodo.co.uk/2017/10/stunning-ai-breakthrough-takes-us-one-step-closer-to-the-singularity/">AlphaZero</a> in particular – artificially intelligent systems capable of defeating the world’s best chess and Go players. He was taken aback by how AlphaGo learned “a form of chess that no human being in all of history ever developed,” and how pre-existing chess-playing computers pitted against this AlphaGo were “defenceless.” He said we need to know what this means in the larger scheme of things, and that we should study this concern – that we’re creating things we don’t really understand. “We’re not conscious of this yet as a society,” he said.</p>
      <p>Kissinger is confident that AI algorithms will eventually become a part of military decision-making, but strategic planners will “have to test themselves in war games and even in actual situations to ensure the degree of reliability we can afford to these algorithms, while also having to think through the consequences.”</p>
      <p>Kissinger said the situation may eventually be analogous to the onset of World War I, in which a <a href="https://io9.gizmodo.com/how-each-of-the-great-powers-helped-start-the-first-wor-1597047451">series of logical steps</a> led to many unanticipated and unwanted consequences.</p>
      <aside>
        <i>AI will be the “philosophical challenge of the future.”</i>
      </aside>
      <p>“If you don’t see through the implications of the technologies... including your emotional capacities to handle unpredictable consequences, then you’re going to fail on the strategic side,” said Kissinger. It’s not clear, he said, how state actors will be able to conduct diplomacy when they can’t be sure what the other side is thinking, or if they’ll even be able to reassure the other side “even if you wanted to,” he said. “This topic is very important to think about – as you develop weapons of great capacity...how do you talk about it, and how do you build restraint on their use?”</p>
      <p>To which he added: “Your weapons in a way become your partner, and if they’re designed for a certain task, how can you modify them under certain conditions? These questions need to be answered.” AI will be the “philosophical challenge of the future,” said Kissinger, because we’ll be partnered with generally intelligent objects that have “never been conceived before, and the limitations are so vast.”</p>
      <p>Scary words from a scary guy. The future looks like a very precarious place.</p>
      <p>
        <i>Featured image: DVIDS</i>
      </p>
    </article>
  </body>
</html>