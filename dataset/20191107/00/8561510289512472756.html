<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <meta property="og:url" content="https://futurism.com/the-byte/openai-released-ai-dangerous-share"/>
    <meta property="og:site_name" content="Futurism"/>
    <meta property="article:published_time" content="2019-11-07T00:00:00+00:00"/>
    <meta property="og:title" content="OpenAI Just Released the AI It Said Was Too Dangerous to Share"/>
    <meta property="og:description" content="Artificial intelligence startup OpenAI has released the full version of GPT-2, an algorithm capable of writing coherent paragraphs of text."/>
  </head>
  <body>
    <article>
      <h1>OpenAI Just Released the AI It Said Was Too Dangerous to Share</h1>
      <address><time datetime="2019-11-07T00:00:00+00:00">07 Nov 2019</time> by <a rel="author">Kristin Houser</a></address>
      <h3>Here You Go</h3>
      <p>In February, artificial intelligence research startup <a href="https://openai.com/blog/better-language-models/">OpenAI announced</a> the creation of GPT-2, an algorithm capable of writing impressively coherent paragraphs of text.</p>
      <p>But rather than release the AI in its entirety, the team shared only a <a href="https://futurism.com/amazing-new-ai-churns-out-coherent-paragraphs-of-text">smaller model</a> out of fear that people would use the more robust tool maliciously — to produce fake news articles or spam, for example.</p>
      <p>But on Tuesday, OpenAI published a <a href="https://openai.com/blog/gpt-2-1-5b-release/">blog post</a> announcing its decision to <a href="https://www.theverge.com/2019/11/7/20953040/openai-text-generation-ai-gpt-2-full-model-release-1-5b-parameters">release the algorithm</a> in full as it has “seen no strong evidence of misuse so far.”</p>
      <h3>Still Not Perfect</h3>
      <p>According to OpenAI’s post, the company did see some “discussion” regarding the potential use of GPT-2 for spam and phishing, but it never actually saw evidence of anyone misusing the released versions of the algorithm.</p>
      <p>The problem might be that, while GPT-2 is one of — if not the — best text-generating AIs in existence, it still can’t produce content that’s indistinguishable from text written by a human. And OpenAI warns it’s <i>those</i> algorithms we’ll have to watch out for.</p>
      <p>“We think synthetic text generators have a higher chance of being misused if their outputs become more reliable and coherent,” the startup wrote.</p>
      <p><b>READ MORE:</b> <a href="https://www.theverge.com/2019/11/7/20953040/openai-text-generation-ai-gpt-2-full-model-release-1-5b-parameters">OpenAI has published the text-generating AI it said was too dangerous to share</a> [<i>The Verge</i>]</p>
      <p><b>More on OpenAI:</b> <i><a href="https://futurism.com/openai-dangerous-text-generator">Now You Can Experiment With OpenAI’s “Dangerous” Fake News AI</a></i></p>
    </article>
  </body>
</html>