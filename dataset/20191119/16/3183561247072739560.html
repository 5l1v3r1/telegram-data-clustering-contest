<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <meta property="og:url" content="https://www.gizmodo.com.au/2019/11/dont-just-blame-echo-chambers-conspiracy-theorists-actively-seek-out-their-online-communities/"/>
    <meta property="og:site_name" content="Gizmodo AU"/>
    <meta property="article:published_time" content="2019-11-19T16:15:27+00:00"/>
    <meta property="og:title" content="Don't (Just) Blame Echo Chambers. Conspiracy Theorists Actively Seek Out Their Online Communities"/>
    <meta property="og:description" content="Why do people believe conspiracy theories? Is it because of who they are, what they’ve encountered, or a combination of both? The answer is important. Belief in conspiracy theories helps fuel climate change denial, anti-vaccination stances, racism, and distrust of the media and science...."/>
  </head>
  <body>
    <article>
      <h1>Don't (Just) Blame Echo Chambers. Conspiracy Theorists Actively Seek Out Their Online Communities</h1>
      <address><time datetime="2019-11-19T16:15:27+00:00">19 Nov 2019, 16:15</time> by <a rel="author">Colin Klein and Adam Dunn and Peter Clutton</a></address>
      <figure>
        <img src="https://edge.alluremedia.com.au/m/g/2019/11/conspiracy.jpg"/>
        <figcaption>Image: Getty Images</figcaption>
      </figure>
      <p>Why do people believe conspiracy theories? Is it because of who they are, what they’ve encountered, or a combination of both?</p>
      <p>The answer is important. Belief in conspiracy theories helps <a href="https://theconversation.com/the-science-for-climate-change-only-feeds-the-denial-how-do-you-beat-that-52813">fuel climate change denial</a>, anti-vaccination stances, <a href="https://theconversation.com/conspiracy-theories-fuel-prejudice-towards-minority-groups-113508">racism</a>, and distrust of the media and science.</p>
      <p>In a <a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0225098">paper published today</a>, we shed light on the online world of conspiracy theorists, by studying a large set of user comments.</p>
      <p>Our key findings are that people who eventually engage with conspiracy forums differ from those who don’t in both where and what they post. The patterns of difference suggest they actively seek out sympathetic communities, rather than passively stumbling into problematic beliefs.</p>
      <p>We looked at eight years of comments posted on the popular website <a href="https://reddit.com/">Reddit</a>, a platform hosting millions of individual forums called subreddits.</p>
      <p>Our aim was to find out the main differences between users who post in r/conspiracy (a subreddit dedicated to conspiracy theories) and other Reddit users.</p>
      <p>Using a technique called <a href="https://towardsdatascience.com/sentiment-analysis-concept-analysis-and-applications-6c94d6f58c17">sentiment analysis</a> we examined what users said, and where they said it, during the months before their first post in r/conspiracy.</p>
      <p>We compared these posts to those of other users who started posting on Reddit at the same time, and in the same subreddits, but without going on to post in r/conspiracy.</p>
      <p>We then constructed a network of the subreddits through which r/conspiracy posters travelled. In doing so, we were able to discover how and why they reached their destination.</p>
      <h3>Seeking the like-minded</h3>
      <p>Our research suggests there is evidence for the “self-selection” of conspiracy theorists. This means users appear to be seeking communities of people who share their views.</p>
      <p>Users followed clear pathways to eventually reach r/conspiracy.</p>
      <p>For example, these users were over-represented in subreddits focused on politics, drugs and internet culture, and engaged with such topics more often than their matched pairs.</p>
      <p>We were also surprised by the diversity of pathways taken to get to r/conspiracy. The users were not as concentrated on one side of the political spectrum as people might expect. Nor did we find more anxiety in their posts, compared with other users.</p>
      <p>Our <a href="https://www.frontiersin.org/articles/10.3389/fpsyg.2018.00189/full">previous research</a> also indicated online conspiracy theorists are more <a href="http://theconversation.com/online-conspiracy-theorists-are-more-diverse-and-ordinary-than-most-assume-92022">diverse and ordinary</a> than most people assume.</p>
      <h3>Where do the beliefs come from?</h3>
      <p>To dig deeper, we examined the interactions between where and what r/conspiracy users posted.</p>
      <p>In political subreddits, the language used by them and their matched pairs was quite similar. However, in Reddit’s very popular general-purpose subreddits, the linguistic differences between the two groups were striking.</p>
      <p>So far, psychologists, sociologists, and philosophers have struggled to find anything distinct about conspiracy believers or their environments.</p>
      <p>Social media can play a role in spreading conspiracy theories, but it mostly entrenches beliefs among those who already have them. Thus it can be challenging to measure and understand how conspiracy beliefs arise.</p>
      <p>Traditional survey and interview approaches don’t always give reliable responses. This is because conspiracy theorists often frame their life in narratives of <a href="https://www.frontiersin.org/articles/10.3389/fpsyg.2017.00861/full">conversation and awakening</a>, which can obscure the more complex origins of their beliefs.</p>
      <p>Furthermore, as philosopher David Coady <a href="https://theconversation.com/in-defence-of-conspiracy-theories-and-why-the-term-is-a-misnomer-101678">pointed out</a>, some conspiracy theories turn out to be true. Insiders do sometimes uncover evidence of malfeasance and cover-ups, as <a href="https://theconversation.com/from-richard-boyle-and-witness-k-to-media-raids-its-time-whistleblowers-had-better-protection-121555">recent debates over the need for whistleblower protections in Australia</a> reflect.</p>
      <h3>Echo chambers worsen the problem</h3>
      <p>Research about online radicalisation from philosophy has focused on the passive effects of technologies such as <a href="https://www.cambridge.org/core/journals/journal-of-the-american-philosophical-association/article/technological-seduction-and-selfradicalization/47CADB240E6141F9C6160C40BC9A6ECF">recommended algorithms</a> and their role in creating <a href="https://aeon.co/essays/why-its-as-hard-to-escape-an-echo-chamber-as-it-is-to-flee-a-cult">online echo chambers</a>.</p>
      <p>Our research instead suggests individuals seem to have a more active role in finding like-minded communities, before their interactions in such communities reinforce their beliefs.</p>
      <p>These “person-situation interactions” are clearly important and under-theorised.</p>
      <p>As the psychologist David C. Funder <a href="https://www.guilford.com/books/Handbook-of-Personality/John-Robins-Pervin/9781609180591/contents">puts it</a>:</p>
      <blockquote>Individuals do not just passively find themselves in the situations of their lives; they often actively seek and choose them. Thus, while a certain kind of bar may tend to generate a situation that creates fights around closing time, only a certain kind of person will choose to go to that kind of bar in the first place.</blockquote>
      <p>We suspect a similar process leads users to conspiracy forums.</p>
      <h3>A complex web of interactions</h3>
      <p>Our data indicates that conspiracy beliefs, like most beliefs, are not adopted in a vacuum. They are actively mulled over, discussed, and sought out by agents in a social (and increasingly online) world.</p>
      <p>And when forums like <a href="https://theconversation.com/8chans-demise-is-a-win-against-hate-but-could-drive-extremists-to-the-dark-web-121521">8chan and Stormfront are pushed offline</a>, users often look for other ways to communicate.</p>
      <p>These complex interactions are growing in number, and technology can amplify their effects.</p>
      <p>YouTube radicalisation, for example, is likely driven by interactions between algorithms and <a href="https://theconversation.com/dont-just-blame-youtubes-algorithms-for-radicalisation-humans-also-play-a-part-125494">self-selected communities</a>.</p>
      <p>When it comes to conspiracy beliefs, more work needs to be done to understand the interplay between a person’s social environment and their information seeking behaviour.</p>
      <p>And this becomes even more pressing as we learn more about the risks that come with conspiracy theorising.</p>
      <hr/>
      <p><a href="https://theconversation.com/profiles/colin-klein-253131">Colin Klein</a>, Associate Professor of Philosophy, <i><a href="http://theconversation.com/institutions/australian-national-university-877">Australian National University</a></i>; <a href="https://theconversation.com/profiles/adam-dunn-2853">Adam Dunn</a>, Associate professor, <i><a href="http://theconversation.com/institutions/macquarie-university-1174">Macquarie University</a></i>, and <a href="https://theconversation.com/profiles/peter-clutton-446664">Peter Clutton</a>, Graduate Student in Philosophy, <i><a href="http://theconversation.com/institutions/australian-national-university-877">Australian National University</a></i></p>
      <p>This article is republished from <a href="http://theconversation.com/">The Conversation</a> under a Creative Commons license. Read the <a href="https://theconversation.com/dont-just-blame-echo-chambers-conspiracy-theorists-actively-seek-out-their-online-communities-127119">original article</a>.</p>
    </article>
  </body>
</html>