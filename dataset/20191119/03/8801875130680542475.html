<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <meta property="og:url" content="https://technews.tw/2019/11/19/nvidia-magnum-io/"/>
    <meta property="og:site_name" content="TechNews 科技新報"/>
    <meta property="article:published_time" content="2019-11-19T03:20:00+00:00"/>
    <meta property="og:title" content="NVIDIA 推出 Magnum IO 套裝軟體，協助資料科學家及 AI 和高效能運算研究人員消除資料瓶頸"/>
    <meta property="og:description" content="NVIDIA（輝達）19 日宣布推出 NVIDIA Magnum IO 軟體，可以協助資料科學家、 AI 與高效能運算研究人員在幾分鐘而非幾小時內處理大量資料。 經過優化後的 Magnum IO 能夠排除儲存及輸入 / 輸出的瓶頸，在執行如財務分析、建立氣候模型與其他高效能運算作業時，可針對多..."/>
  </head>
  <body>
    <article>
      <h1>NVIDIA 推出 Magnum IO 套裝軟體，協助資料科學家及 AI 和高效能運算研究人員消除資料瓶頸</h1>
      <address><time datetime="2019-11-19T03:20:00+00:00">19 Nov 2019, 03:20</time> by <a rel="author" href="https://technews.tw/author/technewsadmin/" target="_blank">TechNews</a></address>
      <p>NVIDIA（輝達）19 日宣布推出 <a href="https://www.nvidia.com/en-us/data-center/magnum-io/">NVIDIA Magnum IO 軟體</a>，可以協助資料科學家、 AI 與高效能運算研究人員在幾分鐘而非幾小時內處理大量資料。</p>
      <p>經過優化後的 Magnum IO 能夠排除儲存及輸入 / 輸出的瓶頸，在執行如財務分析、建立氣候模型與其他高效能運算作業時，可針對多伺服器與多 GPU 節點提供高達 20 倍的資料處理效能。</p>
      <p>NVIDIA 與網路及儲存領域的頂尖業者密切合作，包括 DataDirect Networks、Excelero、IBM、Mellanox 和 WekaIO，並肩開發出 Magnum IO。</p>
      <p>NVIDIA 創辦人暨執行長黃仁勳表示：「處理大量收集或模擬的資料，是 AI 這般由資料帶動之科學研究領域的核心。隨著資料的規模和出現速度呈現指數級增長，資料中心所面臨的巨大挑戰和成本考量就是資料處理。極致的運算需要有極致的輸入 / 輸出功能，而 Magnum IO 將巔覆運算領域的 NVIDIA GPU 加速技術用在輸入 / 輸出功能和儲存裝置上，做到了這一點。如今 AI 研究人員與資料科學家不用再等待資料，反而能專心在他們的研究工作上。」</p>
      <p>Magnum IO 的核心是 GPUDirect，資料可以藉此繞過 CPU，在 GPU、儲存裝置和網路設備提供的「開放高速公路」上進行傳輸。由點對點及遠端直接記憶體存取（RDMA）組成的 GPUDirect，與眾多傳輸互連及 API 皆相容，其中包括 NVIDIA NVLink、NCCL、OpenMPI 及 UCX。</p>
      <p>其最新元素是 GPUDirect Storage，讓研究人員在存取儲存裝置之際可以繞過 CPU，並且快速取得資料檔案來進行模擬、分析或視覺化等作業。</p>
      <p>NVIDIA Magnum IO 軟體現已上市，而特定早鳥計畫的客戶現已可取得尚未上市的 GPUDirect Storage。NVIDIA 計劃在 2020 年上半年讓更多客戶接觸到 GPUDirect Storage。</p>
    </article>
  </body>
</html>