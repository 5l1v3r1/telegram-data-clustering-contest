<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <meta property="og:url" content="https://science.slashdot.org/story/19/11/19/0238212/mit-teaches-autonomous-cars-how-to-deal-with-selfish-drivers"/>
    <meta property="og:site_name" content="science.slashdot.org"/>
    <meta property="article:published_time" content="2019-11-19T05:00:00+00:00"/>
    <meta property="og:title" content="MIT Teaches Autonomous Cars How To Deal With Selfish Drivers"/>
    <meta property="og:description" content="Researchers at MIT's Computer Science and Artificial Intelligence Laboratory (CSAIL) have devised a system that can predict what different cars will do by determining how selfish or selfless a driver is. From a report: Specifically, they used something called social value orientation (SVO), which r..."/>
  </head>
  <body>
    <article>
      <h1>MIT Teaches Autonomous Cars How To Deal With Selfish Drivers</h1>
      <address><time datetime="2019-11-19T05:00:00+00:00">19 Nov 2019, 05:00</time> by <a rel="author">BeauHD</a></address>
      <p>Researchers at MIT's Computer Science and Artificial Intelligence Laboratory (CSAIL) have devised a system that <a href="http://news.mit.edu/2019/predicting-driving-personalities-1118">can predict what different cars will do</a> by determining how selfish or selfless a driver is. From a report: <i>Specifically, they used something called social value orientation (SVO), which represents the degree to which someone is selfish ("egoistic") versus altruistic or cooperative ("prosocial"). The system then estimates drivers' SVOs to create real-time driving trajectories for self-driving cars. Testing their algorithm on the tasks of merging lanes and making unprotected left turns, the team showed that they could better predict the behavior of other cars by a factor of 25 percent. For example, in the left-turn simulations their car knew to wait when the approaching car had a more egoistic driver, and to then make the turn when the other car was more prosocial. <br/><br/>To try to expand the car's social awareness, the CSAIL team combined methods from social psychology with game theory, a theoretical framework for conceiving social situations among competing players. The team modeled road scenarios where each driver tried to maximize their own utility and analyzed their "best responses" given the decisions of all other agents. Based on that small snippet of motion from other cars, the team's algorithm could then predict the surrounding cars' behavior as cooperative, altruistic, or egoistic -- grouping the first two as "prosocial." People's scores for these qualities rest on a continuum with respect to how much a person demonstrates care for themselves versus care for others. </i>Here are some potential use cases of such a system: "Say you're a human driving along and a car suddenly enters your blind spot -- the system could give you a warning in the rear-view mirror that the car has an aggressive driver, allowing you to adjust accordingly. It could also allow self-driving cars to actually learn to exhibit more human-like behavior that will be easier for human drivers to understand." <br/><br/>The team is planning to apply their system to pedestrians, bicycles, and other agents in driving environments. "In addition, they will be investigating other robotic systems acting among humans, such as household robots, and integrating SVO into their prediction and decision-making algorithms," the report says.</p>
    </article>
  </body>
</html>