<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <meta property="og:url" content="https://zn.ua/TECHNOLOGIES/novyy-iskusstvennyy-intellekt-google-ulichili-v-diskriminacii-336600_.html"/>
    <meta property="og:site_name" content="ZN.ua"/>
    <meta property="article:published_time" content="2019-11-19T15:16:00+00:00"/>
    <meta property="og:title" content="Новый искусственный интеллект Google уличили в дискриминации"/>
    <meta property="og:description" content="ИИ подхватил предубеждения из текстов, которые были написаны людьми."/>
  </head>
  <body>
    <article>
      <h1>Новый искусственный интеллект Google уличили в дискриминации</h1>
      <h2>ИИ подхватил предубеждения из текстов, которые были написаны людьми.</h2>
      <address>
        <time datetime="2019-11-19T15:16:00+00:00">19 Nov 2019, 15:16</time>
      </address>
      <p>Компания Google создала новый <a href="https://zn.ua/TECHNOLOGIES/iskusstvennyy-intellekt-sam-dogadalsya-chto-zemlya-vraschaetsya-vokrug-solnca-335466_.html"><b>искусственный интеллект</b></a> BERT, который научили правильно понимать контекст слова в предложении, что помогает ему лучше отвечать на поисковые запросы. Для его обучения использовали статьи из "Википедии" и СМИ. Но ИИ оказался недостаточно прогрессивным в расовых и гендерных вопросах. По мнению экспертов, он подхватил это из текстов, написанных людьми, сообщает <a href="https://thebabel.net/texts/38081-novyy-iskusstvennyy-intellekt-ot-google-diskriminiruet-zhenshchin-afrikancev-i-trampa-etomu-on-nauchilsya-u-lyudey-pereskazyvaem-material-nyt">"theБабель"</a>.</p>
      <p>В основу функционирования BERT заложен принцип "универсальных языковых моделей", то есть, он изучает нюансы того, как люди говорят и пишут. Сначала он научился определять пропущенные слова в предложении, а затем перешел к более сложным задачам. В частности, он научился точно определять контекст слова и правильно реагировать на запросы.</p>
      <p>Но группа экспертов из Университета Карнеги-Меллона обнаружила, что BERT чаще ассоциирует слово "программист" с мужчинами, чем с женщинами. Ученый в области компьютерной лингвистики Роберт Мунро ввел в BERT 100 английских слов, таких как "драгоценности", "ребенок", "лошади", "дом", "деньги", "действие". В 99 случаях искусственный интеллект связал эти слова с мужчинами. Исключением стало слово "мама", которое BERT ассоциировал с женщинами.</p>
      <p>Мунро продолжил изучать языковые сервисы Google и Amazon и обнаружил, что обе нейросети не могли определить слово "ее" как местоимение, хотя "его" - могли. По его мнению, это является следствием исторической несправедливости, заложенной в текстах, которые используют для обучения.</p>
      <p>Директор по науке стартапа Primer, который специализируется на технологиях естественного языка, Джон Боханнон использовал BERT, чтобы создать систему, позволяющую автоматически оценивать "настроение" заголовков, твитов и других потоков онлайн-медиа. Оказалось, что если в твите или заголовке встречались имя и фамилия президента США Дональда Трампа, то ИИ почти всегда помечал их как "негативные", даже если текст был нейтральным.</p>
      <p>BERT и другие системы настолько сложны, что даже разработчики не всегда могут понять, как они работают.  Вместе с тем, в Google и Amazon утверждают, что знают о проблеме и работают над повышением точности и устранением предвзятости в работе систем.</p>
      <p>По мнению генерального директора Primer Шона Гарли, проверка поведения этой технологии станет настолько важной, что породит целую новую отрасль. Компании будут платить специалистам за то, чтобы они проверяли алгоритмы на адекватность и толерантность. "Это может быть миллиардная индустрия", - отметил он.</p>
      <p>Подписывайтесь на наш <a href="https://t.me/ZNlife">Telegram-канал</a> с новостями технологий и культуры.</p>
      <p>Ранее <a href="https://zn.ua/TECHNOLOGIES/iskusstvennyy-intellekt-mozhet-predskazat-smert-pacienta-no-uchenye-ne-znayut-kak-on-eto-delaet-335646_.html"><b>искусственный интеллект научился предсказывать смерть пациента в ближайший год по данным ЭКГ даже в тех случаях, когда они кажутся нормальными врачам</b></a>. Но ученые не знают, как он это делает.</p>
      <footer>По материалам: <a href="https://zn.ua/go/aHR0cHM6Ly90aGViYWJlbC5jb20udWE=">the Бабель</a></footer>
      <footer>Оставайтесь в курсе последних событий! Подписывайтесь на наш канал в <a href="https://t.me/znua_live">Telegram</a></footer>
    </article>
  </body>
</html>