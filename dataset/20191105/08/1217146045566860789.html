<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <meta property="og:url" content="https://www.bleepingcomputer.com/news/security/using-light-beams-to-control-google-apple-amazon-assistants/"/>
    <meta property="og:site_name" content="BleepingComputer"/>
    <meta property="article:published_time" content="2019-11-05T08:34:32+00:00"/>
    <meta property="og:title" content="Using Light Beams to Control Google, Apple, Amazon Assistants"/>
    <meta property="og:description" content="Academic researchers found that certain microphones convert light to sound, allowing voice commands to be sent to voice-controlled (VC) devices like Google Home, Amazon Echo, Facebook Portal, smartphones, or tablets."/>
  </head>
  <body>
    <article>
      <h1>Using Light Beams to Control Google, Apple, Amazon Assistants</h1>
      <address><time datetime="2019-11-05T08:34:32+00:00">05 Nov 2019, 08:34</time> by <a rel="author" href="https://www.bleepingcomputer.com/author/ionut-ilascu/" target="_blank">Ionut Ilascu</a></address>
      <figure>
        <img src="https://www.bleepstatic.com/content/posts/2019/11/04/LightCommands2.jpg"/>
      </figure>
      <p>Academic researchers found that certain microphones convert light to sound, allowing voice commands to be sent to voice-controlled (VC) devices like Google Home, Amazon Echo, Facebook Portal, smartphones, or tablets.</p>
      <p>Dubbed Light Commands, the attack works from afar by shining a laser beam at microphones that use micro-electro-mechanical systems (MEMS), which convert the light into an electrical signal.</p>
      <p>By modulating the intensity of the light beam, MEMS can be tricked to produce the same electrical signals produced by audio commands. With careful aiming and laser focusing, attacks can be successful from as far as 110 meters.</p>
      <h3>Long-range attack</h3>
      <p>In their experiments, researchers from the University of Electro-Communications in Japan and the University of Michigan tested the attack on popular VC devices.</p>
      <p>The voice recognition system in Google Home, Nest Cam, Amazon Echo, Fire Cube TV, iPhone, Samsung Galaxy S9, Google Pixel, and iPad, was tested from various distances.</p>
      <p><b>Device</b> <b>Voice Recognition<br/>System</b> <b>Minimun Laser Power<br/>at 30 cm [mW]</b> <b>Max Distance<br/>at 60 mW [m]*</b> <b>Max Distance<br/>at 5 mW [m]**</b> Google Home Google Assistant 0.5 50+ 110+ Google Home mini Google Assistant 16 20 - Google NEST Cam IQ Google Assistant 9 50+ - Echo Plus 1st Generation Amazon Alexa 2.4 50+ 110+ Echo Plus 2nd Generation Amazon Alexa 2.9 50+ 50 Echo Amazon Alexa 25 50+ - Echo Dot 2nd Generation Amazon Alexa 7 50+ - Echo Dot 3rd Generation Amazon Alexa 9 50+ - Echo Show 5 Amazon Alexa 17 50+ - Echo Spot Amazon Alexa 29 50+ - Facebook Portal Mini Alexa + Portal 18 5 - Fire Cube TV Amazon Alexa 13 20 - EchoBee 4 Amazon Alexa 1.7 50+ 70 iPhone XR Siri 21 10 - iPad 6th Gen Siri 27 20 - Samsung Galaxy S9 Google Assistant 60 5 - Google Pixel 2 Google Assistant 46 5 -</p>
      <p>A Light Commands attack sends inaudible instructions to a voice-controlled device, making it react in a meaningful way. The researchers demonstrated that it can be used to open a garage door or to unlock the front door of a house.</p>
      <figure>
        <iframe src="https://www.youtube.com/embed/ihRAwc24nXw" width="640" height="360" data-service="Youtube" scrolling="no"/>
      </figure>
      <p>No large investment is needed to pull this off, either. A low-cost setup used by the researchers consisted of a normal laser pointer, a Wavelength Electronics laser driver ($339), and a Neoteck NTK059 sound amplifier ($27.99). A computer that plays the recorded audio commands is also required.</p>
      <p>Laser beams provide precise aiming, but the researchers showed that Light Commands attacks also work with a laser flashlight (Acebeam W30). From 10 meters, they were able to inject commands into Google Home.</p>
      <figure>
        <img src="https://www.bleepstatic.com/images/news/u/1100723/LightCommand-Flashlight.png"/>
      </figure>
      <p>As seen in the image above, the light covers the target device completely. This imprecise aiming, though, has its downsides: limited distance and potentially hitting microphones from other devices.</p>
      <p>For long-range attacks, additional gear is required to focus the beam on the right spot: a telescope, a telephoto lens, and a tripod for focus and accurate aiming.</p>
      <p>Windows are not an obstacle as long as there is a direct line of sight between the source of the light and the target device.</p>
      <figure>
        <iframe src="https://www.youtube.com/embed/EtzP-mCwNAs" width="640" height="360" data-service="Youtube" scrolling="no"/>
      </figure>
      <p>Despite the double-pane glass window and windy conditions, the experiment was successful. Reflections were negligible, the researchers write in a paper describing the details for Light Commands injection attacks.</p>
      <p>To run the experiments, four commands were recorded for asking the time, setting the volume to zero, placing an order for a laser pointer, and opening a garage door. To these the predefined device wake up phrase ("OK Google," "Hey Siri," "Alexa," "Hey Portal") was appended.</p>
      <h3>Real-life limitations</h3>
      <p>Although a novel type of attack, it is hard to imagine a successful Light Commands attack outside the preset conditions of an experiment. Clearly, there is no reason for concern at the moment.</p>
      <p>A threat actor has to consider limitations such as line of sight to the device as well as the barriers in the way as light has trouble going through an opaque environment, such as fog or tainted windows.</p>
      <p>Furthermore, the victim may be alerted by the visibility of the light beam, unless infrared is used - but additional gear is necessary in this case, and the audio response fom the target device confirm execution of the command.</p>
      <p>The target device may also represent a problem. A smart speaker at the window is an easier target than a smartphone or a tablet, which are designed for mobility and their owner could place them in a position that does not allow a direct line to their microphone.</p>
      <p>The Light Commands research is the result of Takeshi Sugawara (University of Electro-Communications in Japan), Benjamin Cyr, Sara Rampazzi, Daniel Genkin, and Kevin Fu (University of Michigan). Details are provided in their paper called "Light Commands: Laser-Based Audio Injection Attacks on Voice-Controllable Systems" (<a href="https://lightcommands.com/20191104-Light-Commands.pdf">PDF</a>). A <a href="https://lightcommands.com/">website</a> has also been set up for an overview of this type of attacks.</p>
    </article>
  </body>
</html>