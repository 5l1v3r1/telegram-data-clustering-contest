<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <meta property="og:url" content="https://bdnews24.com/technology/2019/11/05/with-a-laser-researchers-say-they-can-hack-alexa-google-home-or-siri"/>
    <meta property="og:site_name" content="Bdnews24"/>
    <meta property="article:published_time" content="2019-11-05T21:15:00+00:00"/>
    <meta property="og:title" content="With a laser, researchers say they can hack Alexa, Google Home or Siri"/>
    <meta property="og:description" content="Since voice-controlled digital assistants were introduced a few years ago, security experts have fretted that systems like Apple’s Siri and Amazon’s Alexa were a privacy threat and could be easily hacked."/>
  </head>
  <body>
    <article>
      <h1>With a laser, researchers say they can hack Alexa, Google Home or Siri</h1>
      <address>
        <time datetime="2019-11-05T21:15:00+00:00">05 Nov 2019, 21:15</time>
      </address>
      <p>
        <b>Since voice-controlled digital assistants were introduced a few years ago, security experts have fretted that systems like Apple’s Siri and Amazon’s Alexa were a privacy threat and could be easily hacked.</b>
      </p>
      <p>But the risk presented by a cleverly pointed light was probably not on anyone’s radar.</p>
      <p>Researchers in Japan and at the University of Michigan said Monday they had found a way to take over Google Home, Amazon’s Alexa or Apple’s Siri devices from hundreds of feet away by shining laser pointers, and even flashlights, at the devices’ microphones.</p>
      <p>In one case, they said they opened a garage door by shining a laser beam at a voice assistant that was connected to it. They also climbed 140 feet to the top of a bell tower at the University of Michigan and successfully controlled a Google Home device on the fourth floor of an office building 230 feet away. And by focusing their lasers using a telephoto lens, they said, they were able to hijack a voice assistant more than 350 feet away.</p>
      <p>Opening the garage door was easy, the researchers said. With the light commands, the researchers could have hijacked any digital smart systems attached to the voice-controlled assistants.</p>
      <p>They said they could have easily switched light switches on and off, made online purchases or opened a front door protected by a smart lock. They even could have remotely unlocked or started a car that was connected to the device.</p>
      <p>“This opens up an entirely new class of vulnerabilities,” said Kevin Fu, an associate professor of electrical engineering and computer science at the University of Michigan. “It’s difficult to know how many products are affected because this is so basic.”</p>
      <p>The computer science and electrical engineering researchers — Takeshi Sugawara at the University of Electro-Communications in Japan; and Fu, Daniel Genkin, Sara Rampazzi and Benjamin Cyr at the University of Michigan — released their findings in a paper Monday.</p>
      <p>The researchers said they notified Tesla, Ford, Amazon, Apple and Google to the light vulnerability. The companies all said they were studying the conclusions in the paper.</p>
      <p>© 2019 The New York Times Company</p>
    </article>
  </body>
</html>