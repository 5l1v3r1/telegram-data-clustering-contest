<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <meta property="og:url" content="https://www.golem.de/news/alexa-und-siri-sprachbefehle-unhoerbar-per-laser-uebertragen-1911-144805.html"/>
    <meta property="og:site_name" content="Golem.de"/>
    <meta property="article:published_time" content="2019-11-05T11:57:01+00:00"/>
    <meta property="og:title" content="Sprachbefehle unhörbar per Laser übertragen"/>
    <meta property="og:description" content="Sprachbefehle müssen nicht unbedingt per Sprache übertragen werden: Forschern ist es gelungen, smarte Lautsprecher wie Amazon Echo oder Google Home mit einem Laser aus bis zu"/>
  </head>
  <body>
    <article>
      <h1>Sprachbefehle unhörbar per Laser übertragen</h1>
      <h2>Sprachbefehle müssen nicht unbedingt per Sprache übertragen werden: Forschern ist es gelungen, smarte Lautsprecher wie <a href="https://www.golem.de/specials/amazon-echo/">Amazon Echo</a> oder <a href="https://www.golem.de/specials/google-home/">Google Home</a> mit einem Laser aus bis zu 110 Metern Entfernung zu steuern - und so beispielsweise ein Garagentor zu öffnen.</h2>
      <address><time datetime="2019-11-05T11:57:01+00:00">05 Nov 2019, 11:57</time> by <a rel="author">Moritz Tremmel</a></address>
      <p>Auch mit einem Laser lässt sich die Membran eines Mikrofons zum Schwingen bringen, mit den Schwingungen können Töne bis hin zu Sprachbefehlen erzeugt werden. Mit diesen für Menschen nicht hörbaren Sprachbefehlen können Sprachassistenten wie Amazons Alexa oder Apples Siri getriggert werden - und so beispielsweise ein Garagentor geöffnet werden. Selbst über Distanz und durch Fenster gelang es dem Sicherheitsforscher Takeshi Sugawara und einem Team der Universität in Michigan, die Befehle zu übertragen. Zuerst hatte das Magazin <a href="https://www.wired.com/story/lasers-hack-amazon-echo-google-home/">Wired berichtet</a>.</p>
      <p>Anfangs führte Sugawara seine Versuche in einer abgeschirmten schwarzen Box durch, die ihn vor der Strahlung eines Lasers schützen sollte. Diesen hatte er in der Box platziert und auf das Mikrofon eines iPads gerichtet. Je nach Strahlungsintensität des Lasers begann die Membran des Mikrofons zu vibrieren und einen Fiepton aufzunehmen. Sugawara konnte das Licht des Lasers in ein elektrisches Signal umwandeln, wie bei einem Ton. Sugawara forschte gemeinsam mit einem Team der Universität Michigan rund um Professor Kevin Fu.</p>
      <p>Im Laufe eines halben Jahres wurde aus dem Fiepton Sprache. <i>"Mikrofone reagieren auf Licht wie auf Töne"</i>, erklärt Sugawara Wired. <i>"So lassen sich alle Geräte, die auf Klang reagieren, auch mit Licht bedienen."</i> Damit konnten die Sicherheitsforscher lautlos Sprachbefehle an smarte Lautsprecher wie Amazon Echo, Google Home, Apple Homepod, aber auch an Smartphones und Tablets übertragen. Je nach angeschlossenen Geräten und unterstützten Befehlen können Angreifer den Haushalt des Besitzers steuern, das Garagentor öffnen oder online einkaufen. Auch Türschlösser könnten geöffnet oder Thermostate bedient werden. Den Forschern gelang dies aus einer Distanz von einigen Dutzend Metern sowie durch das geschlossene Fenster, während der Besitzer des smarten Lautsprechers nicht zu Hause war.</p>
      <h4>Bis zu 110 Meter überwunden</h4>
      <p>Mit einem 5-Milliwatt-Laser, was ungefähr einem billigen Laserpointer entspricht, schafften die Forscher eine Übertragung über 110 Meter. Rund 75 Meter schafften die Forscher durch ein Fenster in ein naheliegendes Gebäude. Insgesamt testeten die Sicherheitsforscher 16 Geräte. Bei den getesteten Smartphones schafften sie nur deutlich geringere Distanzen. Bei einem iPhone waren es rund 10 Meter, bei einem Testgerät mit Android schafften sie nicht einmal fünf Meter. Komplizierter mache es den Angriff auch, wenn das Aktivierungswort mit der Stimme des Besitzers gesprochen werden müsse, erklärten die Forscher.</p>
      <p>Zwar könnten anwesende Personen die Aktivierung des smarten Lautsprechers sowie das Licht des Lasers auf diesem wahrnehmen, eine Sprachausgabe lasse sich allerdings verhindern, indem zu Beginn des Angriffs die Sprachausgabe des smarten Lautsprechers per Sprachbefehl deaktiviert wird. Zudem könne der Flüstermodus von Alexa verwendet werden, erklärten die Forscher. Dies hätten sie allerdings noch nicht getestet.</p>
      <p>Der Laser muss bei dem Angriff auf das Mikrofon des smarten Lautsprechers gerichtet sein. Die Forscher waren sowohl mit einem gezielten Laserstrahl auf das Mikrofon als auch mit großflächiger Strahlung auf das ganze Gerät erfolgreich. Sind Personen anwesend, können diese das Licht des Lasers auf dem smarten Lautsprecher jedoch sehen. Das lasse sich jedoch über einen Infrarotlaser verhindern, dessen Licht von Menschen nicht wahrgenommen werden könne, erklärten die Forscher.</p>
      <p>Google und Amazon erklärten gegenüber Wired, dass sie die Forschungsergebnisse genau prüfen werden. Apple lehnte einen Kommentar ab. Die Forscher schlagen vor, die Geräte durch Anpassungen am Design zu schützen, beispielsweise durch eine Lichtschranke um das Mikrofon herum oder das Aufnehmen von Sprachbefehlen durch zwei gegenüberliegende Mikrofone. Zudem könne eine PIN zum Einsatz kommen, die der Besitzer beispielsweise bei Käufen einsprechen müsse. Ein erster Schritt ist es, die smarten Lautsprecher nicht im Sichtfeld eines Fensters zu platzieren, dann können sie auch nicht von außen mit einem Laser bestrahlt werden.</p>
    </article>
  </body>
</html>