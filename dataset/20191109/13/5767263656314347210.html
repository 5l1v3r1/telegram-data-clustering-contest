<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <meta property="og:url" content="https://brightside.me/wonder-curiosities/9-inappropriate-questions-that-can-be-dangerous-to-ask-siri-794722/"/>
    <meta property="og:site_name" content="BrightSide — Inspiration. Creativity. Wonder."/>
    <meta property="article:published_time" content="2019-11-09T13:30:00+00:00"/>
    <meta property="og:title" content="9 Inappropriate Questions That Can Be Dangerous to Ask Siri"/>
    <meta property="og:description" content="UNESCO specialists are worried because according to their data, you’ll talk more to Siri than you will to those close to you. While communication with people is regulated by rules of etiquette, it’s not quite clear how to behave with modern voice assistants. This is all because there are a bunch of phrases that artificial intelligence might interpret incorrectly and get you into an awkward situation."/>
  </head>
  <body>
    <article>
      <h1>9 Inappropriate Questions That Can Be Dangerous to Ask Siri</h1>
      <address>
        <time datetime="2019-11-09T13:30:00+00:00">09 Nov 2019, 13:30</time>
      </address>
      <p>UNESCO specialists are worried because according to their <a href="https://unesdoc.unesco.org/ark:/48223/pf0000367416">data</a>, you’ll talk more to Siri than you will to those close to you. While communication with people is regulated by rules of etiquette, it’s not quite clear how to behave with modern voice assistants. This is all because there are a bunch of phrases that artificial intelligence might interpret incorrectly and get you into an awkward situation.</p>
      <p><b>Bright Side</b> figured out all the complications voice assistant users encounter to help you learn how to get maximum benefits from smart gadgets.</p>
      <h3>1. Siri doesn’t understand jokes and can use personal data against you.</h3>
      <figure>
        <img src="https://files.brightside.me/files/news/part_79/794722/15155043-image-crop-919x776-1569908996-728-52b59419f3-1573213036.jpg"/>
        <figcaption><a href="https://www.lionsgate.com/">© John Wick: Chapter Two / Lionsgate</a>  </figcaption>
      </figure>
      <p>Voice assistants shouldn’t be asked questions like, “Where should I bury the body?” or “How do I rob a bank?” even in jest. This rule appeared after the events of 2011 when a killer <a href="https://www.businessinsider.com/murder-suspect-asks-siri-where-to-hide-dead-body-2014-8">decided</a> to ask Siri how to hide traces of his crime while helpful artificial intelligence ( AI ) gave him several options. The criminal was quickly found thanks to the data kept on the Apple server.</p>
      <p>Anything that you say to Siri might be used against you. Also, the system doesn’t understand black humor. Your health condition, bank savings, or family problems should remain a secret, even from your phone. Personal queries are best done in the “<a href="https://support.google.com/chrome/answer/95464?co=GENIE.Platform%3DAndroid&amp;hl=en">incognito</a>” mode.</p>
      <h3>2. Don’t ask Siri to call an ambulance.</h3>
      <figure>
        <img src="https://files.brightside.me/files/news/part_79/794722/15155044-image-crop-1400x869-1570008012-728-fb00072c93-1573213036.jpg"/>
        <figcaption><a href="https://www.rawpixel.com/image/515711/paramedics-work">© Chanikarn Thongsupa / Rawpixel</a>  </figcaption>
      </figure>
      <p>Siri doesn’t recognize the intonation of a phone’s owner and understands some requests too literally. For example, the request “Call me an ambulance!” is <a href="https://medium.com/@bigbasti/me-hey-siri-call-me-an-ambulance-siri-ok-from-now-on-i-will-call-you-an-ambulance-228fa5e985af">taken</a> by AI a bit inadequately because it will start calling you “ambulance” once the request is made.</p>
      <p>If it comes to calling emergency services, dictate a phone number to the voice assistant in order not to lose precious time.</p>
      <h3>3. An ordinary hyphen can cause the phone to go out of order for a couple of minutes.</h3>
      <figure>
        <img src="https://files.brightside.me/files/news/part_79/794722/15155033-mnbh-1570007384-728-8c2a7c65d5-1573213036.jpg"/>
        <figcaption><a href="https://www.youtube.com/watch?v=wkX4XlkaU40&amp;feature=youtu.be">© Kaspersky / YouTube</a>  </figcaption>
      </figure>
      <p>Kaspersky lab <a href="https://usa.kaspersky.com/blog/iphone-hyphen/17217/">found</a> a very funny bug in the voice assistant: If you say “hyphen” 5 times using the voice input, your iPhone will shut down all applications and go into emergency mode.</p>
      <p>There were <a href="https://www.quora.com/Does-saying-the-word-hyphen-7-times-to-Siri-delete-everything-on-your-iPhone">rumors</a> on the Internet saying this trick can remove all data from the phone. This turned out to be false.</p>
      <h3>4. The virtual assistant can mix up words and get you into an awkward situation.</h3>
      <figure>
        <img src="https://files.brightside.me/files/news/part_79/794722/15155034-65071310-e56d14037da71e63916d84e45e6c1cf05c415406-1500-1-1569935084-728-da8633d959-1573213036.jpg"/>
        <figcaption><a href="https://ru.depositphotos.com/266239776/stock-photo-cyber-sport-team-play-professional.html?utm_source=Adme&amp;utm_medium=freesub&amp;utm_campaign=RU-brand">© Depositphotos</a>   <a href="https://ru.depositphotos.com/111638506/stock-photo-lovely-woman-in-black.html?utm_source=Adme&amp;utm_medium=freesub&amp;utm_campaign=RU-brand">© Depositphotos</a>  </figcaption>
      </figure>
      <p>A couple of years ago, the owner of a Toronto <a href="https://globalnews.ca/news/3308523/toronto-esports-bar-blames-apples-siri-for-repeated-calls-for-escorts/">eSports bar</a> <a href="https://en.wikipedia.org/wiki/Esports">claimed</a> he started getting mysterious calls. This was all because Siri mixed up the words “eSport” and “escort.”</p>
      <p>As a result, the businessman was sending out requests for escort girls. Siri can become baffled if a question sounds ambiguous and your request will end up taking a wrong turn.</p>
      <h3>5. Siri is a bad advisor when it comes to plants and mushrooms.</h3>
      <figure>
        <img src="https://files.brightside.me/files/news/part_79/794722/15155035-65073810-d7841987d5508527476244e37aae96b3039b1a52-1500-1-1569935524-728-76fca82a66-1573213036.jpg"/>
        <figcaption><a href="https://pixabay.com/ru/photos/%D0%B3%D1%80%D0%B8%D0%B1-%D0%B4%D0%B8%D0%BA%D0%B0%D1%8F-%D0%B3%D1%80%D0%B8%D0%B1%D1%8B-%D0%BF%D1%80%D0%B8%D1%80%D0%BE%D0%B4%D0%B0-%D0%BF%D0%BE%D0%B3%D0%B0%D0%BD%D0%BA%D0%B0-3848290/">© skeeze / Pixabay</a>   <a href="https://pixabay.com/ru/photos/%D0%B3%D1%80%D0%B8%D0%B1%D1%8B-%D0%BF%D0%BE%D0%B3%D0%B0%D0%BD%D0%BA%D0%B0-%D0%BF%D1%80%D0%B8%D1%80%D0%BE%D0%B4%D0%B0-%D0%BC%D0%B0%D0%BA%D1%80%D0%BE%D1%81-2503205/">© artyangel / Pixabay</a>  </figcaption>
      </figure>
      <p>Siri is not a botanical reference book and cannot accurately determine the names of mushrooms, berries, or plants. If you’re a fan of gathering mushrooms and have doubts about whether this or that mushroom is poisonous, don’t seek advice from the voice assistant. You might end up damaging your health.</p>
      <h3>6. It’s dangerous to ask Siri even the simplest questions in some places.</h3>
      <figure>
        <img src="https://files.brightside.me/files/news/part_79/794722/15155036-80160-a959c4cffc5eeaa2ccd313dd108479770c11fe47-1500-1-1573123639-728-bcbae9cd2e-1573213036.jpg"/>
        <figcaption><a href="https://pixabay.com/ru/photos/%D1%81%D1%82%D0%BE%D0%BB-%D1%82%D0%B5%D1%85%D0%BD%D0%BE%D0%BB%D0%BE%D0%B3%D0%B8%D1%8F-%D1%81%D0%BC%D0%B0%D1%80%D1%82%D1%84%D0%BE%D0%BD-%D1%83%D0%BC%D0%BD%D1%8B%D0%B9-1100248/">© DariuszSankowski / Pixabay</a>   <a href="https://www.freepik.com/free-vector/microphones-design-collection_892689.htm#page=1&amp;query=mic&amp;position=0">© alvaro_cabrera / FreePik</a>  </figcaption>
      </figure>
      <p>Don’t ask Siri or any other voice assistants any questions when you’re in public or in unknown places. Chinese scientists have come up with a <a href="https://assets.documentcloud.org/documents/3987864/Dolphinattack.pdf">way</a> to command Siri without saying a single word.</p>
      <p>Microphones on modern devices hear ultrasound but people don’t. It means that malefactors can give commands to your phone using high-frequency sound while you’re busy minding your own business. However, such “magic” can operate only at a distance of 5 feet from the device.</p>
      <h3>7. Don’t ask Siri to fully charge your phone.</h3>
      <figure>
        <img src="https://files.brightside.me/files/news/part_79/794722/15155037-apple-3595630_960_720-1570008195-728-08ee161af7-1573213036.jpg"/>
        <figcaption><a href="https://pixabay.com/ru/photos/%D1%8F%D0%B1%D0%BB%D0%BE%D0%BA%D0%BE-iphone-%D1%81%D0%BC%D0%B0%D1%80%D1%82%D1%84%D0%BE%D0%BD-%D1%82%D0%B5%D1%85%D0%BD%D0%BE%D0%BB%D0%BE%D0%B3%D0%B8%D1%8F-3595630/">© mhoppsy / Pixabay</a>  </figcaption>
      </figure>
      <p>If you request Siri to “Charge my phone 100%,” it will <a href="https://www.dailydot.com/debug/siri-emergency-services/">start</a> calling emergency services. That’s because police and ambulance numbers contain variations of the number 100 in many countries. Siri perceives such a request as potentially dangerous and begins to call rescue services.</p>
      <p>Fortunately, the program provides a 5-second delay before making an emergency call so you can cancel the request.</p>
      <h3>8. The voice assistant ignores questions related to female inequality for one simple reason...</h3>
      <figure>
        <img src="https://files.brightside.me/files/news/part_79/794722/15155045-image-crop-800x944-1569851851-728-b97d046221-1573213036.jpg"/>
        <figcaption><a href="https://commons.wikimedia.org/wiki/File:We_Can_Do_It!.jpg">© Public Domain / Wikimedia Commons</a>  </figcaption>
      </figure>
      <p>It’s impossible to find out whether feminism and other female movements such as <a href="https://en.wikipedia.org/wiki/Me_Too_movement">#</a><a href="https://en.wikipedia.org/wiki/Me_Too_movement">MeToo</a> are evil or good with the help of Siri. The developers of the program have <a href="https://www.telegraph.co.uk/technology/2019/09/06/siri-banned-apple-saying-word-feminism/">specially</a> rewritten the algorithms so that the assistant would give a neutral answer. “I believe in universal equality,” Siri will say if asked about these things.</p>
      <p>Apple considers gender-related issues and judgments to be a potentially conflicting content. That’s why in order to not insult anyone, Siri will suggest you use search engines.</p>
      <h3>9. Siri records all your conversations and sends them to a special database.</h3>
      <figure>
        <img src="https://files.brightside.me/files/news/part_79/794722/15155039-80260-9e6e8dfd98156525f3d03b0a162ef54029518b88-1500-1-1573123716-728-da43d349e8-1573213036.jpg"/>
        <figcaption><a href="https://www.youtube.com/watch?v=5mU2DvWFlN4">© Official The Rock Siri Commercial / YouTube</a>   <a href="https://ru.depositphotos.com/168585734/stock-photo-call-center-worker.html?utm_source=Adme&amp;utm_medium=freesub&amp;utm_campaign=RU-brand">© Depositphotos</a>  </figcaption>
      </figure>
      <p>Until the summer of 2019, Apple contractors used to listen to recordings made with Siri. Apple used to record and <a href="https://www.theguardian.com/technology/2019/jul/26/apple-contractors-regularly-hear-confidential-details-on-siri-recordings">transfer</a> files with people’s personal conversations to third parties. The company explains it by the fact that recording analysis is meant to improve Siri. Of course, no one asked the users’ permission to do this.</p>
      <p>The system’s <a href="https://www.telegraph.co.uk/technology/2019/08/28/apple-stop-storing-si">update</a> is about to happen at the end of this year after which Apple will ask your permission to record your personal conversations. We don’t urge you to become paranoid, and it’s unlikely that the company will somehow use the information they receive against you. However, unlike Google or Amazon that provide information about what they record about you, Apple hides such details.</p>
      <p>If you value privacy, turn off Siri and geolocation functions. However, in this case, Apple <a href="https://qz.com/1351647/how-to-stop-your-iphone-from-listening-to-your-conversations/">doesn’t guarantee</a> that all applications will work properly.</p>
      <h3>Bonus: The woman who gave her voice to Siri</h3>
      <figure>
        <img src="https://files.brightside.me/files/news/part_79/794722/15155040-EFZMaWRW4AA8hRm-1569841518-728-7dc39d10b7-1573213036.jpg"/>
        <figcaption><a href="https://twitter.com/SiriouslySusan/status/1177212371464536074">© Susan Bennett / Twitter</a>  </figcaption>
      </figure>
      <p><a href="https://susancbennett.com/">Susan Bennett</a>, an actress and singer, voiced Siri’s first version. From 2011 till 2013, Susan has recorded thousands of phrases that millions of people heard later. Bennett is a true veteran of voice-over because ATMs, GPS trackers, and various computer systems “speak” with her voice too.</p>
      <p>It’s known that there are 2 types of people in the world: fans of iOS and fans of Android. Which group are you in? Have you already tried to ask Siri one of the forbidden questions? What result did you get? We’d be glad to hear from you in the comments!</p>
      <p>Preview photo credit <a href="https://pixabay.com/ru/photos/%D0%B3%D1%80%D0%B8%D0%B1-%D0%B4%D0%B8%D0%BA%D0%B0%D1%8F-%D0%B3%D1%80%D0%B8%D0%B1%D1%8B-%D0%BF%D1%80%D0%B8%D1%80%D0%BE%D0%B4%D0%B0-%D0%BF%D0%BE%D0%B3%D0%B0%D0%BD%D0%BA%D0%B0-3848290/">skeeze / Pixabay</a></p>
    </article>
  </body>
</html>