<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <meta property="og:url" content="https://forklog.com/sovet-evropy-proanaliziroval-negativnoe-vliyanie-ii-na-prava-cheloveka/"/>
    <meta property="og:site_name" content="ForkLog"/>
    <meta property="article:published_time" content="2019-11-14T08:44:28+00:00"/>
    <meta property="og:title" content="Совет Европы проанализировал негативное влияние ИИ на права человека"/>
    <meta property="og:description" content="Комитет экспертов по правозащитным аспектам автоматизированной обработки данных и различных форм искусственного интеллекта (MSI-AUT) подготовил проект рекомендаций по защите прав человека от"/>
  </head>
  <body>
    <article>
      <h1>Совет Европы проанализировал негативное влияние ИИ на права человека</h1>
      <address>
        <time datetime="2019-11-14T08:44:28+00:00">14 Nov 2019, 08:44</time>
      </address>
      <p>Комитет экспертов по правозащитным аспектам автоматизированной обработки данных и различных форм искусственного интеллекта (MSI-AUT) подготовил проект <a href="https://rm.coe.int/draft-recommendation-of-the-committee-of-ministers-to-states-on-the-hu/168095eecf">рекомендаций</a> по защите прав человека от негативного влияния ИИ.</p>
      <p>Консультации в подготовке документа оказывали фонд Викимедиа и международная правозащитная группа <a href="https://www.accessnow.org/cms/assets/uploads/2019/10/Submission-on-CoE-recommendation-on-the-human-rights-impacts-of-algorithmic-systems-21.pdf">Access Now</a>.</p>
      <p>По словам авторов, созданию документа предшествовала общественная дискуссия о потенциальном негативном влиянии алгоритмических систем на демократию и самовыражение.</p>
      <p>Рекомендации экспертов охватывают аспекты проектирования, разработки и развертывания алгоритмических систем: управление данными, моделирование, анализ, прозрачность, подотчетность, меры предосторожности, исследования и информирование общественности.</p>
      <p>Например, субъекты частного сектора «должны осознавать риски, связанные с качеством, природой и происхождением данных, которые они используют для обучения своих алгоритмов, чтобы гарантировать, что ошибки, предвзятость и потенциальная дискриминация адекватно учтены в рамках конкретных контекстов».</p>
      <p>В свою очередь государствам необходимо контролировать, чтобы «персонал, участвующий в закупках, разработке, внедрении и оценке алгоритмических систем, был компетентен в правах человека и недискриминации и осознавал свою обязанность обеспечивать не только тщательную техническую оценку, но и соблюдение прав человека».</p>
      <p>Пока что документ проходит стадию утверждения в среде правозащитников. Ожидается, что дополнительные правки могут быть внесены в декабре, после рассмотрения отчета Комитетом по СМИ и информационному обществу.</p>
      <p>Наряду с Европой Россия также изучает перспективы и риски использования искусственного интеллекта. В октябре президент РФ Владимир Путин утвердил <a href="https://forklog.com/putin-utverdil-strategiyu-razvitiya-iskusstvennogo-intellekta-v-rossii-do-2030-goda/">национальную стратегию</a> развития ИИ до 2030 года.</p>
    </article>
  </body>
</html>